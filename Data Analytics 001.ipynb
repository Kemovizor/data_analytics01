{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting business.json to business.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 192609 dictionaries.\n",
      "Execution time:  3.6180918216705322  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_business = []\n",
    "counter =0\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/business.json',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        listOfDicts_business.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  192609 /Users/kemalm/Desktop/yelp_dataset/business.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/business.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business_id' 'name' 'address' 'city' 'state' 'postal_code' 'latitude'\n",
      " 'longitude' 'stars' 'review_count' 'is_open' 'attributes' 'categories'\n",
      " 'hours'] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "attr_arr = np.array(['business_id', 'name', 'address', 'city', 'state', \n",
    "                     'postal_code', 'latitude', 'longitude', 'stars', \n",
    "                     'review_count', 'is_open', 'attributes', 'categories', 'hours'])\n",
    "print(attr_arr, type(attr_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">business.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192609  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['business_id' 192609.0]\n",
      " ['name' 192609.0]\n",
      " ['address' 192609.0]\n",
      " ['city' 192609.0]\n",
      " ['state' 192609.0]\n",
      " ['postal_code' 192609.0]\n",
      " ['latitude' 192609.0]\n",
      " ['longitude' 192609.0]\n",
      " ['stars' 192609.0]\n",
      " ['review_count' 192609.0]\n",
      " ['is_open' 192609.0]\n",
      " ['attributes' 192609.0]\n",
      " ['categories' 192609.0]\n",
      " ['hours' 192609.0]]\n"
     ]
    }
   ],
   "source": [
    "df_containsfield= np.zeros((len(listOfDicts_business),len(attr_arr)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_business)):\n",
    "    df_containsfield[i,:] = np.isin(attr_arr, np.array(list(listOfDicts_business[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((attr_arr.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(attr_arr)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id\n",
      "       0\n",
      "name\n",
      "       0\n",
      "address\n",
      "       0\n",
      "city\n",
      "       0\n",
      "state\n",
      "       0\n",
      "postal_code\n",
      "       0\n",
      "latitude\n",
      "       0\n",
      "longitude\n",
      "       0\n",
      "stars\n",
      "       0\n",
      "review_count\n",
      "       0\n",
      "is_open\n",
      "       0\n",
      "attributes\n",
      "   28836\n",
      "categories\n",
      "     482\n",
      "hours\n",
      "   44830\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(attr_arr):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/business.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> business.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydict(dict):\n",
    "        def __str__(self):\n",
    "            return json.dumps(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 192609 rows\n",
      "Execution time:  6.614404201507568  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/business.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,list(attr_arr), delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_business:\n",
    "        tempDict=dict(dictObj)    \n",
    "        if tempDict.get('attributes') is not None:\n",
    "            tempDict['attributes'] = mydict(tempDict['attributes']).__str__()\n",
    "        else:\n",
    "            tempDict['attributes']=\"{}\"\n",
    "            \n",
    "        if tempDict.get('hours') is not None:\n",
    "            tempDict['hours'] = mydict(tempDict['hours']).__str__()\n",
    "        else:\n",
    "            tempDict['hours']=\"{}\"\n",
    "        writer.writerow(tempDict)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting user.json to user.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 1637138 rows\n",
      "Execution time:  42.027015209198  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_user = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/user.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_user.append(json.loads(line))\n",
    "        counter+=1\n",
    "endend  = time.time()\n",
    "print(\"Successfully appended {} rows\".format(counter))\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1637138 /Users/kemalm/Desktop/yelp_dataset/user.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/user.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637138"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listOfDicts_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_user = np.array(['user_id', 'name', 'review_count', 'yelping_since', 'useful', \n",
    "                     'funny', 'cool', 'elite', 'friends', 'fans', \n",
    "                     'average_stars', 'compliment_hot', 'compliment_more', 'compliment_profile', 'compliment_cute', \n",
    "                     'compliment_list', 'compliment_note', 'compliment_plain', 'compliment_cool', 'compliment_funny', \n",
    "                     'compliment_writer', 'compliment_photos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">user.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "1637138  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['user_id' 1637138.0]\n",
      " ['name' 1637138.0]\n",
      " ['review_count' 1637138.0]\n",
      " ['yelping_since' 1637138.0]\n",
      " ['useful' 1637138.0]\n",
      " ['funny' 1637138.0]\n",
      " ['cool' 1637138.0]\n",
      " ['elite' 1637138.0]\n",
      " ['friends' 1637138.0]\n",
      " ['fans' 1637138.0]\n",
      " ['average_stars' 1637138.0]\n",
      " ['compliment_hot' 1637138.0]\n",
      " ['compliment_more' 1637138.0]\n",
      " ['compliment_profile' 1637138.0]\n",
      " ['compliment_cute' 1637138.0]\n",
      " ['compliment_list' 1637138.0]\n",
      " ['compliment_note' 1637138.0]\n",
      " ['compliment_plain' 1637138.0]\n",
      " ['compliment_cool' 1637138.0]\n",
      " ['compliment_funny' 1637138.0]\n",
      " ['compliment_writer' 1637138.0]\n",
      " ['compliment_photos' 1637138.0]]\n",
      "Execution time:  111.81420087814331  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_user),len(arr_user)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_user)):\n",
    "    df_containsfield[i,:] = np.isin(arr_user, np.array(list(listOfDicts_user[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_user.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_user)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> \n",
    "<h5 style=\"color:red;\"> WARNING! Following method works very slow for very large datasets (user.json). </h5> \n",
    "<h5 style=\"color:red;\"> Therefore, it shouldn't be run more than once. </h5> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "       0\n",
      "name\n",
      "       0\n",
      "review_count\n",
      "       0\n",
      "yelping_since\n",
      "       0\n",
      "useful\n",
      "       0\n",
      "funny\n",
      "       0\n",
      "cool\n",
      "       0\n",
      "elite\n",
      "       0\n",
      "friends\n",
      "       0\n",
      "fans\n",
      "       0\n",
      "average_stars\n",
      "       0\n",
      "compliment_hot\n",
      "       0\n",
      "compliment_more\n",
      "       0\n",
      "compliment_profile\n",
      "       0\n",
      "compliment_cute\n",
      "       0\n",
      "compliment_list\n",
      "       0\n",
      "compliment_note\n",
      "       0\n",
      "compliment_plain\n",
      "       0\n",
      "compliment_cool\n",
      "       0\n",
      "compliment_funny\n",
      "       0\n",
      "compliment_writer\n",
      "       0\n",
      "compliment_photos\n",
      "       0\n",
      "Execution time:  963.2632689476013  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_user):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/user.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> user.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 1637138 rows\n",
      "Execution time:  75.70107102394104\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/user.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,user_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_user:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1637138 yelp_dataset/user.json\n",
      "User.csv has one more row used as a header.\n",
      " 1637139 yelp_dataset/user.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l yelp_dataset/user.json\n",
    "!echo \"User.csv has one more row used as a header.\"\n",
    "!wc -l yelp_dataset/user.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting review.json to review.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 6685900 dictionaries.\n",
      "Execution time:  71.14869093894958  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_review = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/review.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_review.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6685900 /Users/kemalm/Desktop/yelp_dataset/review.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/review.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_review= np.array(['review_id', 'user_id', 'business_id', 'stars', 'useful',\n",
    "                      'funny', 'cool', 'text', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">review.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "6685900  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['review_id' 6685900.0]\n",
      " ['user_id' 6685900.0]\n",
      " ['business_id' 6685900.0]\n",
      " ['stars' 6685900.0]\n",
      " ['useful' 6685900.0]\n",
      " ['funny' 6685900.0]\n",
      " ['cool' 6685900.0]\n",
      " ['text' 6685900.0]\n",
      " ['date' 6685900.0]]\n",
      "Execution time:  299.6732749938965  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_review),len(arr_review)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_review)):\n",
    "    df_containsfield[i,:] = np.isin(arr_review, np.array(list(listOfDicts_review[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_review.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_review)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> \n",
    "<h5 style=\"color:red;\"> WARNING! Following method works very slow for very large datasets (user.json). </h5> \n",
    "<h5 style=\"color:red;\"> Therefore, it shouldn't be run more than once. </h5> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_id\n",
      "       0\n",
      "user_id\n",
      "       0\n",
      "business_id\n",
      "       0\n",
      "stars\n",
      "       0\n",
      "useful\n",
      "       0\n",
      "funny\n",
      "       0\n",
      "cool\n",
      "       0\n",
      "text\n",
      "       0\n",
      "date\n",
      "       0\n",
      "Execution time:  913.4484198093414  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_review):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/review.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date']\n"
     ]
    }
   ],
   "source": [
    "review_cols = list(arr_review)\n",
    "print(review_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> review.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 6685900 rows\n",
      "Execution time:  232.80819010734558  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/review.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,review_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_review:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting checkin.json to checkin.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 161950 dictionaries.\n",
      "Execution time:  2.0320558547973633  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_checkin = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/checkin.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_checkin.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  161950 /Users/kemalm/Desktop/yelp_dataset/checkin.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/checkin.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_checkin = np.array(['business_id', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">checkin.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "161950  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['business_id' 161950.0]\n",
      " ['date' 161950.0]]\n",
      "Execution time:  2.568455934524536  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_checkin),len(arr_checkin)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_checkin)):\n",
    "    df_containsfield[i,:] = np.isin(arr_checkin, np.array(list(listOfDicts_checkin[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_checkin.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_checkin)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id\n",
      "       0\n",
      "date\n",
      "       0\n",
      "Execution time:  14.164305925369263  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_checkin):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/checkin.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business_id', 'date']\n"
     ]
    }
   ],
   "source": [
    "checkin_cols = list(arr_checkin)\n",
    "print(checkin_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> checkin.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 161950 rows\n",
      "Execution time:  9.046382665634155  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/checkin.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,checkin_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_checkin:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  161950 yelp_dataset/checkin.json\n",
      "  161951 yelp_dataset/checkin.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l yelp_dataset/checkin.json\n",
    "!wc -l yelp_dataset/checkin.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting tip.json to tip.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 1223094 dictionaries.\n",
      "Execution time:  6.717769145965576  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_tip = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/tip.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_tip.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1223094 /Users/kemalm/Desktop/yelp_dataset/tip.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/tip.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_tip = np.array(['user_id', 'business_id', 'text', 'date', 'compliment_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">tip.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "1223094  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['user_id' 1223094.0]\n",
      " ['business_id' 1223094.0]\n",
      " ['text' 1223094.0]\n",
      " ['date' 1223094.0]\n",
      " ['compliment_count' 1223094.0]]\n",
      "Execution time:  30.554124116897583  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_tip),len(arr_tip)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_tip)):\n",
    "    df_containsfield[i,:] = np.isin(arr_tip, np.array(list(listOfDicts_tip[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_tip.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_tip)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "       0\n",
      "business_id\n",
      "       0\n",
      "text\n",
      "       0\n",
      "date\n",
      "       0\n",
      "compliment_count\n",
      "       0\n",
      "Execution time:  25.752610683441162  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_tip):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/tip.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'business_id', 'text', 'date', 'compliment_count']\n"
     ]
    }
   ],
   "source": [
    "tip_cols = list(arr_tip)\n",
    "print(tip_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> tip.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 1223094 rows\n",
      "Execution time:  8.033058166503906  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/tip.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,tip_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_tip:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting photo.json to photo.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 200000 dictionaries.\n",
      "Execution time:  0.9235949516296387  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_photo = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/photo.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_photo.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  200000 /Users/kemalm/Desktop/yelp_dataset/photo.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/photo.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_photo = np.array(['caption', 'photo_id', 'business_id', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">photo.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "200000  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['caption' 200000.0]\n",
      " ['photo_id' 200000.0]\n",
      " ['business_id' 200000.0]\n",
      " ['label' 200000.0]]\n",
      "Execution time:  4.147678852081299  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_photo),len(arr_photo)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_photo)):\n",
    "    df_containsfield[i,:] = np.isin(arr_photo, np.array(list(listOfDicts_photo[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_photo.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_photo)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption\n",
      "       0\n",
      "photo_id\n",
      "       0\n",
      "business_id\n",
      "       0\n",
      "label\n",
      "       0\n",
      "Execution time:  3.233721971511841  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_photo):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/photo.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caption', 'photo_id', 'business_id', 'label']\n"
     ]
    }
   ],
   "source": [
    "photo_cols = list(arr_photo)\n",
    "print(photo_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> photo.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 200000 rows\n",
      "Execution time:  0.9482808113098145  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/photo.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,photo_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_photo:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python-to-PostgreSQL client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn=psycopg2.connect(\"dbname='yelpDB' user='postgres' host='localhost' password='P0$tgre$QL'\")\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "#cur.execute(\"\"\"select city,state, count(business_id)\n",
    "#                from Businesses\n",
    "#                where is_open = 1\n",
    "#                group by city,state\n",
    "#                order by 3 desc\n",
    "#                limit 10\"\"\")\n",
    "#recordsDB = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"select name, address, city, state, latitude, longitude, categories, is_open, hours\n",
    "                from Businesses\"\"\")\n",
    "recordsDB = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Places: Sending HTTP Requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from scipy.spatial.distance import pdist\n",
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_content= !cat /Users/kemalm/Desktop/gmAPI.txt\n",
    "api_key = key_content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 0, 'address': 1, 'city': 2, 'state': 3, 'latitude': 4, 'longitude': 5, 'categories': 6, 'is_open': 7, 'hours': 8, 'obt_name': 9, 'obt_address': 10, 'obt_city': 11, 'obt_state': 12, 'obt_latitude': 13, 'obt_longitude': 14, 'obt_categories': 15, 'obt_is_open': 16, 'obt_hours': 17, 'diff_distance_in_meters': 18}\n"
     ]
    }
   ],
   "source": [
    "fields = ['name', 'address', 'city', 'state', 'latitude', 'longitude', 'categories', 'is_open', 'hours']\n",
    "k = np.core.defchararray.add(np.array(['obt_']),np.array(fields))\n",
    "\n",
    "#print(k)\n",
    "indices =[x for x in range(0,len(fields)*2)]\n",
    "#print(indices)\n",
    "mapDictIndexes = dict(zip(fields+list(k),indices))\n",
    "mapDictIndexes['diff_distance_in_meters'] = len(fields)*2\n",
    "print(mapDictIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = np.array([[0,0],\n",
    "                        [ 0, 180]])# Using the geodesic distance function.\n",
    "m_dist = pdist(coordinates, # Coordinates matrix or tuples list\n",
    "               lambda u, v: geodesic(u, v).kilometers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_lat,smpl_lng =  33.5221294, -112.0181866\n",
    "url_api_place_nearbySearch =\"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={},{}&radius=500&keyword={}&key={}\".format(\n",
    "smpl_lat,smpl_lng,'Arizona Biltmore Golf Club', api_key)\n",
    "response_api_place_nearbySearch =requests.get(url_api_place_nearbySearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"html_attributions\": [], \"results\": [{\"geometry\": {\"location\": {\"lat\": 33.5175972, \"lng\": -112.0213628}, \"viewport\": {\"northeast\": {\"lat\": 33.5220429, \"lng\": -112.0195567201073}, \"southwest\": {\"lat\": 33.5161153, \"lng\": -112.0222563798927}}}, \"icon\": \"https://maps.gstatic.com/mapfiles/place_api/icons/golf-71.png\", \"id\": \"4f875490889efc8934301f8e02a335a0b908f81f\", \"name\": \"Arizona Biltmore Golf Club\", \"opening_hours\": {\"open_now\": true}, \"photos\": [{\"height\": 2988, \"html_attributions\": [\"<a href=\\\"https://maps.google.com/maps/contrib/112214149588074350919/photos\\\">Rodolfo Concepcion</a>\"], \"photo_reference\": \"CmRaAAAAusRoo-LbrwqaaaN2MjOjbvkIvfwdas5ojS2L3f9v_wbOrQMr-bso5CZor3XbYUZbLgtW3t8uBCRH2jxbl5uO_-H_4Don1rnlNsNiFm23m2OecwtMq4vw_2gbttX6emFcEhBioqy9PTeeDIQXtLEpTAC7GhRE5Dh_E8m1zn2ewTjwmTpyURSx2Q\", \"width\": 5312}], \"place_id\": \"ChIJ47o1_EENK4cRCeK-yfYA-V8\", \"plus_code\": {\"compound_code\": \"GX9H+2F Phoenix, Arizona, USA\", \"global_code\": \"8559GX9H+2F\"}, \"rating\": 4.3, \"reference\": \"ChIJ47o1_EENK4cRCeK-yfYA-V8\", \"scope\": \"GOOGLE\", \"types\": [\"lodging\", \"point_of_interest\", \"establishment\"], \"user_ratings_total\": 346, \"vicinity\": \"2400 E Missouri Ave, Phoenix\"}], \"status\": \"OK\"}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(response_api_place_nearbySearch.json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_lat,smpl_lng =  33.654815, -112.188568\n",
    "url_api_place_nearbySearch =\"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={},{}&radius=500&keyword={}&key={}\".format(\n",
    "smpl_lat,smpl_lng,'Vita Bella Fine Day Spa', api_key)\n",
    "response_api_place_nearbySearch =requests.get(url_api_place_nearbySearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'html_attributions': [], 'results': [], 'status': 'ZERO_RESULTS'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_api_place_nearbySearch.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Status:  OK\n",
      "Record num. 1\n",
      "Execution time:  0.7021129131317139  seconds.\n",
      "Status:  OK\n",
      "Record num. 2\n",
      "Execution time:  1.4191508293151855  seconds.\n",
      "Status:  OK\n",
      "Record num. 3\n",
      "Execution time:  2.3403608798980713  seconds.\n",
      "Status:  OK\n",
      "Record num. 4\n",
      "Execution time:  2.9542388916015625  seconds.\n",
      "Status:  OK\n",
      "Record num. 5\n",
      "Execution time:  3.8762879371643066  seconds.\n",
      "Status:  OK\n",
      "Record num. 6\n",
      "Execution time:  4.491046905517578  seconds.\n",
      "Status:  OK\n",
      "Record num. 7\n",
      "Execution time:  5.2076098918914795  seconds.\n",
      "Status:  OK\n",
      "Record num. 8\n",
      "Execution time:  6.129266023635864  seconds.\n",
      "Status:  OK\n",
      "Record num. 9\n",
      "Execution time:  6.846045970916748  seconds.\n",
      "Status:  OK\n",
      "Record num. 10\n",
      "Execution time:  7.684054851531982  seconds.\n",
      "Status:  OK\n",
      "Record num. 11\n",
      "Execution time:  8.284544944763184  seconds.\n",
      "Status:  OK\n",
      "Record num. 12\n",
      "Execution time:  8.893998861312866  seconds.\n",
      "Status:  OK\n",
      "Record num. 13\n",
      "Execution time:  9.713221788406372  seconds.\n",
      "Status:  OK\n",
      "Record num. 14\n",
      "Execution time:  10.327652931213379  seconds.\n",
      "Status:  OK\n",
      "Record num. 15\n",
      "Execution time:  11.044584035873413  seconds.\n",
      "Status:  OK\n",
      "Record num. 16\n",
      "Execution time:  11.659189939498901  seconds.\n",
      "Status:  OK\n",
      "Record num. 17\n",
      "Execution time:  12.27336597442627  seconds.\n",
      "Status:  OK\n",
      "Record num. 18\n",
      "Execution time:  12.99016785621643  seconds.\n",
      "Status:  OK\n",
      "Record num. 19\n",
      "Execution time:  13.604652881622314  seconds.\n",
      "Status:  OK\n",
      "Record num. 20\n",
      "Execution time:  14.628405094146729  seconds.\n",
      "Status:  OK\n",
      "Record num. 21\n",
      "Execution time:  15.242988109588623  seconds.\n",
      "Status:  OK\n",
      "Record num. 22\n",
      "Execution time:  15.857290029525757  seconds.\n",
      "Status:  OK\n",
      "Record num. 23\n",
      "Execution time:  16.779310941696167  seconds.\n",
      "Status:  OK\n",
      "Record num. 24\n",
      "Execution time:  17.39326286315918  seconds.\n",
      "Status:  OK\n",
      "Record num. 25\n",
      "Execution time:  18.00755000114441  seconds.\n",
      "Status:  OK\n",
      "Record num. 26\n",
      "Execution time:  18.826764822006226  seconds.\n",
      "Status:  OK\n",
      "Record num. 27\n",
      "Execution time:  19.54325580596924  seconds.\n",
      "Status:  OK\n",
      "Record num. 28\n",
      "Execution time:  20.29045796394348  seconds.\n",
      "Status:  OK\n",
      "Record num. 29\n",
      "Execution time:  20.890723943710327  seconds.\n",
      "Status:  OK\n",
      "Record num. 30\n",
      "Execution time:  21.5918447971344  seconds.\n",
      "Status:  OK\n",
      "Record num. 31\n",
      "Execution time:  22.206256866455078  seconds.\n",
      "Status:  OK\n",
      "Record num. 32\n",
      "Execution time:  22.92311191558838  seconds.\n",
      "Status:  OK\n",
      "Record num. 33\n",
      "Execution time:  23.53719687461853  seconds.\n",
      "Status:  OK\n",
      "Record num. 34\n",
      "Execution time:  24.25429391860962  seconds.\n",
      "Status:  ZERO_RESULTS\n",
      "Record num. 35\n",
      "Execution time:  24.97049880027771  seconds.\n",
      "Status:  OK\n",
      "Record num. 36\n",
      "Execution time:  25.693240880966187  seconds.\n",
      "Status:  OK\n",
      "Record num. 37\n",
      "Execution time:  26.609327793121338  seconds.\n",
      "Status:  OK\n",
      "Record num. 38\n",
      "Execution time:  27.32617974281311  seconds.\n",
      "Status:  OK\n",
      "Record num. 39\n",
      "Execution time:  27.94063901901245  seconds.\n",
      "Status:  OK\n",
      "Record num. 40\n",
      "Execution time:  28.55508780479431  seconds.\n",
      "Status:  OK\n",
      "Record num. 41\n",
      "Execution time:  29.29528498649597  seconds.\n",
      "Status:  OK\n",
      "Record num. 42\n",
      "Execution time:  30.398382902145386  seconds.\n",
      "Status:  OK\n",
      "Record num. 43\n",
      "Execution time:  31.0128116607666  seconds.\n",
      "Status:  OK\n",
      "Record num. 44\n",
      "Execution time:  31.72952389717102  seconds.\n",
      "Status:  OK\n",
      "Record num. 45\n",
      "Execution time:  32.34435987472534  seconds.\n",
      "Status:  OK\n",
      "Record num. 46\n",
      "Execution time:  32.958313941955566  seconds.\n",
      "Status:  ZERO_RESULTS\n",
      "Record num. 47\n",
      "Execution time:  33.57222080230713  seconds.\n",
      "Status:  OK\n",
      "Record num. 48\n",
      "Execution time:  34.18725776672363  seconds.\n",
      "Status:  ZERO_RESULTS\n",
      "Record num. 49\n",
      "Execution time:  34.801018953323364  seconds.\n",
      "Status:  OK\n",
      "Record num. 50\n",
      "Execution time:  35.3136248588562  seconds.\n",
      "Status:  OK\n",
      "Record num. 51\n",
      "Execution time:  35.9285089969635  seconds.\n",
      "Status:  OK\n",
      "Record num. 52\n",
      "Execution time:  36.74730587005615  seconds.\n",
      "Status:  OK\n",
      "Record num. 53\n",
      "Execution time:  37.463958740234375  seconds.\n",
      "Status:  OK\n",
      "Record num. 54\n",
      "Execution time:  38.078412771224976  seconds.\n",
      "Status:  OK\n",
      "Record num. 55\n",
      "Execution time:  38.69283580780029  seconds.\n",
      "Status:  OK\n",
      "Record num. 56\n",
      "Execution time:  39.30725574493408  seconds.\n",
      "Status:  OK\n",
      "Record num. 57\n",
      "Execution time:  40.12654495239258  seconds.\n",
      "Status:  OK\n",
      "Record num. 58\n",
      "Execution time:  40.7402880191803  seconds.\n",
      "Status:  OK\n",
      "Record num. 59\n",
      "Execution time:  41.5595908164978  seconds.\n",
      "Status:  OK\n",
      "Record num. 60\n",
      "Execution time:  42.27656602859497  seconds.\n",
      "Status:  OK\n",
      "Record num. 61\n",
      "Execution time:  43.103553771972656  seconds.\n",
      "Status:  OK\n",
      "Record num. 62\n",
      "Execution time:  43.81298494338989  seconds.\n",
      "Status:  OK\n",
      "Record num. 63\n",
      "Execution time:  44.52969980239868  seconds.\n",
      "Status:  OK\n",
      "Record num. 64\n",
      "Execution time:  45.24664282798767  seconds.\n",
      "Status:  OK\n",
      "Record num. 65\n",
      "Execution time:  45.86091709136963  seconds.\n",
      "Status:  OK\n",
      "Record num. 66\n",
      "Execution time:  46.47538781166077  seconds.\n",
      "Status:  OK\n",
      "Record num. 67\n",
      "Execution time:  47.19211483001709  seconds.\n",
      "Status:  OK\n",
      "Record num. 68\n",
      "Execution time:  47.70394992828369  seconds.\n",
      "Status:  OK\n",
      "Record num. 69\n",
      "Execution time:  48.62562680244446  seconds.\n",
      "Status:  ZERO_RESULTS\n",
      "Record num. 70\n",
      "Execution time:  49.44463086128235  seconds.\n",
      "Status:  ZERO_RESULTS\n",
      "Record num. 71\n",
      "Execution time:  50.058764696121216  seconds.\n",
      "Status:  OK\n",
      "Record num. 72\n",
      "Execution time:  50.878509759902954  seconds.\n",
      "Status:  OK\n",
      "Record num. 73\n",
      "Execution time:  51.59533977508545  seconds.\n",
      "Status:  OK\n",
      "Record num. 74\n",
      "Execution time:  52.209741830825806  seconds.\n",
      "Status:  OK\n",
      "Record num. 75\n",
      "Execution time:  52.82396984100342  seconds.\n",
      "Status:  OK\n",
      "Record num. 76\n",
      "Execution time:  53.541022062301636  seconds.\n",
      "Status:  OK\n",
      "Record num. 77\n",
      "Execution time:  54.462753772735596  seconds.\n",
      "Status:  OK\n",
      "Record num. 78\n",
      "Execution time:  55.384217739105225  seconds.\n",
      "Status:  OK\n",
      "Record num. 79\n",
      "Execution time:  56.101075887680054  seconds.\n",
      "Status:  OK\n",
      "Record num. 80\n",
      "Execution time:  57.12502980232239  seconds.\n",
      "Status:  OK\n",
      "Record num. 81\n",
      "Execution time:  57.739566802978516  seconds.\n",
      "Status:  ZERO_RESULTS\n",
      "Record num. 82\n",
      "Execution time:  58.35330581665039  seconds.\n",
      "Status:  OK\n",
      "Record num. 83\n",
      "Execution time:  58.96820878982544  seconds.\n",
      "Status:  OK\n",
      "Record num. 84\n",
      "Execution time:  59.78744673728943  seconds.\n",
      "Status:  OK\n",
      "Record num. 85\n",
      "Execution time:  60.40180993080139  seconds.\n",
      "Status:  OK\n",
      "Record num. 86\n",
      "Execution time:  61.221038818359375  seconds.\n",
      "Status:  ZERO_RESULTS\n",
      "Record num. 87\n",
      "Execution time:  61.937500953674316  seconds.\n",
      "Status:  OK\n",
      "Record num. 88\n",
      "Execution time:  62.6546049118042  seconds.\n",
      "Status:  ZERO_RESULTS\n",
      "Record num. 89\n",
      "Execution time:  63.268876791000366  seconds.\n",
      "Status:  ZERO_RESULTS\n",
      "Record num. 90\n",
      "Execution time:  63.985564947128296  seconds.\n",
      "Status:  ZERO_RESULTS\n",
      "Record num. 91\n",
      "Execution time:  64.59972095489502  seconds.\n",
      "Status:  OK\n",
      "Record num. 92\n",
      "Execution time:  65.41958570480347  seconds.\n",
      "Status:  OK\n",
      "Record num. 93\n",
      "Execution time:  66.44348788261414  seconds.\n",
      "Status:  OK\n",
      "Record num. 94\n",
      "Execution time:  67.26230192184448  seconds.\n",
      "Status:  OK\n",
      "Record num. 95\n",
      "Execution time:  67.97928667068481  seconds.\n",
      "Status:  OK\n",
      "Record num. 96\n",
      "Execution time:  69.00360298156738  seconds.\n",
      "Status:  OK\n",
      "Record num. 97\n",
      "Execution time:  70.02735686302185  seconds.\n",
      "Status:  OK\n",
      "Record num. 98\n",
      "Execution time:  70.74434208869934  seconds.\n",
      "Status:  OK\n",
      "Record num. 99\n",
      "Execution time:  71.25624871253967  seconds.\n",
      "Status:  ZERO_RESULTS\n",
      "Record num. 100\n",
      "Execution time:  72.27953386306763  seconds.\n",
      "Successfully appended 100 dictionaries\n",
      "Execution time:  72.2799129486084  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts =list()\n",
    "counter=0\n",
    "for record in rn.sample(recordsDB, 100):\n",
    "    \n",
    "    dictObj=dict()\n",
    "    #Fields of a record from yelpDB database\n",
    "    \n",
    "    business_name = record[mapDictIndexes['name']] \n",
    "    business_address = record[mapDictIndexes['address']].replace(\" \",\"+\")\n",
    "    business_latitude = record[mapDictIndexes['latitude']]\n",
    "    business_longitude = record[mapDictIndexes['longitude']]\n",
    "    \n",
    "    dictObj['name']= record[mapDictIndexes['name']]\n",
    "    dictObj['address']= record[mapDictIndexes['address']]\n",
    "    dictObj['city']= record[mapDictIndexes['city']]\n",
    "    dictObj['state']= record[mapDictIndexes['state']]\n",
    "    dictObj['latitude']= record[mapDictIndexes['latitude']]\n",
    "    dictObj['longitude']= record[mapDictIndexes['longitude']]\n",
    "    dictObj['categories']= record[mapDictIndexes['categories']]\n",
    "    dictObj['is_open']= record[mapDictIndexes['is_open']]\n",
    "    dictObj['hours']= record[mapDictIndexes['hours']]\n",
    "      \n",
    "    #generating an url to find whether there is a business in radius of 500 meters centered around geo coordinates we previously obtained\n",
    "    url_nearbySearch =\"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={},{}&radius=500&keyword={}&key={}\".format(\n",
    "    business_latitude,business_longitude,business_name, api_key)\n",
    "    \n",
    "    \n",
    "   \n",
    "    #http request\n",
    "    response_nearbySearch =requests.get(url_nearbySearch)\n",
    "    #converting to json (type:dict)\n",
    "    response_nearbySearchJSON= response_nearbySearch.json()\n",
    "    if(response_nearbySearchJSON['status']=='OK'):\n",
    "        dictObj['obt_name']= response_nearbySearchJSON['results'][0]['name']\n",
    "        obt_add,obt_ct = response_nearbySearchJSON['results'][0]['vicinity'].rsplit(',', 1)\n",
    "        dictObj['obt_address']= obt_add\n",
    "        \n",
    "        dictObj['obt_city'] = obt_ct\n",
    "        dictObj['obt_state'] = '...'\n",
    "        obt_lat,obt_lng =response_nearbySearchJSON['results'][0]['geometry']['location']['lat'], response_nearbySearchJSON['results'][0]['geometry']['location']['lng']\n",
    "        dictObj['obt_latitude']= obt_lat\n",
    "        dictObj['obt_longitude']= obt_lng\n",
    "           \n",
    "        #generating matrix of geo coordinates\n",
    "        coordinates=np.array([[business_latitude, business_longitude],[obt_lat,obt_lng]])\n",
    "        #executing pdist function to calculate distance between spherical points (in kilometers) \n",
    "        m_dist = pdist(coordinates, # Coordinates matrix or tuples list\n",
    "               lambda u, v: geodesic(u, v).kilometers)\n",
    "        \n",
    "        dictObj['diff_distance_in_meters']= float(m_dist)* 1000.0        \n",
    "        dictObj['categories']= response_nearbySearchJSON['results'][0]['types']        \n",
    "        dictObj['obt_is_open'] = 'Not obtained'\n",
    "        dictObj['obt_hours'] = 'Not obtained'        \n",
    "    else:\n",
    "        dictObj['obt_name']= None\n",
    "        dictObj['obt_address']= None\n",
    "        dictObj['obt_city'] = None\n",
    "        dictObj['obt_state'] = None\n",
    "        dictObj['obt_latitude']= np.nan\n",
    "        dictObj['obt_longitude']= np.nan\n",
    "        dictObj['diff_distance_in_meters']= np.nan \n",
    "        dictObj['categories']= None\n",
    "        dictObj['obt_is_open'] = None\n",
    "        dictObj['obt_hours'] = None\n",
    "    print(\"Status: \", response_nearbySearchJSON['status'])  \n",
    "    listOfDicts.append(dictObj)\n",
    "    counter+=1\n",
    "    end = time.time()\n",
    "    print(\"Record num. {}\".format(counter))\n",
    "    print(\"Execution time: \", end - start, \" seconds.\")\n",
    "print(\"Successfully appended {} dictionaries\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.DataFrame(listOfDicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>obt_name</th>\n",
       "      <th>address</th>\n",
       "      <th>obt_address</th>\n",
       "      <th>city</th>\n",
       "      <th>obt_city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>obt_latitude</th>\n",
       "      <th>obt_longitude</th>\n",
       "      <th>diff_distance_in_meters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bond Street Wines</td>\n",
       "      <td>Bond Street Wines</td>\n",
       "      <td>605 Providence Rd</td>\n",
       "      <td>605 Providence Rd</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>35.201695</td>\n",
       "      <td>-80.824522</td>\n",
       "      <td>35.201689</td>\n",
       "      <td>-80.824522</td>\n",
       "      <td>6.989489e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda of South Charlotte</td>\n",
       "      <td>Mazda of South Charlotte</td>\n",
       "      <td>10515 Cadillac St</td>\n",
       "      <td>10515 Cadillac St</td>\n",
       "      <td>Pineville</td>\n",
       "      <td>Pineville</td>\n",
       "      <td>35.097067</td>\n",
       "      <td>-80.882105</td>\n",
       "      <td>35.096992</td>\n",
       "      <td>-80.881727</td>\n",
       "      <td>3.550711e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best Western Ville-Marie Montreal Hotel &amp; Suites</td>\n",
       "      <td>Best Western Ville-Marie Montreal Hotel &amp; Suites</td>\n",
       "      <td>3407 Peel St</td>\n",
       "      <td>3407 Peel St</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>45.502181</td>\n",
       "      <td>-73.576738</td>\n",
       "      <td>45.502181</td>\n",
       "      <td>-73.576738</td>\n",
       "      <td>1.110650e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Revolution Fitness Evolved</td>\n",
       "      <td>Revolution Fitness Evolved</td>\n",
       "      <td>3065 E Patrick Ln, Ste 2</td>\n",
       "      <td>3065 E Patrick Ln</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>36.078610</td>\n",
       "      <td>-115.108479</td>\n",
       "      <td>36.078136</td>\n",
       "      <td>-115.108525</td>\n",
       "      <td>5.268739e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>300 Front Street W</td>\n",
       "      <td>300 Front St W #1</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>43.644103</td>\n",
       "      <td>-79.389446</td>\n",
       "      <td>43.643979</td>\n",
       "      <td>-79.389468</td>\n",
       "      <td>1.388991e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name  \\\n",
       "0                                 Bond Street Wines   \n",
       "1                          Mazda of South Charlotte   \n",
       "2  Best Western Ville-Marie Montreal Hotel & Suites   \n",
       "3                        Revolution Fitness Evolved   \n",
       "4                                         Starbucks   \n",
       "\n",
       "                                           obt_name                   address  \\\n",
       "0                                 Bond Street Wines         605 Providence Rd   \n",
       "1                          Mazda of South Charlotte         10515 Cadillac St   \n",
       "2  Best Western Ville-Marie Montreal Hotel & Suites              3407 Peel St   \n",
       "3                        Revolution Fitness Evolved  3065 E Patrick Ln, Ste 2   \n",
       "4                                         Starbucks        300 Front Street W   \n",
       "\n",
       "         obt_address       city    obt_city   latitude   longitude  \\\n",
       "0  605 Providence Rd  Charlotte   Charlotte  35.201695  -80.824522   \n",
       "1  10515 Cadillac St  Pineville   Pineville  35.097067  -80.882105   \n",
       "2       3407 Peel St   Montreal    Montreal  45.502181  -73.576738   \n",
       "3  3065 E Patrick Ln  Las Vegas   Las Vegas  36.078610 -115.108479   \n",
       "4  300 Front St W #1    Toronto     Toronto  43.644103  -79.389446   \n",
       "\n",
       "   obt_latitude  obt_longitude  diff_distance_in_meters  \n",
       "0     35.201689     -80.824522             6.989489e-01  \n",
       "1     35.096992     -80.881727             3.550711e+01  \n",
       "2     45.502181     -73.576738             1.110650e-09  \n",
       "3     36.078136    -115.108525             5.268739e+01  \n",
       "4     43.643979     -79.389468             1.388991e+01  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset[['name', 'obt_name','address', 'obt_address' ,'city', 'obt_city', 'latitude', 'longitude', 'obt_latitude', 'obt_longitude', 'diff_distance_in_meters'  ]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
