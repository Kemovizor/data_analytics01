{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting business.json to business.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 192609 dictionaries.\n",
      "Execution time:  3.6180918216705322  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_business = []\n",
    "counter =0\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/business.json',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        listOfDicts_business.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  192609 /Users/kemalm/Desktop/yelp_dataset/business.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/business.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business_id' 'name' 'address' 'city' 'state' 'postal_code' 'latitude'\n",
      " 'longitude' 'stars' 'review_count' 'is_open' 'attributes' 'categories'\n",
      " 'hours'] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "attr_arr = np.array(['business_id', 'name', 'address', 'city', 'state', \n",
    "                     'postal_code', 'latitude', 'longitude', 'stars', \n",
    "                     'review_count', 'is_open', 'attributes', 'categories', 'hours'])\n",
    "print(attr_arr, type(attr_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">business.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192609  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['business_id' 192609.0]\n",
      " ['name' 192609.0]\n",
      " ['address' 192609.0]\n",
      " ['city' 192609.0]\n",
      " ['state' 192609.0]\n",
      " ['postal_code' 192609.0]\n",
      " ['latitude' 192609.0]\n",
      " ['longitude' 192609.0]\n",
      " ['stars' 192609.0]\n",
      " ['review_count' 192609.0]\n",
      " ['is_open' 192609.0]\n",
      " ['attributes' 192609.0]\n",
      " ['categories' 192609.0]\n",
      " ['hours' 192609.0]]\n"
     ]
    }
   ],
   "source": [
    "df_containsfield= np.zeros((len(listOfDicts_business),len(attr_arr)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_business)):\n",
    "    df_containsfield[i,:] = np.isin(attr_arr, np.array(list(listOfDicts_business[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((attr_arr.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(attr_arr)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id\n",
      "       0\n",
      "name\n",
      "       0\n",
      "address\n",
      "       0\n",
      "city\n",
      "       0\n",
      "state\n",
      "       0\n",
      "postal_code\n",
      "       0\n",
      "latitude\n",
      "       0\n",
      "longitude\n",
      "       0\n",
      "stars\n",
      "       0\n",
      "review_count\n",
      "       0\n",
      "is_open\n",
      "       0\n",
      "attributes\n",
      "   28836\n",
      "categories\n",
      "     482\n",
      "hours\n",
      "   44830\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(attr_arr):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/business.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> business.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydict(dict):\n",
    "        def __str__(self):\n",
    "            return json.dumps(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 192609 rows\n",
      "Execution time:  6.614404201507568  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/business.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,list(attr_arr), delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_business:\n",
    "        tempDict=dict(dictObj)    \n",
    "        if tempDict.get('attributes') is not None:\n",
    "            tempDict['attributes'] = mydict(tempDict['attributes']).__str__()\n",
    "        else:\n",
    "            tempDict['attributes']=\"{}\"\n",
    "            \n",
    "        if tempDict.get('hours') is not None:\n",
    "            tempDict['hours'] = mydict(tempDict['hours']).__str__()\n",
    "        else:\n",
    "            tempDict['hours']=\"{}\"\n",
    "        writer.writerow(tempDict)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting user.json to user.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 1637138 rows\n",
      "Execution time:  42.027015209198  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_user = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/user.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_user.append(json.loads(line))\n",
    "        counter+=1\n",
    "endend  = time.time()\n",
    "print(\"Successfully appended {} rows\".format(counter))\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1637138 /Users/kemalm/Desktop/yelp_dataset/user.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/user.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637138"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listOfDicts_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_user = np.array(['user_id', 'name', 'review_count', 'yelping_since', 'useful', \n",
    "                     'funny', 'cool', 'elite', 'friends', 'fans', \n",
    "                     'average_stars', 'compliment_hot', 'compliment_more', 'compliment_profile', 'compliment_cute', \n",
    "                     'compliment_list', 'compliment_note', 'compliment_plain', 'compliment_cool', 'compliment_funny', \n",
    "                     'compliment_writer', 'compliment_photos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">user.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "1637138  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['user_id' 1637138.0]\n",
      " ['name' 1637138.0]\n",
      " ['review_count' 1637138.0]\n",
      " ['yelping_since' 1637138.0]\n",
      " ['useful' 1637138.0]\n",
      " ['funny' 1637138.0]\n",
      " ['cool' 1637138.0]\n",
      " ['elite' 1637138.0]\n",
      " ['friends' 1637138.0]\n",
      " ['fans' 1637138.0]\n",
      " ['average_stars' 1637138.0]\n",
      " ['compliment_hot' 1637138.0]\n",
      " ['compliment_more' 1637138.0]\n",
      " ['compliment_profile' 1637138.0]\n",
      " ['compliment_cute' 1637138.0]\n",
      " ['compliment_list' 1637138.0]\n",
      " ['compliment_note' 1637138.0]\n",
      " ['compliment_plain' 1637138.0]\n",
      " ['compliment_cool' 1637138.0]\n",
      " ['compliment_funny' 1637138.0]\n",
      " ['compliment_writer' 1637138.0]\n",
      " ['compliment_photos' 1637138.0]]\n",
      "Execution time:  111.81420087814331  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_user),len(arr_user)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_user)):\n",
    "    df_containsfield[i,:] = np.isin(arr_user, np.array(list(listOfDicts_user[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_user.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_user)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> \n",
    "<h5 style=\"color:red;\"> WARNING! Following method works very slow for very large datasets (user.json). </h5> \n",
    "<h5 style=\"color:red;\"> Therefore, it shouldn't be run more than once. </h5> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "       0\n",
      "name\n",
      "       0\n",
      "review_count\n",
      "       0\n",
      "yelping_since\n",
      "       0\n",
      "useful\n",
      "       0\n",
      "funny\n",
      "       0\n",
      "cool\n",
      "       0\n",
      "elite\n",
      "       0\n",
      "friends\n",
      "       0\n",
      "fans\n",
      "       0\n",
      "average_stars\n",
      "       0\n",
      "compliment_hot\n",
      "       0\n",
      "compliment_more\n",
      "       0\n",
      "compliment_profile\n",
      "       0\n",
      "compliment_cute\n",
      "       0\n",
      "compliment_list\n",
      "       0\n",
      "compliment_note\n",
      "       0\n",
      "compliment_plain\n",
      "       0\n",
      "compliment_cool\n",
      "       0\n",
      "compliment_funny\n",
      "       0\n",
      "compliment_writer\n",
      "       0\n",
      "compliment_photos\n",
      "       0\n",
      "Execution time:  963.2632689476013  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_user):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/user.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> user.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 1637138 rows\n",
      "Execution time:  75.70107102394104\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/user.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,user_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_user:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1637138 yelp_dataset/user.json\n",
      "User.csv has one more row used as a header.\n",
      " 1637139 yelp_dataset/user.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l yelp_dataset/user.json\n",
    "!echo \"User.csv has one more row used as a header.\"\n",
    "!wc -l yelp_dataset/user.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting review.json to review.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 6685900 dictionaries.\n",
      "Execution time:  71.14869093894958  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_review = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/review.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_review.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6685900 /Users/kemalm/Desktop/yelp_dataset/review.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/review.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_review= np.array(['review_id', 'user_id', 'business_id', 'stars', 'useful',\n",
    "                      'funny', 'cool', 'text', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">review.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "6685900  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['review_id' 6685900.0]\n",
      " ['user_id' 6685900.0]\n",
      " ['business_id' 6685900.0]\n",
      " ['stars' 6685900.0]\n",
      " ['useful' 6685900.0]\n",
      " ['funny' 6685900.0]\n",
      " ['cool' 6685900.0]\n",
      " ['text' 6685900.0]\n",
      " ['date' 6685900.0]]\n",
      "Execution time:  299.6732749938965  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_review),len(arr_review)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_review)):\n",
    "    df_containsfield[i,:] = np.isin(arr_review, np.array(list(listOfDicts_review[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_review.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_review)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> \n",
    "<h5 style=\"color:red;\"> WARNING! Following method works very slow for very large datasets (user.json). </h5> \n",
    "<h5 style=\"color:red;\"> Therefore, it shouldn't be run more than once. </h5> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_id\n",
      "       0\n",
      "user_id\n",
      "       0\n",
      "business_id\n",
      "       0\n",
      "stars\n",
      "       0\n",
      "useful\n",
      "       0\n",
      "funny\n",
      "       0\n",
      "cool\n",
      "       0\n",
      "text\n",
      "       0\n",
      "date\n",
      "       0\n",
      "Execution time:  913.4484198093414  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_review):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/review.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date']\n"
     ]
    }
   ],
   "source": [
    "review_cols = list(arr_review)\n",
    "print(review_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> review.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 6685900 rows\n",
      "Execution time:  232.80819010734558  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/review.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,review_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_review:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting checkin.json to checkin.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 161950 dictionaries.\n",
      "Execution time:  2.0320558547973633  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_checkin = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/checkin.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_checkin.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  161950 /Users/kemalm/Desktop/yelp_dataset/checkin.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/checkin.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_checkin = np.array(['business_id', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">checkin.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "161950  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['business_id' 161950.0]\n",
      " ['date' 161950.0]]\n",
      "Execution time:  2.568455934524536  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_checkin),len(arr_checkin)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_checkin)):\n",
    "    df_containsfield[i,:] = np.isin(arr_checkin, np.array(list(listOfDicts_checkin[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_checkin.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_checkin)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id\n",
      "       0\n",
      "date\n",
      "       0\n",
      "Execution time:  14.164305925369263  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_checkin):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/checkin.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business_id', 'date']\n"
     ]
    }
   ],
   "source": [
    "checkin_cols = list(arr_checkin)\n",
    "print(checkin_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> checkin.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 161950 rows\n",
      "Execution time:  9.046382665634155  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/checkin.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,checkin_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_checkin:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  161950 yelp_dataset/checkin.json\n",
      "  161951 yelp_dataset/checkin.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l yelp_dataset/checkin.json\n",
    "!wc -l yelp_dataset/checkin.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting tip.json to tip.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 1223094 dictionaries.\n",
      "Execution time:  6.717769145965576  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_tip = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/tip.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_tip.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1223094 /Users/kemalm/Desktop/yelp_dataset/tip.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/tip.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_tip = np.array(['user_id', 'business_id', 'text', 'date', 'compliment_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">tip.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "1223094  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['user_id' 1223094.0]\n",
      " ['business_id' 1223094.0]\n",
      " ['text' 1223094.0]\n",
      " ['date' 1223094.0]\n",
      " ['compliment_count' 1223094.0]]\n",
      "Execution time:  30.554124116897583  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_tip),len(arr_tip)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_tip)):\n",
    "    df_containsfield[i,:] = np.isin(arr_tip, np.array(list(listOfDicts_tip[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_tip.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_tip)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "       0\n",
      "business_id\n",
      "       0\n",
      "text\n",
      "       0\n",
      "date\n",
      "       0\n",
      "compliment_count\n",
      "       0\n",
      "Execution time:  25.752610683441162  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_tip):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/tip.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'business_id', 'text', 'date', 'compliment_count']\n"
     ]
    }
   ],
   "source": [
    "tip_cols = list(arr_tip)\n",
    "print(tip_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> tip.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 1223094 rows\n",
      "Execution time:  8.033058166503906  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/tip.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,tip_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_tip:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting photo.json to photo.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 200000 dictionaries.\n",
      "Execution time:  0.9235949516296387  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_photo = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/photo.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_photo.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  200000 /Users/kemalm/Desktop/yelp_dataset/photo.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/photo.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_photo = np.array(['caption', 'photo_id', 'business_id', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">photo.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "200000  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['caption' 200000.0]\n",
      " ['photo_id' 200000.0]\n",
      " ['business_id' 200000.0]\n",
      " ['label' 200000.0]]\n",
      "Execution time:  4.147678852081299  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_photo),len(arr_photo)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_photo)):\n",
    "    df_containsfield[i,:] = np.isin(arr_photo, np.array(list(listOfDicts_photo[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_photo.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_photo)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption\n",
      "       0\n",
      "photo_id\n",
      "       0\n",
      "business_id\n",
      "       0\n",
      "label\n",
      "       0\n",
      "Execution time:  3.233721971511841  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_photo):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/photo.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caption', 'photo_id', 'business_id', 'label']\n"
     ]
    }
   ],
   "source": [
    "photo_cols = list(arr_photo)\n",
    "print(photo_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> photo.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e0c41b054e99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Executing the code ...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/kemalm/Desktop/yelp_dataset/photo.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphoto_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcounter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/photo.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,photo_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_photo:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python-to-PostgreSQL client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn=psycopg2.connect(\"dbname='yelpDB' user='postgres' host='localhost' password='P0$tgre$QL'\")\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "#cur.execute(\"\"\"select city,state, count(business_id)\n",
    "#                from Businesses\n",
    "#                where is_open = 1\n",
    "#                group by city,state\n",
    "#                order by 3 desc\n",
    "#                limit 10\"\"\")\n",
    "#recordsDB = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"select business_id, name, address, city, state, latitude, longitude, categories, is_open, hours\n",
    "                from Businesses\"\"\")\n",
    "recordsDB = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US/Canada states/provinces by number of businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"SELECT state,  COUNT(business_id) AS Total_Count\n",
    "               FROM Businesses\n",
    "               GROUP BY state \n",
    "               ORDER BY 2 DESC\"\"\")\n",
    "freqrecords = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Total # of businesses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ</td>\n",
       "      <td>56686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NV</td>\n",
       "      <td>36312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ON</td>\n",
       "      <td>33412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NC</td>\n",
       "      <td>14720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OH</td>\n",
       "      <td>14697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PA</td>\n",
       "      <td>11216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QC</td>\n",
       "      <td>9219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AB</td>\n",
       "      <td>8012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WI</td>\n",
       "      <td>5154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IL</td>\n",
       "      <td>1932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Total # of businesses\n",
       "0    AZ                  56686\n",
       "1    NV                  36312\n",
       "2    ON                  33412\n",
       "3    NC                  14720\n",
       "4    OH                  14697\n",
       "5    PA                  11216\n",
       "6    QC                   9219\n",
       "7    AB                   8012\n",
       "8    WI                   5154\n",
       "9    IL                   1932"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(freqrecords, columns=['State','Total # of businesses']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cities by number of businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"select city,state, count(business_id)\n",
    "               from Businesses\n",
    "               where is_open = 1\n",
    "               group by city,state\n",
    "               order by 3 desc\"\"\")\n",
    "freqrecords = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Total # of businesses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>23784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>15471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>14329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>7945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>7081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Calgary</td>\n",
       "      <td>AB</td>\n",
       "      <td>6445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>5736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Montréal</td>\n",
       "      <td>QC</td>\n",
       "      <td>5163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>AZ</td>\n",
       "      <td>5149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Henderson</td>\n",
       "      <td>NV</td>\n",
       "      <td>4026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City State  Total # of businesses\n",
       "0   Las Vegas    NV                  23784\n",
       "1     Phoenix    AZ                  15471\n",
       "2     Toronto    ON                  14329\n",
       "3   Charlotte    NC                   7945\n",
       "4  Scottsdale    AZ                   7081\n",
       "5     Calgary    AB                   6445\n",
       "6  Pittsburgh    PA                   5736\n",
       "7    Montréal    QC                   5163\n",
       "8        Mesa    AZ                   5149\n",
       "9   Henderson    NV                   4026"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(freqrecords, columns=['City','State','Total # of businesses']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Places: Sending HTTP Requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from scipy.spatial.distance import pdist\n",
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_content= !cat /Users/kemalm/Desktop/gmAPI.txt\n",
    "api_key = key_content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business_id': 0, 'name': 1, 'address': 2, 'city': 3, 'state': 4, 'latitude': 5, 'longitude': 6, 'categories': 7, 'is_open': 8, 'hours': 9}\n"
     ]
    }
   ],
   "source": [
    "fields = ['business_id','name', 'address', 'city', 'state', 'latitude', 'longitude', 'categories', 'is_open', 'hours']\n",
    "#k = np.core.defchararray.add(np.array(['obt_']),np.array(fields))\n",
    "\n",
    "#print(k)\n",
    "indices =[x for x in range(0,len(fields))]\n",
    "#print(indices)\n",
    "mapDictIndexes = dict(zip(fields,indices))\n",
    "print(mapDictIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = np.array([[0,0],\n",
    "                        [ 0, 180]])# Using the geodesic distance function.\n",
    "m_dist = pdist(coordinates, # Coordinates matrix or tuples list\n",
    "               lambda u, v: geodesic(u, v).kilometers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_lat,smpl_lng =  33.5221294, -112.0181866\n",
    "url_api_place_nearbySearch =\"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={},{}&radius=500&keyword={}&key={}\".format(\n",
    "smpl_lat,smpl_lng,'Arizona Biltmore Golf Club', api_key)\n",
    "response_api_place_nearbySearch =requests.get(url_api_place_nearbySearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json.dumps(response_api_place_nearbySearch.json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_lat,smpl_lng =  33.626171,-111.915779\n",
    "url_api_place_nearbySearch =\"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={},{}&radius=500&keyword={}&key={}\".format(\n",
    "smpl_lat,smpl_lng,'Precision Door Service', api_key)\n",
    "response_api_place_nearbySearch =requests.get(url_api_place_nearbySearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_address = '19420 N 59th Ave, Ste 13'.replace(' ','+')\n",
    "url_geocoding = \"https://maps.googleapis.com/maps/api/geocode/json?address={}&key={}\".format(smpl_address,api_key)\n",
    "response_geocoding = requests.get(url_geocoding)\n",
    "response_geocodingJSON= response_geocoding.json()\n",
    "#print(json.dumps(response_geocodingJSON))\n",
    "\n",
    "#frm_address = response_geocodingJSON['results'][0]['formatted_address']\n",
    "#frm_address.rsplit(',',4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Place Search - better method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING GROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Execution time:  1.937471866607666  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "dictBusinesses =dict()\n",
    "counter=0\n",
    "with open('/Users/kemalm/Desktop/Urls/PlaceSearchURLs.txt', mode='w',encoding='utf-8') as f:\n",
    "    for record in recordsDB:\n",
    "        business_id = record[mapDictIndexes['business_id']]\n",
    "        name = record[mapDictIndexes['name']] \n",
    "        address = record[mapDictIndexes['address']]\n",
    "        city = record[mapDictIndexes['city']]\n",
    "        state = record[mapDictIndexes['state']]\n",
    "        latitude = record[mapDictIndexes['latitude']]\n",
    "        longitude = record[mapDictIndexes['longitude']]\n",
    "        categories = record[mapDictIndexes['categories']]\n",
    "        is_open = record[mapDictIndexes['is_open']]\n",
    "        hours = record[mapDictIndexes['hours']]\n",
    "        \n",
    "        all_attrs = [name, address, city,\n",
    "                     state, latitude, longitude, categories,\n",
    "                     is_open, hours]\n",
    "        all_keys = [x for x in list(mapDictIndexes.keys()) if x is not 'business_id']\n",
    "        \n",
    "        dictBusinesses[business_id] = dict(zip(all_keys,all_attrs))\n",
    "\n",
    "        url_placeSearch =\"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={}&inputtype=textquery&locationbias=circle:500@{},{}&key={}&fields=place_id,name,formatted_address,opening_hours,geometry,types\".format(\n",
    "        name,latitude,longitude, api_key)\n",
    "        \n",
    "        f.write(business_id+' | '+url_placeSearch+'\\n')\n",
    "        \n",
    "    \n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HandlingRequest(record):\n",
    "    dictObj=dict()\n",
    "    \n",
    "    business_name = record[mapDictIndexes['name']] \n",
    "    business_address = record[mapDictIndexes['address']]\n",
    "    business_latitude = record[mapDictIndexes['latitude']]\n",
    "    business_longitude = record[mapDictIndexes['longitude']]\n",
    "    \n",
    "    dictObj['business_id'] = record[mapDictIndexes['business_id']] \n",
    "    dictObj['name']= record[mapDictIndexes['name']]\n",
    "    dictObj['address']= record[mapDictIndexes['address']]\n",
    "    dictObj['city']= record[mapDictIndexes['city']]\n",
    "    dictObj['state']= record[mapDictIndexes['state']]\n",
    "    dictObj['latitude']= record[mapDictIndexes['latitude']]\n",
    "    dictObj['longitude']= record[mapDictIndexes['longitude']]\n",
    "    dictObj['categories']= record[mapDictIndexes['categories']]\n",
    "    dictObj['is_open']= record[mapDictIndexes['is_open']]\n",
    "    dictObj['hours']= record[mapDictIndexes['hours']]\n",
    "     \n",
    "    #generating an url to find whether there is a business in radius of 500 meters centered around geo coordinates we previously obtained\n",
    "    url_placeSearch =\"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={}&inputtype=textquery&locationbias=circle:500@{},{}&key={}&fields=place_id,name,formatted_address,opening_hours,geometry,types\".format(\n",
    "    business_name,business_latitude,business_longitude, api_key)\n",
    "   \n",
    "    #http request\n",
    "    response_placeSearch =requests.get(url_placeSearch)\n",
    "    \n",
    "    #converting to json (type:dict)\n",
    "    response_placeSearchJSON= response_placeSearch.json()\n",
    "    \n",
    "    #with open('/Users/kemalm/Desktop/NearbySearch.json', mode='a', encoding='utf-8') as ns_jsonFile:\n",
    "    #    ns_jsonFile.write(json.dumps(response_nearbySearchJSON)+\"\\n\")\n",
    "        #json.dump(response_nearbySearchJSON,ns_jsonFile)\n",
    "    \n",
    "    dictObj['status_request_PS'] = response_placeSearchJSON['status']\n",
    "    if(response_placeSearchJSON['status']=='OK'):\n",
    "        \n",
    "        place_id = response_placeSearchJSON['candidates'][0]['place_id']\n",
    "        dictObj['obt_name']= response_placeSearchJSON['candidates'][0]['name']\n",
    "\n",
    "        #params= response_placeSearchJSON['candidates'][0]['formatted_address'].split(', ',3)\n",
    "        dictObj['formatted_address'] = response_placeSearchJSON['candidates'][0]['formatted_address']\n",
    "        #dictObj['obt_address'] = \"Still working on it\" #params[0]\n",
    "        #dictObj['obt_city'] = \"Still working on it\"#params[1]\n",
    "        #dictObj['obt_state']= \"Still working on it\"#params[2].split(' ')[0]\n",
    "        \n",
    "        #dictObj['obt_state'] = stDictLongToShort[st_temp]\n",
    "        obt_lat,obt_lng =response_placeSearchJSON['candidates'][0]['geometry']['location']['lat'], response_placeSearchJSON['candidates'][0]['geometry']['location']['lng']\n",
    "        dictObj['obt_latitude']= obt_lat\n",
    "        dictObj['obt_longitude']= obt_lng\n",
    "           \n",
    "        #generating matrix of geo coordinates\n",
    "        coordinates=np.array([[business_latitude, business_longitude],[obt_lat,obt_lng]])\n",
    "        #executing pdist function to calculate distance between spherical points (in kilometers) \n",
    "        m_dist = pdist(coordinates, # Coordinates matrix or tuples list\n",
    "               lambda u, v: geodesic(u, v).kilometers)\n",
    "        \n",
    "        dictObj['calc_distance']= float(m_dist)* 1000.0\n",
    "        listTypes = response_placeSearchJSON['candidates'][0]['types']\n",
    "        strTypes =\", \".join(listTypes)\n",
    "        dictObj['obt_categories']= strTypes\n",
    "        \n",
    "        \n",
    "    \n",
    "        url_placeDetails = \"https://maps.googleapis.com/maps/api/place/details/json?key={}&place_id={}&fields=opening_hours\".format(\n",
    "        api_key,place_id)\n",
    "        response_placeDetails = requests.get(url_placeDetails)\n",
    "        response_placeDetailsJSON = response_placeDetails.json()\n",
    "        \n",
    "        dictObj['status_request_PD'] = response_placeDetailsJSON['status']\n",
    "        \n",
    "        if(response_placeDetailsJSON['status']=='OK'):\n",
    "            if('opening_hours' in response_placeDetailsJSON['result'].keys()):\n",
    "                dictObj['obt_is_open']= int(response_placeDetailsJSON['result']['opening_hours']['open_now'])\n",
    "                listHours= response_placeDetailsJSON['result']['opening_hours']['weekday_text']               \n",
    "                dictHours = dict()\n",
    "                for elem in listHours:\n",
    "                    items =elem.rsplit(\": \",2)\n",
    "                    dictHours[items[0]]=items[1]\n",
    "                dictObj['obt_hours'] = dictHours\n",
    "            else:\n",
    "                dictObj['obt_hours'] =dict()\n",
    "    else:\n",
    "        dictObj['obt_hours'] =dict()               \n",
    "    return dictObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "None: Max retries exceeded with url: /maps/api/place/details/json?key=AIzaSyC70mAg4ukA_wduRV2sreHz_ExWuyc_djA&place_id=ChIJd51DBeFYNIgRF6Zp63YbC_c&fields=opening_hours (Caused by None)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\", line 453, in wrap_socket\n    cnx.do_handshake()\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\", line 1907, in do_handshake\n    self._raise_ssl_error(self._ssl, result)\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\", line 1632, in _raise_ssl_error\n    raise SysCallError(-1, \"Unexpected EOF\")\nOpenSSL.SSL.SysCallError: (-1, 'Unexpected EOF')\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n    chunked=chunked)\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 343, in _make_request\n    self._validate_conn(conn)\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 839, in _validate_conn\n    conn.connect()\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/urllib3/connection.py\", line 344, in connect\n    ssl_context=context)\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/urllib3/util/ssl_.py\", line 344, in ssl_wrap_socket\n    return context.wrap_socket(sock, server_hostname=server_hostname)\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\", line 459, in wrap_socket\n    raise ssl.SSLError('bad handshake: %r' % e)\nssl.SSLError: (\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\n    timeout=timeout\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 638, in urlopen\n    _stacktrace=sys.exc_info()[2])\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/urllib3/util/retry.py\", line 398, in increment\n    raise MaxRetryError(_pool, url, error or ResponseError(cause))\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/place/details/json?key=AIzaSyC70mAg4ukA_wduRV2sreHz_ExWuyc_djA&place_id=ChIJd51DBeFYNIgRF6Zp63YbC_c&fields=opening_hours (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/kemalm/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/kemalm/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-9-aad9b293ba0e>\", line 66, in HandlingRequest\n    response_placeDetails = requests.get(url_placeDetails)\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/requests/api.py\", line 75, in get\n    return request('get', url, params=params, **kwargs)\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/requests/api.py\", line 60, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 533, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n    r = adapter.send(request, **kwargs)\n  File \"/Users/kemalm/anaconda3/lib/python3.7/site-packages/requests/adapters.py\", line 514, in send\n    raise SSLError(e, request=request)\nrequests.exceptions.SSLError: HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/place/details/json?key=AIzaSyC70mAg4ukA_wduRV2sreHz_ExWuyc_djA&place_id=ChIJd51DBeFYNIgRF6Zp63YbC_c&fields=opening_hours (Caused by SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\")))\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d92af05eee17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#listOfDicts=pool.map(HandlingRequest, recordsDB[0:10000])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlistOfDicts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHandlingRequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecordsDB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#pool.close()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         '''\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSSLError\u001b[0m: None: Max retries exceeded with url: /maps/api/place/details/json?key=AIzaSyC70mAg4ukA_wduRV2sreHz_ExWuyc_djA&place_id=ChIJd51DBeFYNIgRF6Zp63YbC_c&fields=opening_hours (Caused by None)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import multiprocessing\n",
    "import time as time\n",
    "\n",
    "start = time.time()\n",
    "listOfDicts = list()\n",
    "with multiprocessing.Pool(processes=180) as pool:\n",
    "    #listOfDicts=pool.map(HandlingRequest, recordsDB[0:10000])\n",
    "    listOfDicts=pool.map(HandlingRequest, recordsDB)\n",
    "#pool.close()\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.DataFrame(listOfDicts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listOfDicts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfDicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
