{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting business.json to business.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 192609 dictionaries.\n",
      "Execution time:  3.6180918216705322  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_business = []\n",
    "counter =0\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/business.json',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        listOfDicts_business.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  192609 /Users/kemalm/Desktop/yelp_dataset/business.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/business.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business_id' 'name' 'address' 'city' 'state' 'postal_code' 'latitude'\n",
      " 'longitude' 'stars' 'review_count' 'is_open' 'attributes' 'categories'\n",
      " 'hours'] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "attr_arr = np.array(['business_id', 'name', 'address', 'city', 'state', \n",
    "                     'postal_code', 'latitude', 'longitude', 'stars', \n",
    "                     'review_count', 'is_open', 'attributes', 'categories', 'hours'])\n",
    "print(attr_arr, type(attr_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">business.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192609  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['business_id' 192609.0]\n",
      " ['name' 192609.0]\n",
      " ['address' 192609.0]\n",
      " ['city' 192609.0]\n",
      " ['state' 192609.0]\n",
      " ['postal_code' 192609.0]\n",
      " ['latitude' 192609.0]\n",
      " ['longitude' 192609.0]\n",
      " ['stars' 192609.0]\n",
      " ['review_count' 192609.0]\n",
      " ['is_open' 192609.0]\n",
      " ['attributes' 192609.0]\n",
      " ['categories' 192609.0]\n",
      " ['hours' 192609.0]]\n"
     ]
    }
   ],
   "source": [
    "df_containsfield= np.zeros((len(listOfDicts_business),len(attr_arr)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_business)):\n",
    "    df_containsfield[i,:] = np.isin(attr_arr, np.array(list(listOfDicts_business[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((attr_arr.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(attr_arr)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id\n",
      "       0\n",
      "name\n",
      "       0\n",
      "address\n",
      "       0\n",
      "city\n",
      "       0\n",
      "state\n",
      "       0\n",
      "postal_code\n",
      "       0\n",
      "latitude\n",
      "       0\n",
      "longitude\n",
      "       0\n",
      "stars\n",
      "       0\n",
      "review_count\n",
      "       0\n",
      "is_open\n",
      "       0\n",
      "attributes\n",
      "   28836\n",
      "categories\n",
      "     482\n",
      "hours\n",
      "   44830\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(attr_arr):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/business.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> business.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydict(dict):\n",
    "        def __str__(self):\n",
    "            return json.dumps(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 192609 rows\n",
      "Execution time:  6.614404201507568  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/business.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,list(attr_arr), delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_business:\n",
    "        tempDict=dict(dictObj)    \n",
    "        if tempDict.get('attributes') is not None:\n",
    "            tempDict['attributes'] = mydict(tempDict['attributes']).__str__()\n",
    "        else:\n",
    "            tempDict['attributes']=\"{}\"\n",
    "            \n",
    "        if tempDict.get('hours') is not None:\n",
    "            tempDict['hours'] = mydict(tempDict['hours']).__str__()\n",
    "        else:\n",
    "            tempDict['hours']=\"{}\"\n",
    "        writer.writerow(tempDict)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting user.json to user.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 1637138 rows\n",
      "Execution time:  42.027015209198  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_user = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/user.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_user.append(json.loads(line))\n",
    "        counter+=1\n",
    "endend  = time.time()\n",
    "print(\"Successfully appended {} rows\".format(counter))\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1637138 /Users/kemalm/Desktop/yelp_dataset/user.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/user.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637138"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listOfDicts_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_user = np.array(['user_id', 'name', 'review_count', 'yelping_since', 'useful', \n",
    "                     'funny', 'cool', 'elite', 'friends', 'fans', \n",
    "                     'average_stars', 'compliment_hot', 'compliment_more', 'compliment_profile', 'compliment_cute', \n",
    "                     'compliment_list', 'compliment_note', 'compliment_plain', 'compliment_cool', 'compliment_funny', \n",
    "                     'compliment_writer', 'compliment_photos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">user.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "1637138  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['user_id' 1637138.0]\n",
      " ['name' 1637138.0]\n",
      " ['review_count' 1637138.0]\n",
      " ['yelping_since' 1637138.0]\n",
      " ['useful' 1637138.0]\n",
      " ['funny' 1637138.0]\n",
      " ['cool' 1637138.0]\n",
      " ['elite' 1637138.0]\n",
      " ['friends' 1637138.0]\n",
      " ['fans' 1637138.0]\n",
      " ['average_stars' 1637138.0]\n",
      " ['compliment_hot' 1637138.0]\n",
      " ['compliment_more' 1637138.0]\n",
      " ['compliment_profile' 1637138.0]\n",
      " ['compliment_cute' 1637138.0]\n",
      " ['compliment_list' 1637138.0]\n",
      " ['compliment_note' 1637138.0]\n",
      " ['compliment_plain' 1637138.0]\n",
      " ['compliment_cool' 1637138.0]\n",
      " ['compliment_funny' 1637138.0]\n",
      " ['compliment_writer' 1637138.0]\n",
      " ['compliment_photos' 1637138.0]]\n",
      "Execution time:  111.81420087814331  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_user),len(arr_user)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_user)):\n",
    "    df_containsfield[i,:] = np.isin(arr_user, np.array(list(listOfDicts_user[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_user.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_user)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> \n",
    "<h5 style=\"color:red;\"> WARNING! Following method works very slow for very large datasets (user.json). </h5> \n",
    "<h5 style=\"color:red;\"> Therefore, it shouldn't be run more than once. </h5> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "       0\n",
      "name\n",
      "       0\n",
      "review_count\n",
      "       0\n",
      "yelping_since\n",
      "       0\n",
      "useful\n",
      "       0\n",
      "funny\n",
      "       0\n",
      "cool\n",
      "       0\n",
      "elite\n",
      "       0\n",
      "friends\n",
      "       0\n",
      "fans\n",
      "       0\n",
      "average_stars\n",
      "       0\n",
      "compliment_hot\n",
      "       0\n",
      "compliment_more\n",
      "       0\n",
      "compliment_profile\n",
      "       0\n",
      "compliment_cute\n",
      "       0\n",
      "compliment_list\n",
      "       0\n",
      "compliment_note\n",
      "       0\n",
      "compliment_plain\n",
      "       0\n",
      "compliment_cool\n",
      "       0\n",
      "compliment_funny\n",
      "       0\n",
      "compliment_writer\n",
      "       0\n",
      "compliment_photos\n",
      "       0\n",
      "Execution time:  963.2632689476013  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_user):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/user.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> user.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 1637138 rows\n",
      "Execution time:  75.70107102394104\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/user.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,user_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_user:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1637138 yelp_dataset/user.json\n",
      "User.csv has one more row used as a header.\n",
      " 1637139 yelp_dataset/user.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l yelp_dataset/user.json\n",
    "!echo \"User.csv has one more row used as a header.\"\n",
    "!wc -l yelp_dataset/user.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting review.json to review.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 6685900 dictionaries.\n",
      "Execution time:  71.14869093894958  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_review = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/review.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_review.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6685900 /Users/kemalm/Desktop/yelp_dataset/review.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/review.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_review= np.array(['review_id', 'user_id', 'business_id', 'stars', 'useful',\n",
    "                      'funny', 'cool', 'text', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">review.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "6685900  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['review_id' 6685900.0]\n",
      " ['user_id' 6685900.0]\n",
      " ['business_id' 6685900.0]\n",
      " ['stars' 6685900.0]\n",
      " ['useful' 6685900.0]\n",
      " ['funny' 6685900.0]\n",
      " ['cool' 6685900.0]\n",
      " ['text' 6685900.0]\n",
      " ['date' 6685900.0]]\n",
      "Execution time:  299.6732749938965  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_review),len(arr_review)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_review)):\n",
    "    df_containsfield[i,:] = np.isin(arr_review, np.array(list(listOfDicts_review[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_review.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_review)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> \n",
    "<h5 style=\"color:red;\"> WARNING! Following method works very slow for very large datasets (user.json). </h5> \n",
    "<h5 style=\"color:red;\"> Therefore, it shouldn't be run more than once. </h5> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_id\n",
      "       0\n",
      "user_id\n",
      "       0\n",
      "business_id\n",
      "       0\n",
      "stars\n",
      "       0\n",
      "useful\n",
      "       0\n",
      "funny\n",
      "       0\n",
      "cool\n",
      "       0\n",
      "text\n",
      "       0\n",
      "date\n",
      "       0\n",
      "Execution time:  913.4484198093414  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_review):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/review.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date']\n"
     ]
    }
   ],
   "source": [
    "review_cols = list(arr_review)\n",
    "print(review_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> review.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 6685900 rows\n",
      "Execution time:  232.80819010734558  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/review.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,review_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_review:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting checkin.json to checkin.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 161950 dictionaries.\n",
      "Execution time:  2.0320558547973633  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_checkin = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/checkin.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_checkin.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  161950 /Users/kemalm/Desktop/yelp_dataset/checkin.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/checkin.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_checkin = np.array(['business_id', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">checkin.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "161950  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['business_id' 161950.0]\n",
      " ['date' 161950.0]]\n",
      "Execution time:  2.568455934524536  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_checkin),len(arr_checkin)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_checkin)):\n",
    "    df_containsfield[i,:] = np.isin(arr_checkin, np.array(list(listOfDicts_checkin[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_checkin.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_checkin)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id\n",
      "       0\n",
      "date\n",
      "       0\n",
      "Execution time:  14.164305925369263  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_checkin):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/checkin.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business_id', 'date']\n"
     ]
    }
   ],
   "source": [
    "checkin_cols = list(arr_checkin)\n",
    "print(checkin_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> checkin.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 161950 rows\n",
      "Execution time:  9.046382665634155  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/checkin.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,checkin_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_checkin:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  161950 yelp_dataset/checkin.json\n",
      "  161951 yelp_dataset/checkin.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l yelp_dataset/checkin.json\n",
    "!wc -l yelp_dataset/checkin.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting tip.json to tip.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 1223094 dictionaries.\n",
      "Execution time:  6.717769145965576  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_tip = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/tip.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_tip.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1223094 /Users/kemalm/Desktop/yelp_dataset/tip.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/tip.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_tip = np.array(['user_id', 'business_id', 'text', 'date', 'compliment_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">tip.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "1223094  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['user_id' 1223094.0]\n",
      " ['business_id' 1223094.0]\n",
      " ['text' 1223094.0]\n",
      " ['date' 1223094.0]\n",
      " ['compliment_count' 1223094.0]]\n",
      "Execution time:  30.554124116897583  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_tip),len(arr_tip)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_tip)):\n",
    "    df_containsfield[i,:] = np.isin(arr_tip, np.array(list(listOfDicts_tip[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_tip.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_tip)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "       0\n",
      "business_id\n",
      "       0\n",
      "text\n",
      "       0\n",
      "date\n",
      "       0\n",
      "compliment_count\n",
      "       0\n",
      "Execution time:  25.752610683441162  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_tip):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/tip.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'business_id', 'text', 'date', 'compliment_count']\n"
     ]
    }
   ],
   "source": [
    "tip_cols = list(arr_tip)\n",
    "print(tip_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> tip.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 1223094 rows\n",
      "Execution time:  8.033058166503906  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/tip.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,tip_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_tip:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting photo.json to photo.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 200000 dictionaries.\n",
      "Execution time:  0.9235949516296387  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_photo = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/photo.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_photo.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  200000 /Users/kemalm/Desktop/yelp_dataset/photo.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/photo.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_photo = np.array(['caption', 'photo_id', 'business_id', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">photo.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "200000  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['caption' 200000.0]\n",
      " ['photo_id' 200000.0]\n",
      " ['business_id' 200000.0]\n",
      " ['label' 200000.0]]\n",
      "Execution time:  4.147678852081299  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_photo),len(arr_photo)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_photo)):\n",
    "    df_containsfield[i,:] = np.isin(arr_photo, np.array(list(listOfDicts_photo[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_photo.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_photo)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption\n",
      "       0\n",
      "photo_id\n",
      "       0\n",
      "business_id\n",
      "       0\n",
      "label\n",
      "       0\n",
      "Execution time:  3.233721971511841  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_photo):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/photo.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caption', 'photo_id', 'business_id', 'label']\n"
     ]
    }
   ],
   "source": [
    "photo_cols = list(arr_photo)\n",
    "print(photo_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> photo.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e0c41b054e99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Executing the code ...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/kemalm/Desktop/yelp_dataset/photo.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphoto_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcounter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/photo.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,photo_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_photo:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python-to-PostgreSQL client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn=psycopg2.connect(\"dbname='yelpDB' user='postgres' host='localhost' password='P0$tgre$QL'\")\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "#cur.execute(\"\"\"select city,state, count(business_id)\n",
    "#                from Businesses\n",
    "#                where is_open = 1\n",
    "#                group by city,state\n",
    "#                order by 3 desc\n",
    "#                limit 10\"\"\")\n",
    "#recordsDB = cur.fetchall()\n",
    "cur.execute(\"\"\"\n",
    "            SELECT *\n",
    "            FROM information_schema.columns\n",
    "            WHERE table_schema = 'public'\n",
    "          AND table_name   = 'Businesses'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"SELECT 'business_id', COUNT(*) -COUNT(business_id) As business_id_counter_counter, \t\t\n",
    "\t\t\t 'name',COUNT(*)-COUNT(name) As name_counter_counter,\n",
    "\t\t\t 'address',COUNT(*)-COUNT(address) As address_counter,\n",
    "\t\t\t 'city',COUNT(*)-COUNT(city) As city_counter,\n",
    "\t\t\t 'state',COUNT(*)-COUNT(state) As state_counter,\n",
    "\t\t\t 'postal_code',COUNT(*)-COUNT(postal_code) As postal_code_counter,\n",
    "\t\t\t 'latitude',COUNT(*)-COUNT(latitude) As latitude_counter,\n",
    "\t\t\t 'longitude',COUNT(*)-COUNT(longitude) As longitude_counter,\n",
    "\t\t\t 'stars',COUNT(*)-COUNT(stars) As stars_counter,\n",
    "\t\t\t 'review_count',COUNT(*)-COUNT(review_count) As review_count_counter,\n",
    "\t\t\t 'is_open',COUNT(*)-COUNT(is_open) As is_open_counter,\n",
    "\t\t\t 'attributes',COUNT(*)-( SELECT COUNT(attributes) \n",
    "\t\t\t \t\t\t\tFROM Businesses \n",
    "\t\t\t \t\t\t\tWHERE attributes <> '{}' )  As attributes_counter,\n",
    "\t\t\t'categories',COUNT(*)-COUNT(categories) As categories_counter,\n",
    "\t\t\t 'hours',COUNT(*)-( SELECT COUNT(hours) \n",
    "\t\t\t\t  \tFROM Businesses \n",
    "\t\t\t\t    WHERE hours <> '{}' )  As hours_counter\n",
    "FROM Businesses;\"\"\")\n",
    "recordsDB = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('business_id',\n",
       "  0,\n",
       "  'name',\n",
       "  0,\n",
       "  'address',\n",
       "  0,\n",
       "  'city',\n",
       "  0,\n",
       "  'state',\n",
       "  0,\n",
       "  'postal_code',\n",
       "  0,\n",
       "  'latitude',\n",
       "  0,\n",
       "  'longitude',\n",
       "  0,\n",
       "  'stars',\n",
       "  0,\n",
       "  'review_count',\n",
       "  0,\n",
       "  'is_open',\n",
       "  0,\n",
       "  'attributes',\n",
       "  28836,\n",
       "  'categories',\n",
       "  482,\n",
       "  'hours',\n",
       "  44830)]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordsDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US/Canada states/provinces by number of businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"SELECT state,  COUNT(business_id) AS Total_Count\n",
    "               FROM Businesses\n",
    "               WHERE is_open = 1\n",
    "               GROUP BY state \n",
    "               ORDER BY 2 DESC\"\"\")\n",
    "freqrecords = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Total # of businesses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ</td>\n",
       "      <td>46910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NV</td>\n",
       "      <td>29562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ON</td>\n",
       "      <td>26525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>12546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NC</td>\n",
       "      <td>12419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PA</td>\n",
       "      <td>9430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QC</td>\n",
       "      <td>7623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AB</td>\n",
       "      <td>6694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WI</td>\n",
       "      <td>4210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IL</td>\n",
       "      <td>1545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Total # of businesses\n",
       "0    AZ                  46910\n",
       "1    NV                  29562\n",
       "2    ON                  26525\n",
       "3    OH                  12546\n",
       "4    NC                  12419\n",
       "5    PA                   9430\n",
       "6    QC                   7623\n",
       "7    AB                   6694\n",
       "8    WI                   4210\n",
       "9    IL                   1545"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(freqrecords, columns=['State','Total # of businesses']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cities by number of businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"select city,state, count(business_id)\n",
    "               from Businesses\n",
    "               where is_open = 1\n",
    "               group by city,state\n",
    "               order by 3 desc\"\"\")\n",
    "freqrecords = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Total # of businesses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>23784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>15471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>14329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>7945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>7081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Calgary</td>\n",
       "      <td>AB</td>\n",
       "      <td>6445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>5736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Montr√©al</td>\n",
       "      <td>QC</td>\n",
       "      <td>5163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>AZ</td>\n",
       "      <td>5149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Henderson</td>\n",
       "      <td>NV</td>\n",
       "      <td>4026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City State  Total # of businesses\n",
       "0   Las Vegas    NV                  23784\n",
       "1     Phoenix    AZ                  15471\n",
       "2     Toronto    ON                  14329\n",
       "3   Charlotte    NC                   7945\n",
       "4  Scottsdale    AZ                   7081\n",
       "5     Calgary    AB                   6445\n",
       "6  Pittsburgh    PA                   5736\n",
       "7    Montr√©al    QC                   5163\n",
       "8        Mesa    AZ                   5149\n",
       "9   Henderson    NV                   4026"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(freqrecords, columns=['City','State','Total # of businesses']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Places: Sending HTTP Requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from scipy.spatial.distance import pdist\n",
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_content= !cat /Users/kemalm/Desktop/gmAPI.txt\n",
    "api_key = key_content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business_id': 0, 'name': 1, 'address': 2, 'city': 3, 'state': 4, 'latitude': 5, 'longitude': 6, 'categories': 7, 'is_open': 8, 'hours': 9}\n"
     ]
    }
   ],
   "source": [
    "fields = ['business_id','name', 'address', 'city', 'state', 'latitude', 'longitude', 'categories', 'is_open', 'hours']\n",
    "#k = np.core.defchararray.add(np.array(['obt_']),np.array(fields))\n",
    "\n",
    "#print(k)\n",
    "indices =[x for x in range(0,len(fields))]\n",
    "#print(indices)\n",
    "mapDictIndexes = dict(zip(fields,indices))\n",
    "print(mapDictIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = np.array([[0,0],\n",
    "                        [ 0, 180]])# Using the geodesic distance function.\n",
    "m_dist = pdist(coordinates, # Coordinates matrix or tuples list\n",
    "               lambda u, v: geodesic(u, v).kilometers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_lat,smpl_lng =  33.5221294, -112.0181866\n",
    "url_api_place_nearbySearch =\"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={},{}&radius=500&keyword={}&key={}\".format(\n",
    "smpl_lat,smpl_lng,'Arizona Biltmore Golf Club', api_key)\n",
    "response_api_place_nearbySearch =requests.get(url_api_place_nearbySearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json.dumps(response_api_place_nearbySearch.json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_lat,smpl_lng =  33.626171,-111.915779\n",
    "url_api_place_nearbySearch =\"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={},{}&radius=500&keyword={}&key={}\".format(\n",
    "smpl_lat,smpl_lng,'Precision Door Service', api_key)\n",
    "response_api_place_nearbySearch =requests.get(url_api_place_nearbySearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_address = \"1705 S. Greenfield Road, 101\"\n",
    "url_geocoding = \"https://maps.googleapis.com/maps/api/geocode/json?address={}&key={}\".format(smpl_address,api_key)\n",
    "response_geocoding = requests.get(url_geocoding)\n",
    "response_geocodingJSON= response_geocoding.json()\n",
    "#print(json.dumps(response_geocodingJSON))\n",
    "\n",
    "#frm_address = response_geocodingJSON['results'][0]['formatted_address']\n",
    "#frm_address.rsplit(',',4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_address = '19420 N 59th Ave #, Ste 13'.replace(' ','+')\n",
    "url_geocoding = \"https://maps.googleapis.com/maps/api/geocode/json?address={}&key={}\".format(smpl_address,api_key)\n",
    "response_geocoding = requests.get(url_geocoding)\n",
    "response_geocodingJSON= response_geocoding.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from scipy.spatial.distance import pdist\n",
    "from geopy.distance import geodesic\n",
    "import random as rn\n",
    "import json\n",
    "\n",
    "try:\n",
    "    conn=psycopg2.connect(\"dbname='yelpDB' user='postgres' host='localhost' password='P0$tgre$QL'\")\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"select business_id, name, address, city, state, latitude, longitude, categories\n",
    "                from Businesses\"\"\")\n",
    "recordsDB = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192609"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recordsDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business_id': 0, 'name': 1, 'address': 2, 'city': 3, 'state': 4, 'latitude': 5, 'longitude': 6, 'categories': 7}\n"
     ]
    }
   ],
   "source": [
    "key_content= !cat /Users/kemalm/Desktop/gmAPI.txt\n",
    "api_key = key_content[0]\n",
    "fields = ['business_id','name', 'address', 'city', 'state', 'latitude', 'longitude', 'categories']\n",
    "#k = np.core.defchararray.add(np.array(['obt_']),np.array(fields))\n",
    "\n",
    "#print(k)\n",
    "indices =[x for x in range(0,len(fields))]\n",
    "#print(indices)\n",
    "mapDictIndexes = dict(zip(fields,indices))\n",
    "print(mapDictIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeocodingRequestHandling(record):\n",
    "    dictObj=dict()\n",
    "    \n",
    "    business_name = record[mapDictIndexes['name']] \n",
    "    business_address = record[mapDictIndexes['address']]\n",
    "    business_latitude = record[mapDictIndexes['latitude']]\n",
    "    business_longitude = record[mapDictIndexes['longitude']]\n",
    "    \n",
    "    dictObj['business_id'] = record[mapDictIndexes['business_id']] \n",
    "    dictObj['name']= business_name\n",
    "    dictObj['address']= business_address\n",
    "    dictObj['city']= record[mapDictIndexes['city']]\n",
    "    dictObj['state']= record[mapDictIndexes['state']]\n",
    "    dictObj['latitude']= business_latitude\n",
    "    dictObj['longitude']= business_longitude\n",
    "    dictObj['categories']= record[mapDictIndexes['categories']]\n",
    "    #dictObj['is_open']= record[mapDictIndexes['is_open']]\n",
    "     \n",
    "    if(business_address !=''):\n",
    "        url_geocoding =\"https://maps.googleapis.com/maps/api/geocode/json?address={}&sensor=true&key={}\".format(\n",
    "        business_address,api_key)\n",
    "        resp =requests.get(url_geocoding)\n",
    "        resp_dict= resp.json()\n",
    "        dictObj['geocoding_status'] = resp_dict['status']\n",
    "        if(dictObj['geocoding_status']=='OK'):\n",
    "            GeocodingFunc(dictObj,resp_dict)\n",
    "    \n",
    "    url_invgeocoding = \"https://maps.googleapis.com/maps/api/geocode/json?latlng={},{}&key={}\".format(\n",
    "        business_latitude,business_longitude,api_key)\n",
    "    resp =requests.get(url_invgeocoding)\n",
    "    resp_dict= resp.json()\n",
    "    dictObj['invgeocoding_status'] = resp_dict['status']\n",
    "    if(dictObj['invgeocoding_status']=='OK'):\n",
    "        InvGeocodingFunc(dictObj, resp_dict)\n",
    "    \n",
    "    return dictObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeocodingFunc(dictObj,resp_dict):\n",
    "    dictObj['latitude_from_address']= resp_dict['results'][0]['geometry']['location']['lat']\n",
    "    dictObj['longitude_from_address']= resp_dict['results'][0]['geometry']['location']['lng']\n",
    "    #dictObj['formatted_address_from_address'] = response_placeSearchJSON['results'][0]['formatted_address']\n",
    "    coordinates=np.array([[dictObj['latitude'], dictObj['longitude']],\n",
    "                          [dictObj['latitude_from_address'],dictObj['longitude_from_address']]])    \n",
    "    m_dist = pdist(coordinates, # Coordinates matrix or tuples list\n",
    "           lambda u, v: geodesic(u, v).kilometers)\n",
    "    dictObj['dist_diff']= float(m_dist)* 1000.0\n",
    "    dictObj['place_id_from_address']= resp_dict['results'][0]['place_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InvGeocodingFunc(dictObj,resp_dict):\n",
    "    dictObj['formatted_address_from_coord'] = resp_dict['results'][0]['formatted_address']    \n",
    "    dictObj['address_components_from_coord'] = resp_dict['results'][0]['address_components']  \n",
    "    dictObj['place_id_from_coord']= resp_dict['results'][0]['place_id']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 100 rows. In total 100\n",
      "Execution time:  15.795691967010498  seconds.\n",
      "Appended 100 rows. In total 200\n",
      "Execution time:  32.00659203529358  seconds.\n",
      "Appended 100 rows. In total 300\n",
      "Execution time:  48.9500470161438  seconds.\n",
      "Appended 100 rows. In total 400\n",
      "Execution time:  64.60181403160095  seconds.\n",
      "Appended 100 rows. In total 500\n",
      "Execution time:  80.37112879753113  seconds.\n",
      "Appended 100 rows. In total 600\n",
      "Execution time:  95.18814992904663  seconds.\n",
      "Appended 100 rows. In total 700\n",
      "Execution time:  111.17470383644104  seconds.\n",
      "Appended 100 rows. In total 800\n",
      "Execution time:  125.73102593421936  seconds.\n",
      "Appended 100 rows. In total 900\n",
      "Execution time:  141.76359391212463  seconds.\n",
      "Appended 100 rows. In total 1000\n",
      "Execution time:  156.80530095100403  seconds.\n",
      "Appended 100 rows. In total 1100\n",
      "Execution time:  171.58871293067932  seconds.\n",
      "Appended 100 rows. In total 1200\n",
      "Execution time:  187.241938829422  seconds.\n",
      "Appended 100 rows. In total 1300\n",
      "Execution time:  202.5680377483368  seconds.\n",
      "Appended 100 rows. In total 1400\n",
      "Execution time:  216.77816605567932  seconds.\n",
      "Appended 100 rows. In total 1500\n",
      "Execution time:  231.94861268997192  seconds.\n",
      "Appended 100 rows. In total 1600\n",
      "Execution time:  247.23677372932434  seconds.\n",
      "Appended 100 rows. In total 1700\n",
      "Execution time:  262.8335428237915  seconds.\n",
      "Appended 100 rows. In total 1800\n",
      "Execution time:  278.169939994812  seconds.\n",
      "Appended 100 rows. In total 1900\n",
      "Execution time:  293.51794481277466  seconds.\n",
      "Appended 100 rows. In total 2000\n",
      "Execution time:  307.56024384498596  seconds.\n",
      "Appended 100 rows. In total 2100\n",
      "Execution time:  323.906222820282  seconds.\n",
      "Appended 100 rows. In total 2200\n",
      "Execution time:  339.32849192619324  seconds.\n",
      "Appended 100 rows. In total 2300\n",
      "Execution time:  355.2178008556366  seconds.\n",
      "Appended 100 rows. In total 2400\n",
      "Execution time:  370.4978668689728  seconds.\n",
      "Appended 100 rows. In total 2500\n",
      "Execution time:  384.8549189567566  seconds.\n",
      "Appended 100 rows. In total 2600\n",
      "Execution time:  400.68819975852966  seconds.\n",
      "Appended 100 rows. In total 2700\n",
      "Execution time:  416.2079849243164  seconds.\n",
      "Appended 100 rows. In total 2800\n",
      "Execution time:  431.24926471710205  seconds.\n",
      "Appended 100 rows. In total 2900\n",
      "Execution time:  446.0875508785248  seconds.\n",
      "Appended 100 rows. In total 3000\n",
      "Execution time:  461.5965509414673  seconds.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import multiprocessing\n",
    "import time as time\n",
    "\n",
    "start = time.time()\n",
    "counter = 0\n",
    "sample = rn.sample(recordsDB,3000)\n",
    "listOfDicts=[]\n",
    "for i in range(0,len(sample),100):\n",
    "    with multiprocessing.Pool( processes=multiprocessing.cpu_count()) as pool:\n",
    "        listOfDicts+=pool.map(GeocodingRequestHandling, sample[i:i+100])\n",
    "    counter+=100   \n",
    "    print(\"Appended 100 rows. In total {}\".format(counter))\n",
    "    end = time.time()\n",
    "    print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listOfDicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 3000 dictionaries\n"
     ]
    }
   ],
   "source": [
    "frm_listOfDicts = []\n",
    "counter = 0\n",
    "for el in listOfDicts:\n",
    "    dictObj = dict(el)\n",
    "    street_name, route, city, state,country = \"\",\"\",\"\",\"\",\"\"\n",
    "    for sub_el in el['address_components_from_coord']:\n",
    "        if('street_number' in sub_el['types']):\n",
    "            street_name = sub_el['long_name']\n",
    "        if('route' in sub_el['types']):\n",
    "            route = sub_el['long_name']\n",
    "        if('locality' in sub_el['types'] ):\n",
    "            city = sub_el['long_name']\n",
    "        if('administrative_area_level_1' in sub_el['types'] ):\n",
    "            state =  sub_el['short_name']\n",
    "        if('country' in sub_el['types'] ):\n",
    "            country =  sub_el['short_name']\n",
    "    if(street_name != \"\" and route != \"\"):\n",
    "        dictObj['address_from_coord'] = street_name+' '+route\n",
    "    else:\n",
    "        dictObj['address_from_coord'] = street_name+route      \n",
    "    dictObj['city_from_coord'] = city\n",
    "    dictObj['state_from_coord'] = state\n",
    "    dictObj['country_from_coord'] = country     \n",
    "    frm_listOfDicts.append(dictObj)\n",
    "    counter+=1\n",
    "print(\"Appended {} dictionaries\".format(counter))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampleGEO = pd.DataFrame(frm_listOfDicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampleGEO.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['address', 'address_components_from_coord', 'address_from_coord',\n",
       "       'business_id', 'categories', 'city', 'city_from_coord',\n",
       "       'country_from_coord', 'dist_diff', 'formatted_address_from_coord',\n",
       "       'geocoding_status', 'invgeocoding_status', 'latitude',\n",
       "       'latitude_from_address', 'longitude', 'longitude_from_address', 'name',\n",
       "       'place_id_from_address', 'place_id_from_coord', 'state',\n",
       "       'state_from_coord'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampleGEO.columns #We are going to ignore address_components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignoring address components\n",
    "cols_GEO = [ 'business_id',\n",
    "            'name',\n",
    "            'address',\n",
    "            'city',\n",
    "            'state',\n",
    "            'address_from_coord',\n",
    "            'city_from_coord',\n",
    "            'state_from_coord',\n",
    "            'country_from_coord', \n",
    "            'formatted_address_from_coord',      \n",
    "            'latitude',\n",
    "            'latitude_from_address',\n",
    "            'longitude',\n",
    "            'longitude_from_address',\n",
    "            'dist_diff',   \n",
    "            'categories',\n",
    "            'place_id_from_address',\n",
    "            'place_id_from_coord',\n",
    "            'geocoding_status',\n",
    "            'invgeocoding_status',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_GEO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['OK', nan, 'ZERO_RESULTS', 'REQUEST_DENIED'], dtype=object),\n",
       " array(['OK'], dtype=object))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampleGEO['geocoding_status'].unique(), df_sampleGEO['invgeocoding_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "address                          3000\n",
       "address_components_from_coord    3000\n",
       "address_from_coord               3000\n",
       "business_id                      3000\n",
       "categories                       2984\n",
       "city                             3000\n",
       "city_from_coord                  3000\n",
       "country_from_coord               3000\n",
       "dist_diff                        2853\n",
       "formatted_address_from_coord     3000\n",
       "geocoding_status                 2876\n",
       "invgeocoding_status              3000\n",
       "latitude                         3000\n",
       "latitude_from_address            2853\n",
       "longitude                        3000\n",
       "longitude_from_address           2853\n",
       "name                             3000\n",
       "place_id_from_address            2853\n",
       "place_id_from_coord              3000\n",
       "state                            3000\n",
       "state_from_coord                 3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampleGEO.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampleGEO[cols_GEO].to_csv(path_or_buf='/Users/kemalm/Desktop/FinalGM/geocodingSampleFormatted.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sampleGEO[df_sampleGEO.address_from_coord == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/Users/kemalm/Desktop/FinalGM/geocodingSampleFormatted.csv')\n",
    "df_test.loc[ df_test['address'].isnull(), 'address'] = ''\n",
    "df_test.loc[ df_test['address_from_coord'].isnull(), 'address_from_coord'] = ''\n",
    "df_test.loc[ df_test['city_from_coord'].isnull(), 'city_from_coord'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "address                         3000\n",
       "city                            3000\n",
       "state                           3000\n",
       "address_from_coord              3000\n",
       "city_from_coord                 3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "formatted_address_from_coord    3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2853\n",
       "longitude                       3000\n",
       "longitude_from_address          2853\n",
       "dist_diff                       2853\n",
       "categories                      2984\n",
       "place_id_from_address           2853\n",
       "place_id_from_coord             3000\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sampleGEO[cols_GEO].count() == df_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>address_from_coord</th>\n",
       "      <th>city_from_coord</th>\n",
       "      <th>state_from_coord</th>\n",
       "      <th>country_from_coord</th>\n",
       "      <th>formatted_address_from_coord</th>\n",
       "      <th>latitude</th>\n",
       "      <th>latitude_from_address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>longitude_from_address</th>\n",
       "      <th>dist_diff</th>\n",
       "      <th>categories</th>\n",
       "      <th>place_id_from_address</th>\n",
       "      <th>place_id_from_coord</th>\n",
       "      <th>geocoding_status</th>\n",
       "      <th>invgeocoding_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pBmhuYniNwodaxlfJq5UBQ</td>\n",
       "      <td>Red Modern Furniture</td>\n",
       "      <td>201 E Camelback Rd</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>201 East Camelback Road</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>US</td>\n",
       "      <td>201 E Camelback Rd, Phoenix, AZ 85012, USA</td>\n",
       "      <td>33.509034</td>\n",
       "      <td>33.509034</td>\n",
       "      <td>-112.070878</td>\n",
       "      <td>-112.070878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Antiques, Home Decor, Home Services, Lighting ...</td>\n",
       "      <td>ChIJfZtx8L8SK4cRQCW1UnJ8JJk</td>\n",
       "      <td>ChIJfZtx8L8SK4cRQCW1UnJ8JJk</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>wOJ3NMhumJDs9FKDADa0AQ</td>\n",
       "      <td>Modify Yoga Spa Cafe</td>\n",
       "      <td>4164 N Marshall Way</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>7040 East 3rd Avenue</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>US</td>\n",
       "      <td>7040 E 3rd Ave, Scottsdale, AZ 85251, USA</td>\n",
       "      <td>33.496462</td>\n",
       "      <td>33.496462</td>\n",
       "      <td>-111.929118</td>\n",
       "      <td>-111.929118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yoga, Restaurants, Fitness &amp; Instruction, Day ...</td>\n",
       "      <td>ChIJC0Tf8ZULK4cRAjNI5fnty7k</td>\n",
       "      <td>ChIJOSUZ8JULK4cRPKOojYcQbiw</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>QusBsOLrcamSQvoCPy3TQQ</td>\n",
       "      <td>Westney Heights Medical Centre and Xray</td>\n",
       "      <td>15 Westney Road N, Suite 11</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>ON</td>\n",
       "      <td>15 Westney Road North</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>ON</td>\n",
       "      <td>CA</td>\n",
       "      <td>15 Westney Rd N, Ajax, ON L1T 1P5, Canada</td>\n",
       "      <td>43.859083</td>\n",
       "      <td>43.859083</td>\n",
       "      <td>-79.039129</td>\n",
       "      <td>-79.039129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dentists, Health &amp; Medical, Walk-in Clinics, M...</td>\n",
       "      <td>EiUxMSwgMTUgV2VzdG5leSBSZCBOLCBBamF4LCBPTiwgQ2...</td>\n",
       "      <td>ChIJLxmMauzf1IkReXQEPO2mkGA</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>CXFR88uNnlcVemPV27oExg</td>\n",
       "      <td>Tracy's Downtown Barbers</td>\n",
       "      <td>590 N Alma School Rd, Ste 28</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>AZ</td>\n",
       "      <td>590 North Alma School Road</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>AZ</td>\n",
       "      <td>US</td>\n",
       "      <td>590 N Alma School Rd, Chandler, AZ 85224, USA</td>\n",
       "      <td>33.311682</td>\n",
       "      <td>33.311682</td>\n",
       "      <td>-111.859979</td>\n",
       "      <td>-111.859979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Barbers, Beauty &amp; Spas</td>\n",
       "      <td>EjEyOCwgNTkwIE4gQWxtYSBTY2hvb2wgUmQsIENoYW5kbG...</td>\n",
       "      <td>ChIJDwIgJ6sAK4cR21dg0BIKCnU</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>DFZnNrIZu1_oHv-4aaxJbg</td>\n",
       "      <td>Taste Of Thai</td>\n",
       "      <td>124 E Sangamon Ave</td>\n",
       "      <td>Rantoul</td>\n",
       "      <td>IL</td>\n",
       "      <td>128 East Sangamon Avenue</td>\n",
       "      <td>Rantoul</td>\n",
       "      <td>IL</td>\n",
       "      <td>US</td>\n",
       "      <td>128 E Sangamon Ave, Rantoul, IL 61866, USA</td>\n",
       "      <td>40.310398</td>\n",
       "      <td>40.310398</td>\n",
       "      <td>-88.157689</td>\n",
       "      <td>-88.157689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thai, Vietnamese, Restaurants, Asian Fusion</td>\n",
       "      <td>ChIJq6oau-gfDYgRFczdVeHQ5Nk</td>\n",
       "      <td>ChIJcXwdu-gfDYgRAffq_z8S2wM</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id                                     name  \\\n",
       "0     pBmhuYniNwodaxlfJq5UBQ                     Red Modern Furniture   \n",
       "895   wOJ3NMhumJDs9FKDADa0AQ                     Modify Yoga Spa Cafe   \n",
       "2344  QusBsOLrcamSQvoCPy3TQQ  Westney Heights Medical Centre and Xray   \n",
       "900   CXFR88uNnlcVemPV27oExg                 Tracy's Downtown Barbers   \n",
       "2341  DFZnNrIZu1_oHv-4aaxJbg                            Taste Of Thai   \n",
       "\n",
       "                           address        city state  \\\n",
       "0               201 E Camelback Rd     Phoenix    AZ   \n",
       "895            4164 N Marshall Way  Scottsdale    AZ   \n",
       "2344   15 Westney Road N, Suite 11        Ajax    ON   \n",
       "900   590 N Alma School Rd, Ste 28    Chandler    AZ   \n",
       "2341            124 E Sangamon Ave     Rantoul    IL   \n",
       "\n",
       "              address_from_coord city_from_coord state_from_coord  \\\n",
       "0        201 East Camelback Road         Phoenix               AZ   \n",
       "895         7040 East 3rd Avenue      Scottsdale               AZ   \n",
       "2344       15 Westney Road North            Ajax               ON   \n",
       "900   590 North Alma School Road        Chandler               AZ   \n",
       "2341    128 East Sangamon Avenue         Rantoul               IL   \n",
       "\n",
       "     country_from_coord                   formatted_address_from_coord  \\\n",
       "0                    US     201 E Camelback Rd, Phoenix, AZ 85012, USA   \n",
       "895                  US      7040 E 3rd Ave, Scottsdale, AZ 85251, USA   \n",
       "2344                 CA      15 Westney Rd N, Ajax, ON L1T 1P5, Canada   \n",
       "900                  US  590 N Alma School Rd, Chandler, AZ 85224, USA   \n",
       "2341                 US     128 E Sangamon Ave, Rantoul, IL 61866, USA   \n",
       "\n",
       "       latitude  latitude_from_address   longitude  longitude_from_address  \\\n",
       "0     33.509034              33.509034 -112.070878             -112.070878   \n",
       "895   33.496462              33.496462 -111.929118             -111.929118   \n",
       "2344  43.859083              43.859083  -79.039129              -79.039129   \n",
       "900   33.311682              33.311682 -111.859979             -111.859979   \n",
       "2341  40.310398              40.310398  -88.157689              -88.157689   \n",
       "\n",
       "      dist_diff                                         categories  \\\n",
       "0           0.0  Antiques, Home Decor, Home Services, Lighting ...   \n",
       "895         0.0  Yoga, Restaurants, Fitness & Instruction, Day ...   \n",
       "2344        0.0  Dentists, Health & Medical, Walk-in Clinics, M...   \n",
       "900         0.0                             Barbers, Beauty & Spas   \n",
       "2341        0.0        Thai, Vietnamese, Restaurants, Asian Fusion   \n",
       "\n",
       "                                  place_id_from_address  \\\n",
       "0                           ChIJfZtx8L8SK4cRQCW1UnJ8JJk   \n",
       "895                         ChIJC0Tf8ZULK4cRAjNI5fnty7k   \n",
       "2344  EiUxMSwgMTUgV2VzdG5leSBSZCBOLCBBamF4LCBPTiwgQ2...   \n",
       "900   EjEyOCwgNTkwIE4gQWxtYSBTY2hvb2wgUmQsIENoYW5kbG...   \n",
       "2341                        ChIJq6oau-gfDYgRFczdVeHQ5Nk   \n",
       "\n",
       "              place_id_from_coord geocoding_status invgeocoding_status  \n",
       "0     ChIJfZtx8L8SK4cRQCW1UnJ8JJk               OK                  OK  \n",
       "895   ChIJOSUZ8JULK4cRPKOojYcQbiw               OK                  OK  \n",
       "2344  ChIJLxmMauzf1IkReXQEPO2mkGA               OK                  OK  \n",
       "900   ChIJDwIgJ6sAK4cR21dg0BIKCnU               OK                  OK  \n",
       "2341  ChIJcXwdu-gfDYgRAffq_z8S2wM               OK                  OK  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[~df_test['dist_diff'].isnull()].sort_values(by=['dist_diff']).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value for calc_distance: 0.0 meters\n",
      "Max value for calc_distance: 7496171.563305463 meters\n",
      "Mean value for calc_distance: 90272.86056974754 meters\n",
      "Median for calc_distance: 5.08889081764884 meters\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Min value for calc_distance: {} meters\n",
    "Max value for calc_distance: {} meters\n",
    "Mean value for calc_distance: {} meters\n",
    "Median for calc_distance: {} meters\"\"\".format(\n",
    "                            df_test['dist_diff'].min(), \n",
    "                            df_test['dist_diff'].max(), \n",
    "                            df_test['dist_diff'].mean(),\n",
    "                            df_test['dist_diff'].median(),\n",
    "\n",
    "\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.853000e+03\n",
       "mean     9.027286e+04\n",
       "std      4.783915e+05\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      5.088891e+00\n",
       "75%      4.448364e+01\n",
       "max      7.496172e+06\n",
       "Name: dist_diff, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.dist_diff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7496171\n",
      "[0, 15, 30, 60, 120, 240, 480, 960, 1920, 3840, 7680, 15360, 30720, 61440, 122880, 245760, 491520, 983040, 1966080, 3932160, 7864320]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "ranges = [0,15]\n",
    "temp_var = 15\n",
    "while temp_var <= int(df_test['dist_diff'].max()):\n",
    "    temp_var *=2\n",
    "    ranges.append(temp_var) \n",
    "print(int(df_test['dist_diff'].max()))\n",
    "print(ranges)\n",
    "print(len(ranges))\n",
    "k = df_test[~df_test['dist_diff'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dist_diff\n",
       "(0, 15]               994\n",
       "(15, 30]              243\n",
       "(30, 60]              238\n",
       "(60, 120]             190\n",
       "(120, 240]            110\n",
       "(240, 480]             53\n",
       "(480, 960]             24\n",
       "(960, 1920]            10\n",
       "(1920, 3840]           14\n",
       "(3840, 7680]            9\n",
       "(7680, 15360]          20\n",
       "(15360, 30720]         16\n",
       "(30720, 61440]          7\n",
       "(61440, 122880]         1\n",
       "(122880, 245760]        8\n",
       "(245760, 491520]       19\n",
       "(491520, 983040]       42\n",
       "(983040, 1966080]      48\n",
       "(1966080, 3932160]     36\n",
       "(3932160, 7864320]      7\n",
       "Name: business_id, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.groupby(pd.cut(\n",
    "                k['dist_diff'], \n",
    "                ranges)).count()['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 44.483641290534365\n"
     ]
    }
   ],
   "source": [
    "QUANTILES = df_test.dist_diff.quantile([0.25,0.5,0.75])\n",
    "Q1, Q3 = QUANTILES[0.25], QUANTILES[0.75]\n",
    "print(Q1,Q3)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.bitwise_or(df_test.dist_diff <= Q1-IQR*1.5, df_test.dist_diff  >= Q3+IQR*1.5 )).astype(np.int64).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[np.bitwise_or(df_test.dist_diff <= Q1-IQR*1.5, df_test.dist_diff  >= Q3+IQR*1.5 )].sort_values(by=['dist_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'CA'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.country_from_coord.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AZ', 'AB', 'ON', 'NC', 'NV', 'QC', 'SC', 'OH', 'WI', 'PA', 'IL',\n",
       "       'NY'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.state_from_coord.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address (null count): 0\n",
      "Address (empty count): 124\n",
      "City (null count): 0\n",
      "City (empty count): 0\n",
      "State (null count): 0\n",
      "State (empty count): 0\n",
      "--------------------------------------------\n",
      "Address from coordinates (null count): 0\n",
      "Address from coordinates (empty count): 95\n",
      "City from coordinates (null count): 0\n",
      "City from coordinates (empty count): 6\n",
      "State from coordinates (null count): 0\n",
      "State from coordinates (empty count): 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Address (null count): {}\n",
    "Address (empty count): {}\n",
    "City (null count): {}\n",
    "City (empty count): {}\n",
    "State (null count): {}\n",
    "State (empty count): {}\n",
    "--------------------------------------------\n",
    "Address from coordinates (null count): {}\n",
    "Address from coordinates (empty count): {}\n",
    "City from coordinates (null count): {}\n",
    "City from coordinates (empty count): {}\n",
    "State from coordinates (null count): {}\n",
    "State from coordinates (empty count): {}\n",
    "\"\"\".format(\n",
    "df_test [df_test.address.isnull()]['business_id'].count(),\n",
    "df_test [df_test.address == '']['business_id'].count(),      \n",
    "df_test [df_test.city.isnull()]['business_id'].count(),\n",
    "df_test [df_test.city == '']['business_id'].count(),     \n",
    "df_test [df_test.state.isnull()]['business_id'].count(),\n",
    "df_test [df_test.state == '']['business_id'].count(),     \n",
    "\n",
    "df_test [df_test.address_from_coord.isnull()]['business_id'].count(),\n",
    "df_test [df_test.address_from_coord == '']['business_id'].count(),      \n",
    "df_test [df_test.city_from_coord.isnull()]['business_id'].count(),\n",
    "df_test [df_test.city_from_coord == '']['business_id'].count(),     \n",
    "df_test [df_test.state_from_coord.isnull()]['business_id'].count(),\n",
    "df_test [df_test.state_from_coord == '']['business_id'].count()   \n",
    "     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some invgeocoding calls return empty addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching cities and states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fltStates = pd.DataFrame (df_test[np.bitwise_and(df_test.state != '', df_test.state_from_coord != '')][['business_id','state','state_from_coord']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fltStates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fltCities= pd.DataFrame (df_test[np.bitwise_and(df_test.city != '', df_test.city_from_coord != '')][['business_id','city','city_from_coord']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2994, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fltCities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities match: 2800 out of 2994\n",
      "States match: 2995 out of 3000\n",
      "Filtered out null and empty values.\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Cities match: {} out of {}\n",
    "States match: {} out of {}\n",
    "Filtered out null and empty values.\"\"\" .format(\n",
    "df_fltCities[df_fltCities.city == df_fltCities.city_from_coord ].business_id.count(), df_fltCities.shape[0],\n",
    "df_fltStates[df_fltStates.state == df_fltStates.state_from_coord ].business_id.count(), df_fltStates.shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fltAddresses= pd.DataFrame(df_test[np.bitwise_and(df_test.address != '', df_test.address_from_coord != '')][['business_id','address','address_from_coord']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "scores = np.zeros((df_fltAddresses.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2794, 1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(df_fltAddresses.itertuples(index=False)):\n",
    "    addr=row.__getattribute__('address')\n",
    "    addr_c = row.__getattribute__('address_from_coord')\n",
    "    score = fuzz.token_set_ratio(addr,addr_c)\n",
    "    scores[idx,0] = score\n",
    "df_fltAddresses['addr_score']= scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>address</th>\n",
       "      <th>address_from_coord</th>\n",
       "      <th>addr_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>1hceMTsoDKL40bgIqp1xkg</td>\n",
       "      <td>6432 Rea Road</td>\n",
       "      <td>6432 Rea Road</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>LQ9WorDtNJXeEfA7GWIXTA</td>\n",
       "      <td>6355 Yonge Street</td>\n",
       "      <td>6355 Yonge Street</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>wphF5TNh31RQ0a-nbrpqyw</td>\n",
       "      <td>B104-20 Broadleaf Avenue</td>\n",
       "      <td>20 Broadleaf Avenue</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>zXO__HLv4CqHJ7LJNUOc2A</td>\n",
       "      <td>884 Danforth Avenue</td>\n",
       "      <td>884 Danforth Avenue</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>r6bvqwhWy73SgyK_w8Y5Lg</td>\n",
       "      <td>2555 Victoria Park Avenue</td>\n",
       "      <td>2555 Victoria Park Avenue</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>yxTkyYEWzfsPbD58_Zblig</td>\n",
       "      <td>505 Highway 7  E</td>\n",
       "      <td>505 Highway 7</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>2DIQm_EDH7d422g6HxoTDA</td>\n",
       "      <td>621 Dixon</td>\n",
       "      <td>621 Dixon Road</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>LHqBSGDa3Iw7q_44RP9dVg</td>\n",
       "      <td>7001 Boulevard de la V√©rendrye</td>\n",
       "      <td>7001 Boulevard de la V√©rendrye</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Dht5tuQpI9m1DCuNG323xg</td>\n",
       "      <td>421 Bentley Street</td>\n",
       "      <td>421 Bentley Street</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>YjyQlqHoB3Q9ysJGXiJuLA</td>\n",
       "      <td>33 Villiers Street</td>\n",
       "      <td>33 Villiers Street</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id                         address  \\\n",
       "2672  1hceMTsoDKL40bgIqp1xkg                   6432 Rea Road   \n",
       "1325  LQ9WorDtNJXeEfA7GWIXTA               6355 Yonge Street   \n",
       "2745  wphF5TNh31RQ0a-nbrpqyw        B104-20 Broadleaf Avenue   \n",
       "2856  zXO__HLv4CqHJ7LJNUOc2A             884 Danforth Avenue   \n",
       "2857  r6bvqwhWy73SgyK_w8Y5Lg       2555 Victoria Park Avenue   \n",
       "410   yxTkyYEWzfsPbD58_Zblig                505 Highway 7  E   \n",
       "411   2DIQm_EDH7d422g6HxoTDA                       621 Dixon   \n",
       "934   LHqBSGDa3Iw7q_44RP9dVg  7001 Boulevard de la V√©rendrye   \n",
       "2744  Dht5tuQpI9m1DCuNG323xg              421 Bentley Street   \n",
       "2261  YjyQlqHoB3Q9ysJGXiJuLA              33 Villiers Street   \n",
       "\n",
       "                  address_from_coord  addr_score  \n",
       "2672                   6432 Rea Road       100.0  \n",
       "1325               6355 Yonge Street       100.0  \n",
       "2745             20 Broadleaf Avenue       100.0  \n",
       "2856             884 Danforth Avenue       100.0  \n",
       "2857       2555 Victoria Park Avenue       100.0  \n",
       "410                    505 Highway 7       100.0  \n",
       "411                   621 Dixon Road       100.0  \n",
       "934   7001 Boulevard de la V√©rendrye       100.0  \n",
       "2744              421 Bentley Street       100.0  \n",
       "2261              33 Villiers Street       100.0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fltAddresses.sort_values(by=['addr_score'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_scores= pd.DataFrame(pd.merge(df_test, df_fltAddresses[['business_id','addr_score']], on='business_id' ,how='left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 21)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_scores.sort_values(by=['addr_score'], ascending=False)[ [ 'business_id',\n",
    "            'name',\n",
    "            'address',\n",
    "            'city',\n",
    "            'state',\n",
    "            'address_from_coord',\n",
    "            'addr_score',\n",
    "            'city_from_coord',\n",
    "            'state_from_coord',\n",
    "            'country_from_coord', \n",
    "            'formatted_address_from_coord',      \n",
    "            'latitude',\n",
    "            'latitude_from_address',\n",
    "            'longitude',\n",
    "            'longitude_from_address',\n",
    "            'dist_diff',   \n",
    "            'categories',\n",
    "            'place_id_from_address',\n",
    "            'place_id_from_coord',\n",
    "            'geocoding_status',\n",
    "            'invgeocoding_status'\n",
    "            ]].to_csv(path_or_buf='/Users/kemalm/Desktop/FinalGM/scoresSample.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "address                         3000\n",
       "city                            3000\n",
       "state                           3000\n",
       "address_from_coord              3000\n",
       "city_from_coord                 3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "formatted_address_from_coord    3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2853\n",
       "longitude                       3000\n",
       "longitude_from_address          2853\n",
       "dist_diff                       2853\n",
       "categories                      2984\n",
       "place_id_from_address           2853\n",
       "place_id_from_coord             3000\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "addr_score                      2794\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_scores[~df_with_scores.isnull()].count() # for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = pd.read_csv('/Users/kemalm/Desktop/FinalGM/scoresSample.csv')\n",
    "testing_df.loc[ testing_df['address'].isnull(), 'address'] = ''\n",
    "testing_df.loc[ testing_df['address_from_coord'].isnull(), 'address_from_coord'] = ''\n",
    "testing_df.loc[ testing_df['city_from_coord'].isnull(), 'city_from_coord'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "address                         3000\n",
       "city                            3000\n",
       "state                           3000\n",
       "address_from_coord              3000\n",
       "addr_score                      2794\n",
       "city_from_coord                 3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "formatted_address_from_coord    3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2853\n",
       "longitude                       3000\n",
       "longitude_from_address          2853\n",
       "dist_diff                       2853\n",
       "categories                      2984\n",
       "place_id_from_address           2853\n",
       "place_id_from_coord             3000\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df[~testing_df.isnull()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Place Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_placeSearch =\"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={}&inputtype=textquery&locationbias=circle:100@{},{}&key={}&fields=place_id,name,type,permanently_closed\".format(\n",
    "    'Meatball House'.replace(' ','%'),45.4884,-73.5682, api_key)\n",
    "       \n",
    "response_placeSearch =requests.get(url_placeSearch)\n",
    "response_placeSearchJSON= response_placeSearch.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidates': [{'name': 'Meatball House',\n",
       "   'place_id': 'ChIJLd5qjmQayUwRPy5fx6lhk2c',\n",
       "   'types': ['restaurant', 'point_of_interest', 'food', 'establishment']}],\n",
       " 'status': 'OK'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_placeSearchJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'html_attributions': [], 'result': {'name': '1752 Rue Notre-Dame Ouest', 'types': ['street_address']}, 'status': 'OK'}\n"
     ]
    }
   ],
   "source": [
    "url_placeDetails = 'https://maps.googleapis.com/maps/api/place/details/json?placeid={}&fields=name,types&key={}'.format(\n",
    "'ChIJI2drjmQayUwRzU5g3kukboY',api_key)\n",
    "resp = requests.get(url_placeDetails)\n",
    "resp_dict = resp.json()\n",
    "print(resp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining info from Find Place (Places API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_df_with_scores = pd.DataFrame(testing_df[np.bitwise_and(~testing_df.dist_diff.isnull(),~testing_df.addr_score.isnull())][testing_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2771, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flt_df_with_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2173, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flt_df_with_scores[(flt_df_with_scores.dist_diff <= 100) & (flt_df_with_scores.addr_score>=70) ][flt_df_with_scores.columns].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_list_of_dicts = flt_df_with_scores[(flt_df_with_scores.dist_diff <= 100) & (flt_df_with_scores.addr_score>=70) ][flt_df_with_scores.columns].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2173, list)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flt_list_of_dicts), type(flt_list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flt_list_of_dicts)/41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaceSearchHandlingRequest(record):\n",
    "    dictObj=dict(record)\n",
    "    \n",
    "    b_name = record['name']\n",
    "    b_lat = record['latitude']\n",
    "    b_long = record['longitude']\n",
    "\n",
    "    url_placeSearch =\"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={}&inputtype=textquery&locationbias=circle:100@{},{}&key={}&fields=place_id,name,type\".format(\n",
    "    b_name,b_lat,b_long ,api_key)\n",
    "       \n",
    "    resp_ps =requests.get(url_placeSearch)\n",
    "    resp_psDict= resp_ps.json()\n",
    "       \n",
    "    dictObj['placeSearch_status'] = resp_psDict['status']  # 1\n",
    "    if(dictObj['placeSearch_status']=='OK'):\n",
    "        ObtainData(dictObj,resp_psDict)            \n",
    "    return dictObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ObtainData(dictObj, resp_psDict):\n",
    "    dictObj['business_place_id'] = resp_psDict['candidates'][0]['place_id'] #2\n",
    "    dictObj['name_from_location']= resp_psDict['candidates'][0]['name']  #3\n",
    "    listTypes = resp_psDict['candidates'][0]['types']\n",
    "    strTypes =\", \".join(listTypes)\n",
    "    dictObj['categories_from_location']= strTypes   #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 41 rows. In total 41\n",
      "Execution time:  1.3877439498901367  seconds.\n",
      "Appended 41 rows. In total 82\n",
      "Execution time:  2.771635055541992  seconds.\n",
      "Appended 41 rows. In total 123\n",
      "Execution time:  4.159236907958984  seconds.\n",
      "Appended 41 rows. In total 164\n",
      "Execution time:  5.54879093170166  seconds.\n",
      "Appended 41 rows. In total 205\n",
      "Execution time:  6.930213928222656  seconds.\n",
      "Appended 41 rows. In total 246\n",
      "Execution time:  8.308640718460083  seconds.\n",
      "Appended 41 rows. In total 287\n",
      "Execution time:  9.692788124084473  seconds.\n",
      "Appended 41 rows. In total 328\n",
      "Execution time:  11.080191135406494  seconds.\n",
      "Appended 41 rows. In total 369\n",
      "Execution time:  12.462975025177002  seconds.\n",
      "Appended 41 rows. In total 410\n",
      "Execution time:  13.860663890838623  seconds.\n",
      "Appended 41 rows. In total 451\n",
      "Execution time:  15.233250856399536  seconds.\n",
      "Appended 41 rows. In total 492\n",
      "Execution time:  16.620210886001587  seconds.\n",
      "Appended 41 rows. In total 533\n",
      "Execution time:  18.013474941253662  seconds.\n",
      "Appended 41 rows. In total 574\n",
      "Execution time:  19.410805702209473  seconds.\n",
      "Appended 41 rows. In total 615\n",
      "Execution time:  20.78187894821167  seconds.\n",
      "Appended 41 rows. In total 656\n",
      "Execution time:  22.169805765151978  seconds.\n",
      "Appended 41 rows. In total 697\n",
      "Execution time:  26.139781951904297  seconds.\n",
      "Appended 41 rows. In total 738\n",
      "Execution time:  31.089346885681152  seconds.\n",
      "Appended 41 rows. In total 779\n",
      "Execution time:  35.13517189025879  seconds.\n",
      "Appended 41 rows. In total 820\n",
      "Execution time:  39.90575289726257  seconds.\n",
      "Appended 41 rows. In total 861\n",
      "Execution time:  44.059682846069336  seconds.\n",
      "Appended 41 rows. In total 902\n",
      "Execution time:  48.21386694908142  seconds.\n",
      "Appended 41 rows. In total 943\n",
      "Execution time:  52.78075695037842  seconds.\n",
      "Appended 41 rows. In total 984\n",
      "Execution time:  57.2644259929657  seconds.\n",
      "Appended 41 rows. In total 1025\n",
      "Execution time:  61.62956094741821  seconds.\n",
      "Appended 41 rows. In total 1066\n",
      "Execution time:  66.1126298904419  seconds.\n",
      "Appended 41 rows. In total 1107\n",
      "Execution time:  70.57208776473999  seconds.\n",
      "Appended 41 rows. In total 1148\n",
      "Execution time:  74.76075196266174  seconds.\n",
      "Appended 41 rows. In total 1189\n",
      "Execution time:  78.81330275535583  seconds.\n",
      "Appended 41 rows. In total 1230\n",
      "Execution time:  83.57717990875244  seconds.\n",
      "Appended 41 rows. In total 1271\n",
      "Execution time:  88.33957195281982  seconds.\n",
      "Appended 41 rows. In total 1312\n",
      "Execution time:  94.03223896026611  seconds.\n",
      "Appended 41 rows. In total 1353\n",
      "Execution time:  98.70358800888062  seconds.\n",
      "Appended 41 rows. In total 1394\n",
      "Execution time:  103.28057789802551  seconds.\n",
      "Appended 41 rows. In total 1435\n",
      "Execution time:  107.86665987968445  seconds.\n",
      "Appended 41 rows. In total 1476\n",
      "Execution time:  112.34134101867676  seconds.\n",
      "Appended 41 rows. In total 1517\n",
      "Execution time:  116.38991904258728  seconds.\n",
      "Appended 41 rows. In total 1558\n",
      "Execution time:  121.16521978378296  seconds.\n",
      "Appended 41 rows. In total 1599\n",
      "Execution time:  125.51002597808838  seconds.\n",
      "Appended 41 rows. In total 1640\n",
      "Execution time:  129.75257992744446  seconds.\n",
      "Appended 41 rows. In total 1681\n",
      "Execution time:  134.10957288742065  seconds.\n",
      "Appended 41 rows. In total 1722\n",
      "Execution time:  138.56562495231628  seconds.\n",
      "Appended 41 rows. In total 1763\n",
      "Execution time:  142.82872796058655  seconds.\n",
      "Appended 41 rows. In total 1804\n",
      "Execution time:  147.2925148010254  seconds.\n",
      "Appended 41 rows. In total 1845\n",
      "Execution time:  151.56368017196655  seconds.\n",
      "Appended 41 rows. In total 1886\n",
      "Execution time:  155.81609392166138  seconds.\n",
      "Appended 41 rows. In total 1927\n",
      "Execution time:  159.96066999435425  seconds.\n",
      "Appended 41 rows. In total 1968\n",
      "Execution time:  164.94490790367126  seconds.\n",
      "Appended 41 rows. In total 2009\n",
      "Execution time:  169.22658276557922  seconds.\n",
      "Appended 41 rows. In total 2050\n",
      "Execution time:  173.47633600234985  seconds.\n",
      "Appended 41 rows. In total 2091\n",
      "Execution time:  177.6421799659729  seconds.\n",
      "Appended 41 rows. In total 2132\n",
      "Execution time:  181.91329908370972  seconds.\n",
      "Appended 41 rows. In total 2173\n",
      "Execution time:  186.91731691360474  seconds.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import multiprocessing\n",
    "import time as time\n",
    "\n",
    "start = time.time()\n",
    "counter = 0\n",
    "\n",
    "dicts_with_even_name_types=[]\n",
    "for i in range(0,len(flt_list_of_dicts),41):\n",
    "    with multiprocessing.Pool( processes=multiprocessing.cpu_count()) as pool:\n",
    "        dicts_with_even_name_types+=pool.map(PlaceSearchHandlingRequest, flt_list_of_dicts[i:i+41])\n",
    "    counter+=41   \n",
    "    print(\"Appended 41 rows. In total {}\".format(counter))\n",
    "    end = time.time()\n",
    "    print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2173"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dicts_with_even_name_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePlaceSearchForEveryCase = pd.DataFrame(dicts_with_even_name_types)[['business_id',\n",
    "            'name',\n",
    "            'name_from_location',\n",
    "            'address',\n",
    "            'city',\n",
    "            'state',\n",
    "            'address_from_coord',\n",
    "            'addr_score',\n",
    "            'city_from_coord',\n",
    "            'state_from_coord',\n",
    "            'country_from_coord', \n",
    "            'formatted_address_from_coord',      \n",
    "            'latitude',\n",
    "            'latitude_from_address',\n",
    "            'longitude',\n",
    "            'longitude_from_address',\n",
    "            'dist_diff',   \n",
    "            'categories',\n",
    "            'categories_from_location',\n",
    "            'place_id_from_address',\n",
    "            'place_id_from_coord',\n",
    "            'business_place_id',\n",
    "            'geocoding_status',\n",
    "            'invgeocoding_status',                                                                        \n",
    "            'placeSearch_status'                                                    \n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     2173\n",
       "name                            2173\n",
       "name_from_location              2109\n",
       "address                         2173\n",
       "city                            2173\n",
       "state                           2173\n",
       "address_from_coord              2173\n",
       "addr_score                      2173\n",
       "city_from_coord                 2173\n",
       "state_from_coord                2173\n",
       "country_from_coord              2173\n",
       "formatted_address_from_coord    2173\n",
       "latitude                        2173\n",
       "latitude_from_address           2173\n",
       "longitude                       2173\n",
       "longitude_from_address          2173\n",
       "dist_diff                       2173\n",
       "categories                      2162\n",
       "categories_from_location        2109\n",
       "place_id_from_address           2173\n",
       "place_id_from_coord             2173\n",
       "business_place_id               2109\n",
       "geocoding_status                2173\n",
       "invgeocoding_status             2173\n",
       "placeSearch_status              2173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savePlaceSearchForEveryCase[~savePlaceSearchForEveryCase.isnull()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2173, 25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savePlaceSearchForEveryCase.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePlaceSearchForEveryCase.to_csv(path_or_buf='/Users/kemalm/Desktop/FinalGM/spasi_da_se_ne_gubi.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.DataFrame(        pd.merge(testing_df, \n",
    "         savePlaceSearchForEveryCase[['business_id','business_place_id','name_from_location','categories_from_location','placeSearch_status']],\n",
    "         on='business_id',\n",
    "         how='left'))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 25)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1971, 25)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df.placeSearch_status =='OK'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OK' nan 'ZERO_RESULTS' 'REQUEST_DENIED'] ['OK' 'ZERO_RESULTS' 'REQUEST_DENIED' nan] ['OK']\n"
     ]
    }
   ],
   "source": [
    "print(merged_df['placeSearch_status'].unique(),\n",
    "merged_df['geocoding_status'].unique(),\n",
    "merged_df['invgeocoding_status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[['business_id',\n",
    "            'name',\n",
    "            'name_from_location',\n",
    "            'address',\n",
    "            'city',\n",
    "            'state',\n",
    "            'address_from_coord',\n",
    "            'addr_score',\n",
    "            'city_from_coord',\n",
    "            'state_from_coord',\n",
    "            'country_from_coord', \n",
    "            'formatted_address_from_coord',      \n",
    "            'latitude',\n",
    "            'latitude_from_address',\n",
    "            'longitude',\n",
    "            'longitude_from_address',\n",
    "            'dist_diff',   \n",
    "            'categories',\n",
    "            'categories_from_location',\n",
    "            'place_id_from_address',\n",
    "            'place_id_from_coord',\n",
    "            'business_place_id',\n",
    "            'geocoding_status',\n",
    "            'invgeocoding_status',                                                                        \n",
    "            'placeSearch_status'                                                    \n",
    "]].to_csv(path_or_buf='/Users/kemalm/Desktop/FinalGM/mrgSample.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "address                         3000\n",
       "city                            3000\n",
       "state                           3000\n",
       "address_from_coord              3000\n",
       "addr_score                      2794\n",
       "city_from_coord                 3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "formatted_address_from_coord    3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2853\n",
       "longitude                       3000\n",
       "longitude_from_address          2853\n",
       "dist_diff                       2853\n",
       "categories                      2984\n",
       "place_id_from_address           2853\n",
       "place_id_from_coord             3000\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "business_place_id               2109\n",
       "name_from_location              2109\n",
       "categories_from_location        2109\n",
       "placeSearch_status              2173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[~merged_df.isnull()].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Dataset (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from scipy.spatial.distance import pdist\n",
    "from geopy.distance import geodesic\n",
    "import random as rn\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_mrgDataset = pd.read_csv('/Users/kemalm/Desktop/FinalGM//mrgSample.csv')\n",
    "testing_mrgDataset.loc[ testing_mrgDataset['address'].isnull(), 'address'] = ''\n",
    "testing_mrgDataset.loc[ testing_mrgDataset['address_from_coord'].isnull(), 'address_from_coord'] = ''\n",
    "testing_mrgDataset.loc[ testing_mrgDataset['city_from_coord'].isnull(), 'city_from_coord'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_mrgDataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "name_from_location              2109\n",
       "address                         3000\n",
       "city                            3000\n",
       "state                           3000\n",
       "address_from_coord              3000\n",
       "addr_score                      2794\n",
       "city_from_coord                 3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "formatted_address_from_coord    3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2853\n",
       "longitude                       3000\n",
       "longitude_from_address          2853\n",
       "dist_diff                       2853\n",
       "categories                      2984\n",
       "categories_from_location        2109\n",
       "place_id_from_address           2853\n",
       "place_id_from_coord             3000\n",
       "business_place_id               2109\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "placeSearch_status              2173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_mrgDataset[~testing_mrgDataset.isnull()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import math as mt\n",
    "\n",
    "list_of_buss =list() \n",
    "for idx, row in enumerate(testing_mrgDataset.itertuples(index=False)):\n",
    "    dictObj=dict()\n",
    "    \n",
    "    business_id=row.__getattribute__('business_id')\n",
    "    dictObj['business_id'] = business_id\n",
    "    \n",
    "    name=row.__getattribute__('name')\n",
    "    dictObj['name'] = name\n",
    "\n",
    "    name_frm_loc=row.__getattribute__('name_from_location')\n",
    "    dictObj['name_from_location'] = name_frm_loc\n",
    "       \n",
    "    if(type(name_frm_loc)==str and name_frm_loc!=''):\n",
    "        name_score = fuzz.token_set_ratio(name,name_frm_loc)\n",
    "        dictObj['name_score'] = name_score\n",
    " \n",
    "    cat=row.__getattribute__('categories')\n",
    "    dictObj['categories'] = cat\n",
    "    \n",
    "    cat_frn_loc=row.__getattribute__('categories_from_location')\n",
    "    dictObj['categories_from_location']= cat_frn_loc\n",
    "    if(type(name_frm_loc)==str and cat_frn_loc!=''):     \n",
    "        cat_frm_loc_filtered = cat_frn_loc.replace(\"point_of_interest\",\"\").replace(\"establishment\",\"\")\n",
    "        categories_score = fuzz.token_set_ratio(cat,cat_frm_loc_filtered)\n",
    "        dictObj['categories_score']= categories_score\n",
    "    list_of_buss.append(dictObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_buss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_set_ratio('coffee tea food', 'cafe store food,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_buss = pd.DataFrame(list_of_buss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accul=pd.DataFrame(pd.merge(testing_mrgDataset, \n",
    "         dict_buss[['business_id', 'name_score', 'categories_score']],\n",
    "         on='business_id',\n",
    "         how='left')[['business_id',\n",
    "            'name',\n",
    "            'name_from_location',\n",
    "            'name_score',\n",
    "            'address',\n",
    "            'city',\n",
    "            'state',\n",
    "            'address_from_coord',\n",
    "            'addr_score',\n",
    "            'city_from_coord',\n",
    "            'state_from_coord',\n",
    "            'country_from_coord', \n",
    "            'formatted_address_from_coord',      \n",
    "            'latitude',\n",
    "            'latitude_from_address',\n",
    "            'longitude',\n",
    "            'longitude_from_address',\n",
    "            'dist_diff',   \n",
    "            'categories',\n",
    "            'categories_from_location',\n",
    "            'categories_score',\n",
    "            'place_id_from_address',\n",
    "            'place_id_from_coord',\n",
    "            'business_place_id',\n",
    "            'geocoding_status',\n",
    "            'invgeocoding_status',                                                                        \n",
    "            'placeSearch_status'     \n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_accul' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-89c08e8dcb0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_accul\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/Users/kemalm/Desktop/FinalGM/allScoresSample.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_accul' is not defined"
     ]
    }
   ],
   "source": [
    "df_accul.to_csv(path_or_buf='/Users/kemalm/Desktop/FinalGM/allScoresSample.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "name_from_location              2109\n",
       "name_score                      2109\n",
       "address                         3000\n",
       "city                            3000\n",
       "state                           3000\n",
       "address_from_coord              3000\n",
       "addr_score                      2794\n",
       "city_from_coord                 3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "formatted_address_from_coord    3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2853\n",
       "longitude                       3000\n",
       "longitude_from_address          2853\n",
       "dist_diff                       2853\n",
       "categories                      2984\n",
       "categories_from_location        2109\n",
       "categories_score                2109\n",
       "place_id_from_address           2853\n",
       "place_id_from_coord             3000\n",
       "business_place_id               2109\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "placeSearch_status              2173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accul[~df_accul.isnull()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allscores = pd.read_csv('/Users/kemalm/Desktop/FinalGM/allScoresSample.csv')\n",
    "df_allscores.loc[ df_allscores['address'].isnull(), 'address'] = ''\n",
    "df_allscores.loc[ df_allscores['address_from_coord'].isnull(), 'address_from_coord'] = ''\n",
    "df_allscores.loc[ df_allscores['city_from_coord'].isnull(), 'city_from_coord'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_allscores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "repair_request_denied = df_allscores[df_allscores.geocoding_status == 'REQUEST_DENIED'][\n",
    "    ['business_id','address','geocoding_status',\n",
    "     'latitude', 'longitude', 'latitude_from_address',\n",
    "     'longitude_from_address','dist_diff','place_id_from_address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 9)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repair_request_denied.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>address</th>\n",
       "      <th>geocoding_status</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude_from_address</th>\n",
       "      <th>longitude_from_address</th>\n",
       "      <th>dist_diff</th>\n",
       "      <th>place_id_from_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>pLoiSZMnLD612xK8opkHhg</td>\n",
       "      <td>1705 S. Greenfield Road, #101</td>\n",
       "      <td>REQUEST_DENIED</td>\n",
       "      <td>33.384034</td>\n",
       "      <td>-111.737128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>Pydv8bKHerfw8EYQf134Sw</td>\n",
       "      <td>10001 W. Bell Road, #101</td>\n",
       "      <td>REQUEST_DENIED</td>\n",
       "      <td>33.637858</td>\n",
       "      <td>-112.276676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>_M6cf_rx6rMsKaEiLmZVFA</td>\n",
       "      <td>2650 N Tenaya Way, #180</td>\n",
       "      <td>REQUEST_DENIED</td>\n",
       "      <td>36.207884</td>\n",
       "      <td>-115.249355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>m2R3fjLag8EzYPAeIXdC7g</td>\n",
       "      <td>1500 N. Green Valley Pkwy., #120</td>\n",
       "      <td>REQUEST_DENIED</td>\n",
       "      <td>36.029428</td>\n",
       "      <td>-115.085949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>sxPwFSLoW7xx1tWgNZ-p6g</td>\n",
       "      <td>10157 W. Charleston Blvd., #420, Ste 420</td>\n",
       "      <td>REQUEST_DENIED</td>\n",
       "      <td>36.158887</td>\n",
       "      <td>-115.316411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>7ONpBeG74dGo2kVmTNXCFg</td>\n",
       "      <td>2824 E Indian School Rd, #1</td>\n",
       "      <td>REQUEST_DENIED</td>\n",
       "      <td>33.496219</td>\n",
       "      <td>-112.020960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>EJgC5p_-AxdHaxm9Dh0P5g</td>\n",
       "      <td>4565 W Ann Road # 100</td>\n",
       "      <td>REQUEST_DENIED</td>\n",
       "      <td>36.173110</td>\n",
       "      <td>-115.125401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id                                   address  \\\n",
       "1110  pLoiSZMnLD612xK8opkHhg             1705 S. Greenfield Road, #101   \n",
       "1181  Pydv8bKHerfw8EYQf134Sw                  10001 W. Bell Road, #101   \n",
       "1513  _M6cf_rx6rMsKaEiLmZVFA                   2650 N Tenaya Way, #180   \n",
       "1743  m2R3fjLag8EzYPAeIXdC7g          1500 N. Green Valley Pkwy., #120   \n",
       "2059  sxPwFSLoW7xx1tWgNZ-p6g  10157 W. Charleston Blvd., #420, Ste 420   \n",
       "2099  7ONpBeG74dGo2kVmTNXCFg               2824 E Indian School Rd, #1   \n",
       "2754  EJgC5p_-AxdHaxm9Dh0P5g                     4565 W Ann Road # 100   \n",
       "\n",
       "     geocoding_status   latitude   longitude  latitude_from_address  \\\n",
       "1110   REQUEST_DENIED  33.384034 -111.737128                    NaN   \n",
       "1181   REQUEST_DENIED  33.637858 -112.276676                    NaN   \n",
       "1513   REQUEST_DENIED  36.207884 -115.249355                    NaN   \n",
       "1743   REQUEST_DENIED  36.029428 -115.085949                    NaN   \n",
       "2059   REQUEST_DENIED  36.158887 -115.316411                    NaN   \n",
       "2099   REQUEST_DENIED  33.496219 -112.020960                    NaN   \n",
       "2754   REQUEST_DENIED  36.173110 -115.125401                    NaN   \n",
       "\n",
       "      longitude_from_address  dist_diff place_id_from_address  \n",
       "1110                     NaN        NaN                   NaN  \n",
       "1181                     NaN        NaN                   NaN  \n",
       "1513                     NaN        NaN                   NaN  \n",
       "1743                     NaN        NaN                   NaN  \n",
       "2059                     NaN        NaN                   NaN  \n",
       "2099                     NaN        NaN                   NaN  \n",
       "2754                     NaN        NaN                   NaN  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repair_request_denied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = repair_request_denied.to_dict('records')\n",
    "for i in range(0,len(val_list),1):\n",
    "   \n",
    "    smpl_address = val_list[i]['address']\n",
    "    if(smpl_address !=''):\n",
    "        url_geocoding = \"https://maps.googleapis.com/maps/api/geocode/json?address={}&key={}\".format(smpl_address.replace('#',''),api_key)\n",
    "        resp = requests.get(url_geocoding)\n",
    "        resp_json = resp.json()\n",
    "        \n",
    "        val_list[i]['geocoding_status'] = resp_json['status']\n",
    "        if(resp_json['status']=='OK'):\n",
    "            val_list[i]['latitude_from_address']= resp_json['results'][0]['geometry']['location']['lat']\n",
    "            val_list[i]['longitude_from_address']= resp_json['results'][0]['geometry']['location']['lng']\n",
    "    \n",
    "            coordinates=np.array([[val_list[i]['latitude'], val_list[i]['longitude']],\n",
    "                                  [val_list[i]['latitude_from_address'],val_list[i]['longitude_from_address']]])    \n",
    "            m_dist = pdist(coordinates, # Coordinates matrix or tuples list\n",
    "                   lambda u, v: geodesic(u, v).kilometers)\n",
    "            val_list[i]['dist_diff']= float(m_dist)* 1000.0\n",
    "            val_list[i]['place_id_from_address']= resp_json['results'][0]['place_id']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['business_id', 'address', 'geocoding_status', 'latitude', 'longitude', 'latitude_from_address', 'longitude_from_address', 'dist_diff', 'place_id_from_address'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_list[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in val_list:\n",
    "    df_allscores.loc[df_allscores.business_id == el['business_id'], 'geocoding_status'] = el['geocoding_status']\n",
    "    df_allscores.loc[df_allscores.business_id == el['business_id'], 'latitude_from_address'] = el['latitude_from_address']\n",
    "    df_allscores.loc[df_allscores.business_id == el['business_id'], 'longitude_from_address'] = el['longitude_from_address']\n",
    "    df_allscores.loc[df_allscores.business_id == el['business_id'], 'dist_diff'] = el['dist_diff']\n",
    "    df_allscores.loc[df_allscores.business_id == el['business_id'], 'place_id_from_address'] = el['place_id_from_address']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 27)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_allscores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 27)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_allscores[df_allscores.geocoding_status == 'REQUEST_DENIED'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fix001 = pd.DataFrame(df_allscores[['business_id',\n",
    "            'name', 'name_from_location', 'name_score',\n",
    "            'address', 'address_from_coord', 'addr_score', 'formatted_address_from_coord',\n",
    "            'city',  'city_from_coord',\n",
    "            'state', 'state_from_coord',  'country_from_coord', \n",
    "            'latitude', 'latitude_from_address', 'longitude', 'longitude_from_address', 'dist_diff',   \n",
    "            'categories', 'categories_from_location', 'categories_score',\n",
    "            'place_id_from_address', 'place_id_from_coord', 'business_place_id',\n",
    "            'geocoding_status', 'invgeocoding_status', 'placeSearch_status'     ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 27)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fix001.to_csv(path_or_buf='/Users/kemalm/Desktop/Collection of fSets/fSet001.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>placeSearch_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>De1sTuZgJfNxh4YIFzNX6A</td>\n",
       "      <td>Speedee Mart #123</td>\n",
       "      <td>36.013831</td>\n",
       "      <td>-115.155348</td>\n",
       "      <td>REQUEST_DENIED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id               name   latitude   longitude  \\\n",
       "1123  De1sTuZgJfNxh4YIFzNX6A  Speedee Mart #123  36.013831 -115.155348   \n",
       "\n",
       "     placeSearch_status  \n",
       "1123     REQUEST_DENIED  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001[df_fix001.placeSearch_status=='REQUEST_DENIED'][['business_id','name','latitude','longitude','placeSearch_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_placeSearch =\"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={}&inputtype=textquery&locationbias=circle:100@{},{}&key={}&fields=place_id,name,type\".format(\n",
    "    'Speedee Mart 123',36.013831,-115.155348, api_key)\n",
    "response_placeSearch =requests.get(url_placeSearch)\n",
    "response_placeSearchJSON= response_placeSearch.json()\n",
    "\n",
    "\n",
    "df_fix001.loc[df_fix001.business_id=='De1sTuZgJfNxh4YIFzNX6A', 'placeSearch_status'] = response_placeSearchJSON['status']\n",
    "\n",
    "if(response_placeSearchJSON['status'] == 'OK'):\n",
    "    df_fix001.loc[df_fix001.business_id=='De1sTuZgJfNxh4YIFzNX6A', 'business_place_id'] = response_placeSearchJSON['candidates'][0]['place_id']\n",
    "    df_fix001.loc[df_fix001.business_id=='De1sTuZgJfNxh4YIFzNX6A', 'name_from_location'] = response_placeSearchJSON['candidates'][0]['name']\n",
    "    listTypes = response_placeSearchJSON['candidates'][0]['types']\n",
    "    strTypes =\", \".join(listTypes)\n",
    "    df_fix001.loc[df_fix001.business_id=='De1sTuZgJfNxh4YIFzNX6A', 'categories_from_location'] = strTypes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OK', 'ZERO_RESULTS'], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001[~df_fix001.placeSearch_status.isnull() ]['placeSearch_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fix001.to_csv(path_or_buf='/Users/kemalm/Desktop/Collection of fSets/fSet001.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split ;;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fix001 = pd.read_csv('/Users/kemalm/Desktop/Collection of fSets/fSet001.csv')\n",
    "df_fix001.loc[ df_fix001['address'].isnull(), 'address'] = ''\n",
    "df_fix001.loc[ df_fix001['address_from_coord'].isnull(), 'address_from_coord'] = ''\n",
    "df_fix001.loc[ df_fix001['city_from_coord'].isnull(), 'city_from_coord'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlist_2 = df_fix001[df_fix001.placeSearch_status.isnull()][['business_id','name', 'latitude','longitude']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "827"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fixlist_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter:  0\n",
      "Counter:  50\n",
      "Counter:  100\n",
      "Counter:  150\n",
      "Counter:  200\n",
      "Counter:  250\n",
      "Counter:  300\n",
      "Counter:  350\n",
      "Counter:  400\n",
      "Counter:  450\n",
      "Counter:  500\n",
      "Counter:  550\n",
      "Counter:  600\n",
      "Counter:  650\n",
      "Counter:  700\n",
      "Counter:  750\n",
      "Counter:  800\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for el in fixlist_2:\n",
    "    b_name = el['name']\n",
    "    b_lat = el['latitude']\n",
    "    b_long = el['longitude']\n",
    "\n",
    "    url_placeSearch =\"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={}&inputtype=textquery&locationbias=circle:100@{},{}&key={}&fields=place_id,name,type\".format(\n",
    "    b_name,b_lat,b_long ,api_key)\n",
    "       \n",
    "    resp_ps =requests.get(url_placeSearch)\n",
    "    resp_psDict= resp_ps.json()\n",
    "    df_fix001.loc[df_fix001.business_id==el['business_id'],'placeSearch_status'] = resp_psDict['status']  # 1\n",
    "    if(resp_psDict['status']=='OK'):\n",
    "        df_fix001.loc[df_fix001.business_id==el['business_id'], 'business_place_id'] = resp_psDict['candidates'][0]['place_id']\n",
    "        df_fix001.loc[df_fix001.business_id==el['business_id'], 'name_from_location'] = resp_psDict['candidates'][0]['name']\n",
    "        listTypes = resp_psDict['candidates'][0]['types']\n",
    "        strTypes =\", \".join(listTypes)\n",
    "        df_fix001.loc[df_fix001.business_id==el['business_id'], 'categories_from_location'] = strTypes\n",
    "    if(counter % 50 ==0):\n",
    "        print(\"Counter: \", counter)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 27)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001[df_fix001.placeSearch_status.isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "name_from_location              2839\n",
       "name_score                      2109\n",
       "address                         3000\n",
       "address_from_coord              3000\n",
       "addr_score                      2794\n",
       "formatted_address_from_coord    3000\n",
       "city                            3000\n",
       "city_from_coord                 3000\n",
       "state                           3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2860\n",
       "longitude                       3000\n",
       "longitude_from_address          2860\n",
       "dist_diff                       2860\n",
       "categories                      2984\n",
       "categories_from_location        2839\n",
       "categories_score                2109\n",
       "place_id_from_address           2860\n",
       "place_id_from_coord             3000\n",
       "business_place_id               2839\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "placeSearch_status              3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001[~df_fix001.isnull()].count().column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OK', 'ZERO_RESULTS', nan], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001.geocoding_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OK'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001.invgeocoding_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OK', 'ZERO_RESULTS'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001.placeSearch_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 27)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fix001.rename(columns={\"addr_score\": \"aScore_tokenSet\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# whenever i have to write to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                 3000\n",
       "name                        3000\n",
       "name_from_location          2839\n",
       "nScore_tokenSet             3000\n",
       "nScore_leven                3000\n",
       "address                     3000\n",
       "stand_address               3000\n",
       "address_from_coord          3000\n",
       "aScore_tokenSet             3000\n",
       "aScore_leven                3000\n",
       "city                        3000\n",
       "city_from_coord             3000\n",
       "state                       3000\n",
       "state_from_coord            3000\n",
       "latitude                    3000\n",
       "latitude_prec               3000\n",
       "latitude_from_address       2860\n",
       "longitude                   3000\n",
       "longitude_prec              3000\n",
       "longitude_from_address      2860\n",
       "dist_diff                   2860\n",
       "dMetric_score               3000\n",
       "categories                  3000\n",
       "categories_mapping          3000\n",
       "categories_from_location    3000\n",
       "categories_score            3000\n",
       "geocoding_status            2876\n",
       "invgeocoding_status         3000\n",
       "placeSearch_status          3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001[~df_fix001.isnull()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fix001.to_csv(path_or_buf='/Users/kemalm/Desktop/Collection of fSets/fSet002.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fix001."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# whenever i have to import from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_fix001 = pd.read_csv('/Users/kemalm/Desktop/Collection of fSets/fSet002.csv')\n",
    "df_fix001.loc[ df_fix001['address'].isnull(), 'address'] = ''\n",
    "df_fix001.loc[ df_fix001['stand_address'].isnull(), 'stand_address'] = ''\n",
    "df_fix001.loc[ df_fix001['address_from_coord'].isnull(), 'address_from_coord'] = ''\n",
    "df_fix001.loc[ df_fix001['city_from_coord'].isnull(), 'city_from_coord'] = ''\n",
    "df_fix001.loc[ df_fix001['categories'].isnull(), 'categories'] = ''\n",
    "df_fix001.loc[ df_fix001['categories_mapping'].isnull(), 'categories_mapping'] = ''\n",
    "df_fix001.loc[ df_fix001['categories_from_location'].isnull(), 'categories_from_location'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                 3000\n",
       "name                        3000\n",
       "name_from_location          2839\n",
       "nScore_tokenSet             3000\n",
       "nScore_leven                3000\n",
       "nScore_total                3000\n",
       "address                     3000\n",
       "stand_address               3000\n",
       "address_from_coord          3000\n",
       "aScore_tokenSet             3000\n",
       "aScore_leven                3000\n",
       "city                        3000\n",
       "city_from_coord             3000\n",
       "state                       3000\n",
       "state_from_coord            3000\n",
       "latitude                    3000\n",
       "latitude_prec               3000\n",
       "latitude_from_address       2860\n",
       "longitude                   3000\n",
       "longitude_prec              3000\n",
       "longitude_from_address      2860\n",
       "dist_diff                   2860\n",
       "dMetric_score               3000\n",
       "categories                  3000\n",
       "categories_mapping          3000\n",
       "categories_from_location    3000\n",
       "categories_score            3000\n",
       "geocoding_status            2876\n",
       "invgeocoding_status         3000\n",
       "placeSearch_status          3000\n",
       "larger_length               3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001[~df_fix001.isnull()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'name', 'name_from_location', 'nScore_tokenSet',\n",
       "       'nScore_leven', 'address', 'stand_address', 'address_from_coord',\n",
       "       'aScore_tokenSet', 'aScore_leven', 'aScore_absDiff',\n",
       "       'formatted_address_from_coord', 'city', 'city_from_coord', 'state',\n",
       "       'state_from_coord', 'country_from_coord', 'latitude', 'latitude_prec',\n",
       "       'latitude_from_address', 'longitude', 'longitude_prec',\n",
       "       'longitude_from_address', 'dist_diff', 'dMetric_score', 'categories',\n",
       "       'categories_mapping', 'categories_from_location', 'categories_score',\n",
       "       'place_id_from_address', 'place_id_from_coord', 'business_place_id',\n",
       "       'geocoding_status', 'invgeocoding_status', 'placeSearch_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fix001 = df_fix001.drop(['aScore_leven'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization (address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = df_fix001.to_dict('records')\n",
    "common_words = dict()\n",
    "for el in temp_list:\n",
    "    address = el['address']\n",
    "    if(address!=''):\n",
    "        words = [x for x in address.split(' ') if x.isalpha() == True]\n",
    "        for w in words:\n",
    "            if common_words.get(w) is None:\n",
    "                common_words[w]=1\n",
    "            else:\n",
    "                common_words[w]+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "srr_common_words = pd.Series(common_words).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ste            634\n",
       "Rd             444\n",
       "W              443\n",
       "E              407\n",
       "N              352\n",
       "S              289\n",
       "St             287\n",
       "Ave            268\n",
       "Street         194\n",
       "Blvd           190\n",
       "Avenue         133\n",
       "Dr             128\n",
       "Road            72\n",
       "Unit            72\n",
       "Las             65\n",
       "Rue             64\n",
       "Vegas           63\n",
       "Suite           57\n",
       "Pkwy            49\n",
       "Boulevard       45\n",
       "School          44\n",
       "Main            39\n",
       "Queen           38\n",
       "SW              34\n",
       "Yonge           34\n",
       "Center          31\n",
       "Bell            31\n",
       "Drive           31\n",
       "Hwy             30\n",
       "Rainbow         30\n",
       "              ... \n",
       "Germann          4\n",
       "Madison          4\n",
       "Hurontario       4\n",
       "G                4\n",
       "Saint            4\n",
       "Pike             4\n",
       "Mackenzie        4\n",
       "Toronto          4\n",
       "Cedar            4\n",
       "Major            4\n",
       "Lebanon          4\n",
       "Westney          4\n",
       "Concord          4\n",
       "H                4\n",
       "Rose             4\n",
       "Du               4\n",
       "Great            4\n",
       "Freeport         4\n",
       "Keele            4\n",
       "Crowfoot         4\n",
       "Buren            4\n",
       "Forbes           4\n",
       "Statesville      4\n",
       "Bayview          4\n",
       "Cheyenne         4\n",
       "Space            4\n",
       "Sherbrooke       4\n",
       "Roosevelt        4\n",
       "Darrow           4\n",
       "Bethany          4\n",
       "Length: 258, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srr_common_words[srr_common_words>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrs_to_words = dict()\n",
    "words_to_abbrs =dict()\n",
    "with open('/Users/kemalm/Desktop/Collection of fSets/fileToImport.txt','r',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        seg=line.split('<TD>')\n",
    "        abbr, word = seg[0].lower().capitalize(), seg[1].replace('\\n','').lower().capitalize()\n",
    "        abbrs_to_words[abbr]=word\n",
    "        words_to_abbrs[word]=abbr\n",
    "        \n",
    "w_s = ['North','West','South','East', 'Northwest','Northeast','Southwest','Southeast']\n",
    "w_sabbr = ['N','W','S','E','NW','NE','SW','SE']\n",
    "\n",
    "for i in range(0,len(w_s)):\n",
    "    abbrs_to_words[w_sabbr[i]]=w_s[i]\n",
    "    words_to_abbrs[w_s[i]]=w_sabbr[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fix001.insert(5,'stand_address','')\n",
    "#df_fix001.insert(8, 'aScore_leven', 0)\n",
    "#df_fix001.insert(9, 'aScore_absDiff', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Levenshtein\n",
    "Levenshtein.distance(\"store\",\"shopping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(df_fix001.itertuples(index=False)):\n",
    "    business_id = row.__getattribute__('business_id')\n",
    "    address = row.__getattribute__('address')\n",
    "    if(address != ''):\n",
    "        substrs = address.split(' ')\n",
    "\n",
    "        for i in range(0,len(substrs),1):\n",
    "            if substrs[i].replace(',','') in abbrs_to_words.keys():\n",
    "                substrs[i] = abbrs_to_words[substrs[i].replace(',','')]\n",
    "        frm_address = ' '.join(substrs)\n",
    "        df_fix001.loc[df_fix001.business_id==business_id, 'stand_address']= frm_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# address scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'name', 'name_from_location', 'nScore_tokenSet',\n",
       "       'nScore_leven', 'nScore_total', 'address', 'stand_address',\n",
       "       'address_from_coord', 'aScore_tokenSet', 'city', 'city_from_coord',\n",
       "       'state', 'state_from_coord', 'latitude', 'latitude_prec',\n",
       "       'latitude_from_address', 'longitude', 'longitude_prec',\n",
       "       'longitude_from_address', 'dist_diff', 'dMetric_score', 'categories',\n",
       "       'categories_mapping', 'categories_from_location', 'categories_score',\n",
       "       'geocoding_status', 'invgeocoding_status', 'placeSearch_status',\n",
       "       'larger_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fix001.insert(10,'address_EnablePenalty',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import Levenshtein as lv\n",
    "for idx, row in enumerate(df_fix001.itertuples(index=False)):\n",
    "    business_id = row.__getattribute__('business_id')\n",
    "    stand_addr=row.__getattribute__('stand_address')\n",
    "    addr_c = row.__getattribute__('address_from_coord')\n",
    "    \n",
    "    if(type(stand_addr)!=str):\n",
    "        stand_addr=''\n",
    "    if(type(addr_c)!=str):\n",
    "        addr_c=''\n",
    "    \n",
    "    #sa_list = [x for x in stand_addr if x.isalnum()==True]\n",
    "    #sa_list.sort()\n",
    "    #stand_addr= ' '.join(sa_list).lower()\n",
    "    \n",
    "    #ac_list = [x for x in addr_c if x.isalnum()==True]\n",
    "    #ac_list.sort()\n",
    "    #addr_c= ' '.join(ac_list).lower()\n",
    "    \n",
    "    \n",
    "    score_tokenSet = fuzz.token_set_ratio(stand_addr,addr_c)\n",
    "    score_leven = lv.distance(stand_addr,addr_c)\n",
    "    maxLen= max(len(stand_addr),len(addr_c))\n",
    "    num = score_leven - abs(len(stand_addr) - len(addr_c) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_fix001.loc[df_fix001.business_id ==business_id, 'aScore_tokenSet' ] = score_tokenSet\n",
    "    df_fix001.loc[df_fix001.business_id ==business_id, 'aScore_leven' ] = score_leven\n",
    "    if(len(stand_addr)==0 and len(addr_c)>0 ):\n",
    "        df_fix001.loc[df_fix001.business_id ==business_id, 'address_EnablePenalty' ] = True\n",
    "    #comp1= 0.7*score_tokenSet\n",
    "    #if(maxLen>0.0):\n",
    "     #   comp2= 0.3*(100.0 - 100*(num/maxLen))\n",
    "    #else:\n",
    "    #    comp2=0.0\n",
    "    df_fix001.loc[df_fix001.business_id ==business_id\n",
    "                  , 'aScore_total' ] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2 ='The Zoldan Law Group', 'The Zoldan Law Group - Employment Law Employee Discrimination Wrongful Termination Lawyer Attorney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(fuzz.token_set_ratio(s1,s2))\n",
    "print(fuzz.token_set_ratio(s2,s1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# name scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fix001.insert(5,'n_maxlen',0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fix001= df_fix001.drop([1],axis=1)\n",
    "#df_fix001.insert(3,'nScore_tokenSet',0.0)\n",
    "#df_fix001.insert(4,'nScore_leven',0.0)\n",
    "#df_fix001.insert(5,'nFinalScore',0.0)\n",
    "#df_fix001.insert(5,'nLeven_to_len_ratio', 0.0)\n",
    "#df_fix001.insert(6,'n_seq_matcher', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'name', 'name_from_location', 'nScore_wghtAvgTok',\n",
       "       'nScore_leven', 'nScore_total', 'address', 'stand_address',\n",
       "       'address_from_coord', 'aScore_tokenSet', 'address_EnablePenalty',\n",
       "       'city', 'city_from_coord', 'cityScore_leven', 'state',\n",
       "       'state_from_coord', 'stateScore_leven', 'latitude', 'latitude_prec',\n",
       "       'latitude_from_address', 'longitude', 'longitude_prec',\n",
       "       'longitude_from_address', 'dist_diff', 'dMetric_score', 'categories',\n",
       "       'categories_mapping', 'categories_from_location', 'categories_score',\n",
       "       'geocoding_status', 'invgeocoding_status', 'placeSearch_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001.columns\n",
    "#df_fix001.insert(3,'nScore_wghtAvgTok', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import math as mt\n",
    "import Levenshtein as lv\n",
    "import pandas as pd\n",
    "\n",
    "for idx, row in enumerate(df_fix001.itertuples(index=False)):\n",
    "    business_id = row.__getattribute__('business_id')\n",
    "    name=row.__getattribute__('name')\n",
    "    name_loc = row.__getattribute__('name_from_location')\n",
    "    if(type(name_loc)!=str):\n",
    "        name_loc=''\n",
    "    name=name.lower()\n",
    "    name_loc=name_loc.lower()\n",
    "    \n",
    "    \n",
    "    \n",
    "    score_tokenSet = fuzz.token_set_ratio(name,name_loc)\n",
    "    score_parttokenSet = fuzz.partial_token_set_ratio(name,name_loc)\n",
    "\n",
    "\n",
    "    score_leven = lv.distance(name,name_loc)\n",
    "    \n",
    "    n_list = [x for x in name.split(' ')]\n",
    "    n_list.sort()\n",
    "    nname= ' '.join(n_list).lower()\n",
    "    \n",
    "    na_list = [x for x in name_loc.split(' ')]\n",
    "    na_list.sort()\n",
    "    nname_loc= ' '.join(na_list).lower()\n",
    "    \n",
    "    overf = min(score_leven,lv.distance(nname,nname_loc))\n",
    "    \n",
    "    comp1 = 0.3 * score_tokenSet\n",
    "    comp2 = 0.7 * score_parttokenSet\n",
    "    \n",
    "    maxLen= max(len(name),len(name_loc)) \n",
    "    num = overf - abs(len(name) - len(name_loc) )\n",
    "    df_fix001.loc[df_fix001.business_id ==business_id, 'nScore_wghtAvgTok' ] = comp1+comp2\n",
    "    df_fix001.loc[df_fix001.business_id ==business_id, 'nScore_leven' ] = score_leven\n",
    "    \n",
    "    \n",
    "    tcomp1= 0.55*(comp1+comp2)\n",
    "    tcomp2= 0.45*(100.0 - 100*(num/maxLen))\n",
    "    \n",
    "    if(len(name_loc)>0):\n",
    "        df_fix001.loc[df_fix001.business_id ==business_id, 'nScore_total' ] = tcomp1+tcomp2\n",
    "    else:\n",
    "        df_fix001.loc[df_fix001.business_id ==business_id, 'nScore_total' ] =0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coord precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fix001=  df_fix001.drop(['coord_precision'],axis=1)\n",
    "#df_fix001.insert(19, 'latitude_prec', 0)\n",
    "#df_fix001.insert(22, 'longitude_prec', 0)\n",
    "#df_fix001.columns\n",
    "for idx, row in enumerate(df_fix001.itertuples(index=False)):\n",
    "    business_id = row.__getattribute__('business_id')\n",
    "    lat=row.__getattribute__('latitude')\n",
    "    long = row.__getattribute__('longitude')\n",
    "    \n",
    "    lat_prec= len(str(lat).split('.')[1])\n",
    "    long_prec= len(str(long).split('.')[1])\n",
    "    df_fix001.loc[df_fix001.business_id ==business_id, 'latitude_prec' ] = lat_prec\n",
    "    df_fix001.loc[df_fix001.business_id ==business_id, 'longitude_prec' ] = long_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fix001[['latitude','longitude', 'latitude_prec', 'longitude_prec']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# City score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fix001 = df_fix001.drop(['cityScore_leven'],axis=1)\n",
    "#df_fix001.insert(13,'cityScore_leven', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(df_fix001.itertuples(index=False)):\n",
    "    business_id = row.__getattribute__('business_id')\n",
    "    city=row.__getattribute__('city')\n",
    "    city_from_coord = row.__getattribute__('city_from_coord')\n",
    "    \n",
    "    if(type(city_from_coord)!=str):\n",
    "        city_from_coord=''       \n",
    "    leven_score = lv.distance(city,city_from_coord)\n",
    "    df_fix001.loc[df_fix001.business_id ==business_id, 'cityScore_leven' ] = leven_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fix001.insert(14,'city_score',0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(df_fix001.itertuples(index=False)):\n",
    "    business_id = row.__getattribute__('business_id')\n",
    "    city=row.__getattribute__('city')\n",
    "    city_from_coord = row.__getattribute__('city_from_coord')\n",
    "    cityScore_leven = row.__getattribute__('cityScore_leven')\n",
    "    \n",
    "    if(type(city_from_coord)!=str):\n",
    "        city_from_coord=''       \n",
    "    \n",
    "    maxLen = max(len(city),len(city_from_coord))\n",
    "    df_fix001.loc[df_fix001.business_id ==business_id, 'city_score' ] = 100* (1-(cityScore_leven/maxLen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fix001.insert(16,'stateScore_leven', 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'name', 'name_from_location', 'nScore_wghtAvgTok',\n",
       "       'nScore_leven', 'nScore_total', 'address', 'stand_address',\n",
       "       'address_from_coord', 'aScore_tokenSet', 'address_EnablePenalty',\n",
       "       'city', 'city_from_coord', 'cityScore_leven', 'city_score', 'state',\n",
       "       'state_from_coord', 'stateScore_leven', 'state_score', 'latitude',\n",
       "       'latitude_prec', 'latitude_from_address', 'longitude', 'longitude_prec',\n",
       "       'longitude_from_address', 'dist_diff', 'dMetric_score', 'categories',\n",
       "       'categories_mapping', 'categories_from_location', 'categories_score',\n",
       "       'categories_PenaltyEnabled', 'geocoding_status', 'invgeocoding_status',\n",
       "       'placeSearch_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fix001.insert(18,'state_score',0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(df_fix001.itertuples(index=False)):\n",
    "    business_id = row.__getattribute__('business_id')\n",
    "    state=row.__getattribute__('state')\n",
    "    state_from_coord = row.__getattribute__('state_from_coord')\n",
    "    \n",
    "    if(type(state_from_coord)!=str):\n",
    "        state_from_coord=''  \n",
    "    maxLen = max(len(state),len(state_from_coord))\n",
    "    leven_score = lv.distance(state,state_from_coord)\n",
    "    df_fix001.loc[df_fix001.business_id ==business_id, 'stateScore_leven' ] = leven_score\n",
    "    df_fix001.loc[df_fix001.business_id ==business_id, 'state_score' ] = 100.0*(1- (leven_score/maxLen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categories score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fix001= df_fix001.drop(['categories_score'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                  3000\n",
       "name                         3000\n",
       "name_from_location           2839\n",
       "nScore_wghtAvgTok            3000\n",
       "nScore_leven                 3000\n",
       "nScore_total                 3000\n",
       "address                      3000\n",
       "stand_address                3000\n",
       "address_from_coord           3000\n",
       "aScore_tokenSet              3000\n",
       "address_EnablePenalty        3000\n",
       "city                         3000\n",
       "city_from_coord              3000\n",
       "cityScore_leven              3000\n",
       "state                        3000\n",
       "state_from_coord             3000\n",
       "stateScore_leven             3000\n",
       "latitude                     3000\n",
       "latitude_prec                3000\n",
       "latitude_from_address        2860\n",
       "longitude                    3000\n",
       "longitude_prec               3000\n",
       "longitude_from_address       2860\n",
       "dist_diff                    2860\n",
       "dMetric_score                3000\n",
       "categories                   3000\n",
       "categories_mapping           3000\n",
       "categories_from_location     3000\n",
       "categories_score             3000\n",
       "categories_PenaltyEnabled    3000\n",
       "geocoding_status             2876\n",
       "invgeocoding_status          3000\n",
       "placeSearch_status           3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_fix001.insert(29, 'categories_PenaltyEnabled', False)\n",
    "df_fix001[~df_fix001.isnull()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(df_fix001.itertuples(index=False)):\n",
    "    business_id = row.__getattribute__('business_id')\n",
    "    categories = row.__getattribute__('categories')\n",
    "    ca_cl = row.__getattribute__('categories_from_location')    \n",
    "    if(len(categories)==0 and len(ca_cl)>1):\n",
    "        df_fix001.loc[df_fix001.business_id==business_id,\"categories_PenaltyEnabled\"]= True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "YelpCategories = dict()\n",
    "for idx, row in enumerate(df_fix001.itertuples(index=False)):\n",
    "    ca = row.__getattribute__('categories')\n",
    "    if(type(ca)==str):\n",
    "        ls_ca = ca.lower().split(', ')\n",
    "        for el in ls_ca:\n",
    "            if(YelpCategories.get(el) is None):\n",
    "                YelpCategories[el]=1\n",
    "            else:\n",
    "                YelpCategories[el]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "srr_yelpCategories = pd.Series(YelpCategories).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "restaurants                   885\n",
       "shopping                      524\n",
       "food                          506\n",
       "home services                 305\n",
       "beauty & spas                 295\n",
       "health & medical              265\n",
       "automotive                    236\n",
       "local services                225\n",
       "nightlife                     189\n",
       "event planning & services     166\n",
       "bars                          161\n",
       "active life                   143\n",
       "home & garden                 128\n",
       "auto repair                   126\n",
       "fashion                       124\n",
       "sandwiches                    118\n",
       "coffee & tea                  117\n",
       "fast food                     104\n",
       "hair salons                   104\n",
       "pizza                         102\n",
       "hotels & travel               101\n",
       "american (traditional)         94\n",
       "specialty food                 91\n",
       "arts & entertainment           89\n",
       "doctors                        88\n",
       "professional services          84\n",
       "real estate                    83\n",
       "american (new)                 82\n",
       "burgers                        81\n",
       "nail salons                    78\n",
       "                             ... \n",
       "ultrasound imaging centers      1\n",
       "mobile dent repair              1\n",
       "motorcycle gear                 1\n",
       "champagne bars                  1\n",
       "patio coverings                 1\n",
       "vacation rentals                1\n",
       "installment loans               1\n",
       "strip clubs                     1\n",
       "cabaret                         1\n",
       "aviation services               1\n",
       "shanghainese                    1\n",
       "waterproofing                   1\n",
       "university housing              1\n",
       "scavenger hunts                 1\n",
       "wine tours                      1\n",
       "hypnosis/hypnotherapy           1\n",
       "fireplace services              1\n",
       "public relations                1\n",
       "wine tasting room               1\n",
       "herbal shops                    1\n",
       "life coach                      1\n",
       "distilleries                    1\n",
       "motorcycle rental               1\n",
       "bartending schools              1\n",
       "dui law                         1\n",
       "wedding chapels                 1\n",
       "commercial truck repair         1\n",
       "bookkeepers                     1\n",
       "payroll services                1\n",
       "tui na                          1\n",
       "Length: 820, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srr_yelpCategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleCategories = dict()\n",
    "for idx, row in enumerate(df_fix001.itertuples(index=False)):\n",
    "    ca = row.__getattribute__('categories_from_location')\n",
    "    if(type(ca)==str):\n",
    "        ls_ca = ca.replace('_',' ').split(', ')\n",
    "        for el in ls_ca:\n",
    "            if(GoogleCategories.get(el) is None):\n",
    "                GoogleCategories[el]=1\n",
    "            else:\n",
    "                GoogleCategories[el]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "srr_googleCategories= pd.Series(GoogleCategories).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time  1.6788978576660156  seconds.\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "import Levenshtein as lv\n",
    "from fuzzywuzzy import fuzz\n",
    "start=time.time()\n",
    "\n",
    "mappingDict =dict()\n",
    "for el in list(srr_yelpCategories.keys()):\n",
    "    d = dict()\n",
    "    for el2 in list(srr_googleCategories.keys()):\n",
    "        token_score = fuzz.token_set_ratio(el,el2)\n",
    "        #leven_score = 100-lv.distance(el,el2)\n",
    "        d[el2]=token_score\n",
    "    s1=pd.Series(d).sort_values(ascending=False)\n",
    "    #print(\"-----------------------------------\")\n",
    "    #print(\"Element #\", el)\n",
    "    #print(s1)\n",
    "    #print(\"-----------------------------------\")\n",
    "    if(s1.iloc[0]>=90):\n",
    "        mappingDict[el] = s1.keys()[0]\n",
    "    else:\n",
    "        mappingDict[el]=''\n",
    "end = time.time()\n",
    "print(\"Execution time \", end - start,\" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "srr_mapping = pd.Series(mappingDict)\n",
    "with open('/Users/kemalm/Desktop/Categories matching/categoriesMatching.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in range(0,len(list(srr_mapping.keys())),1):   \n",
    "        string_to_write=\"{}\\t|\\t{}\\n\".format(srr_mapping.keys()[i],srr_mapping.iloc[i])\n",
    "        f.write(string_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     820 /Users/kemalm/Desktop/Categories matching/categoriesMatching.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l '/Users/kemalm/Desktop/Categories matching/categoriesMatching.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'name', 'name_from_location', 'nScore_tokenSet',\n",
       "       'nScore_leven', 'nScore_absDiff', 'address', 'stand_address',\n",
       "       'address_from_coord', 'aScore_tokenSet', 'aScore_leven',\n",
       "       'aScore_absDiff', 'formatted_address_from_coord', 'city',\n",
       "       'city_from_coord', 'state', 'state_from_coord', 'country_from_coord',\n",
       "       'latitude', 'latitude_prec', 'latitude_from_address', 'longitude',\n",
       "       'longitude_prec', 'longitude_from_address', 'dist_diff', 'categories',\n",
       "       'categories_mapping', 'categories_from_location', 'categories_score',\n",
       "       'place_id_from_address', 'place_id_from_coord', 'business_place_id',\n",
       "       'geocoding_status', 'invgeocoding_status', 'placeSearch_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_fix001.insert(26,'categories_mapping','')\n",
    "df_fix001.insert(28,'categories_score',0.0)\n",
    "df_fix001.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(df_fix001.itertuples(index=False)):\n",
    "    business_id = row.__getattribute__('business_id')\n",
    "    categories = row.__getattribute__('categories')\n",
    "    if(type(categories)==str):\n",
    "        list_categ = categories.lower().split(', ')\n",
    "        list_mapped_categ=[]\n",
    "        for el in list_categ:\n",
    "            mapp_el =srr_mapping[el]\n",
    "            if(mapp_el!=''):\n",
    "                list_mapped_categ.append(mapp_el)\n",
    "        list_mapped_categ= list(set(list_mapped_categ))\n",
    "        map_categories=', '.join(list_mapped_categ)\n",
    "        df_fix001.loc[df_fix001.business_id==business_id,\"categories_mapping\"]=map_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fix001[['categories','categories_mapping']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fix001.insert(28,'categories_score',0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(df_fix001.itertuples(index=False)):\n",
    "    business_id = row.__getattribute__('business_id')\n",
    "    ca = row.__getattribute__('categories').lower()\n",
    "    ca_map = row.__getattribute__('categories_mapping')\n",
    "    ca_loc = row.__getattribute__('categories_from_location').replace('_',' ') \n",
    "\n",
    "    ca_loc_list = ca_loc.split(', ')\n",
    "    ca_loc_list =[x for x in ca_loc_list if x not in ['point of interest','establishment'] ]\n",
    "    ca_loc = ', '.join(ca_loc_list)\n",
    "    \n",
    "    if(ca_map!=''):\n",
    "        matchFound = False  \n",
    "        ca_map_list = ca_map.split(', ')\n",
    "        for el in ca_map_list:\n",
    "            if el in ca_loc.split(', '):\n",
    "                matchFound=True\n",
    "                \n",
    "        if(matchFound == False):\n",
    "            scr = 0.0\n",
    "            for ca_el in ca.split(', '):\n",
    "                for ca_el2 in ca_loc.split(', '):\n",
    "                    if(scr <= fuzz.token_set_ratio(ca_el,ca_el2)):\n",
    "                        scr = fuzz.token_set_ratio(ca_el,ca_el2)\n",
    "            df_fix001.loc[df_fix001.business_id== business_id,'categories_score']= scr\n",
    "        else:\n",
    "            df_fix001.loc[df_fix001.business_id== business_id,'categories_score']= 100.0\n",
    "    else: \n",
    "        if (ca!=''):\n",
    "            scr = 0.0\n",
    "            for ca_el in ca.split(', '):\n",
    "                for ca_el2 in ca_loc.split(', '):\n",
    "                    if(scr <= fuzz.token_set_ratio(ca_el,ca_el2)):\n",
    "                        scr = fuzz.token_set_ratio(ca_el,ca_el2)\n",
    "            df_fix001.loc[df_fix001.business_id== business_id,'categories_score']= scr\n",
    "        else:\n",
    "            df_fix001.loc[df_fix001.business_id== business_id,'categories_score']= 0.0\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein as lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lv.distance('Eee','E  ee')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dist diff score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'name', 'name_from_location', 'nScore_wghtAvgTok',\n",
       "       'nScore_leven', 'nScore_total', 'address', 'stand_address',\n",
       "       'address_from_coord', 'aScore_tokenSet', 'address_EnablePenalty',\n",
       "       'city', 'city_from_coord', 'cityScore_leven', 'state',\n",
       "       'state_from_coord', 'stateScore_leven', 'latitude', 'latitude_prec',\n",
       "       'latitude_from_address', 'longitude', 'longitude_prec',\n",
       "       'longitude_from_address', 'dist_diff', 'dMetric_score', 'categories',\n",
       "       'categories_mapping', 'categories_from_location', 'categories_score',\n",
       "       'geocoding_status', 'invgeocoding_status', 'placeSearch_status',\n",
       "       'larger_length', 'aScore_leven', 'aScore_total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_fix001.insert(25,'dMetric_score',0.0)\n",
    "df_fix001.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "dScores = df_fix001.dist_diff.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_dScores = np.zeros((3000,2))\n",
    "threshold = 200.0\n",
    "matrix_dScores[:,0]= dScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "indNan = matrix_dScores[:,0]!=matrix_dScores[:,0]\n",
    "df_fix001.loc[indNan,1]=0.0\n",
    "\n",
    "indices = matrix_dScores[:,0]<=  threshold\n",
    "matrix_dScores[indices,1] = 100.0 *(1.0-(matrix_dScores[indices,0]/threshold) )**2\n",
    "indicesGreater = matrix_dScores[:,0]>=  threshold\n",
    "matrix_dScores[indicesGreater,1] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fix001.loc[:,'dMetric_score'] = matrix_dScores[:,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_diff</th>\n",
       "      <th>dMetric_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.529686e+00</td>\n",
       "      <td>90.697351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.180084e+00</td>\n",
       "      <td>96.845198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.181710e+00</td>\n",
       "      <td>98.821781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.211089e+02</td>\n",
       "      <td>15.559512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.169885e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.143054e-09</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.775434e+01</td>\n",
       "      <td>57.946849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.299756e-01</td>\n",
       "      <td>99.670297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.953468e+00</td>\n",
       "      <td>92.204676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.013568e+02</td>\n",
       "      <td>24.326209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.347786e+01</td>\n",
       "      <td>53.671846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.719899e-01</td>\n",
       "      <td>99.229500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.060393e-09</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.712302e-09</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.110081e-09</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.647538e+02</td>\n",
       "      <td>3.105741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.378310e+01</td>\n",
       "      <td>46.387609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.165918e+01</td>\n",
       "      <td>88.680659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.555517e-01</td>\n",
       "      <td>99.844509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.734357e+01</td>\n",
       "      <td>74.525606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.453096e-02</td>\n",
       "      <td>99.935479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>1.582685e+02</td>\n",
       "      <td>4.353789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>2.788673e+02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>6.193679e+01</td>\n",
       "      <td>47.653626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>5.236900e+01</td>\n",
       "      <td>54.487278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>6.683411e+01</td>\n",
       "      <td>44.332887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>1.193730e+02</td>\n",
       "      <td>16.251769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>3.476242e+01</td>\n",
       "      <td>68.258647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>2.446054e+01</td>\n",
       "      <td>77.035253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>3.506227e+01</td>\n",
       "      <td>68.011139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>1.433754e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>1.804675e+02</td>\n",
       "      <td>0.953793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>7.351976e+01</td>\n",
       "      <td>39.993131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>3.434116e+02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dist_diff  dMetric_score\n",
       "0     9.529686e+00      90.697351\n",
       "1     3.180084e+00      96.845198\n",
       "2     1.181710e+00      98.821781\n",
       "3     0.000000e+00     100.000000\n",
       "4     1.211089e+02      15.559512\n",
       "5     0.000000e+00     100.000000\n",
       "6     1.169885e+06       0.000000\n",
       "7     0.000000e+00     100.000000\n",
       "8     1.143054e-09     100.000000\n",
       "9     0.000000e+00     100.000000\n",
       "10    0.000000e+00     100.000000\n",
       "11    4.775434e+01      57.946849\n",
       "12    0.000000e+00     100.000000\n",
       "13    3.299756e-01      99.670297\n",
       "14    0.000000e+00     100.000000\n",
       "15    7.953468e+00      92.204676\n",
       "16    1.013568e+02      24.326209\n",
       "17    5.347786e+01      53.671846\n",
       "18    7.719899e-01      99.229500\n",
       "19    1.060393e-09     100.000000\n",
       "20    2.712302e-09     100.000000\n",
       "21    1.110081e-09     100.000000\n",
       "22    1.647538e+02       3.105741\n",
       "23    0.000000e+00     100.000000\n",
       "24    6.378310e+01      46.387609\n",
       "25    0.000000e+00     100.000000\n",
       "26    1.165918e+01      88.680659\n",
       "27    1.555517e-01      99.844509\n",
       "28    2.734357e+01      74.525606\n",
       "29    6.453096e-02      99.935479\n",
       "...            ...            ...\n",
       "2970  1.582685e+02       4.353789\n",
       "2971           NaN       0.000000\n",
       "2972  2.788673e+02       0.000000\n",
       "2973  6.193679e+01      47.653626\n",
       "2974           NaN       0.000000\n",
       "2975           NaN       0.000000\n",
       "2976           NaN       0.000000\n",
       "2977  5.236900e+01      54.487278\n",
       "2978  6.683411e+01      44.332887\n",
       "2979  1.193730e+02      16.251769\n",
       "2980           NaN       0.000000\n",
       "2981           NaN       0.000000\n",
       "2982           NaN       0.000000\n",
       "2983           NaN       0.000000\n",
       "2984  3.476242e+01      68.258647\n",
       "2985           NaN       0.000000\n",
       "2986           NaN       0.000000\n",
       "2987  2.446054e+01      77.035253\n",
       "2988           NaN       0.000000\n",
       "2989  3.506227e+01      68.011139\n",
       "2990  1.433754e+06       0.000000\n",
       "2991           NaN       0.000000\n",
       "2992  1.804675e+02       0.953793\n",
       "2993  7.351976e+01      39.993131\n",
       "2994           NaN       0.000000\n",
       "2995  3.434116e+02       0.000000\n",
       "2996           NaN       0.000000\n",
       "2997           NaN       0.000000\n",
       "2998           NaN       0.000000\n",
       "2999           NaN       0.000000\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fix001[['dist_diff','dMetric_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.5296858 , 90.69735148],\n",
       "       [ 3.180084  , 96.84519833],\n",
       "       [ 1.18170982, 98.82178128],\n",
       "       ...,\n",
       "       [        nan,  0.        ],\n",
       "       [        nan,  0.        ],\n",
       "       [        nan,  0.        ]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_dScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix_dScores[matrix_dScores[:,1] <=0.0][:,1] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fix001 = df_fix001.drop(['quality'],axis=1)\n",
    "#df_fix001.insert(32,'finalScore', 0.0)\n",
    "#df_fix001.insert(33,'quality', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight={\n",
    "    \"nScore_total\": 0.2,\n",
    "    \"aScore_tokenSet\": 0.2,\n",
    "    \"city_score\": 0.15,\n",
    "    \"state_score\": 0.05,\n",
    "    \"dMetric_score\": 0.25,\n",
    "    \"categories_score\":0.15\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(df_fix001.itertuples(index=False)):\n",
    "    \n",
    "    business_id = row.__getattribute__('business_id')   \n",
    "    nScore_total = row.__getattribute__('nScore_total')\n",
    "    aScore_tokenSet = row.__getattribute__('aScore_tokenSet')\n",
    "    city_score = row.__getattribute__('city_score')\n",
    "    state_score = row.__getattribute__('state_score')\n",
    "    dMetric_score = row.__getattribute__('dMetric_score')\n",
    "    categories_score = row.__getattribute__('categories_score')    \n",
    "    all_scores_list = [('nScore_total',nScore_total),\n",
    "                       ('aScore_tokenSet',aScore_tokenSet),\n",
    "                       ('city_score',city_score),\n",
    "                       ('state_score',state_score),\n",
    "                       ('dMetric_score',dMetric_score),\n",
    "                       ('categories_score',categories_score)]\n",
    "    \n",
    "    allComp = 0.0\n",
    "    for el in all_scores_list:\n",
    "        allComp+= weight[el[0]]*el[1]\n",
    "    df_fix001.loc[df_fix001.business_id==business_id,\"finalScore\"]=allComp\n",
    "    \n",
    "    if(allComp>=90):\n",
    "         df_fix001.loc[df_fix001.business_id==business_id,\"quality\"]='HIGH'\n",
    "    elif(allComp>=50 and allComp<90):\n",
    "         df_fix001.loc[df_fix001.business_id==business_id,\"quality\"]='MEDIUM'\n",
    "    else:\n",
    "         df_fix001.loc[df_fix001.business_id==business_id,\"quality\"]='LOW'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicates (string matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try:\n",
    "    conn=psycopg2.connect(\"dbname='yelpDB' user='postgres' host='localhost' password='P0$tgre$QL'\")\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"SELECT name, address, city, state\n",
    "               FROM Businesses\n",
    "               WHERE address <>''\n",
    "               ORDER BY address\"\"\")\n",
    "queryResult = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184927"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queryResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepList =[]\n",
    "\n",
    "for tupl in queryResult:\n",
    "    dictObj =dict()\n",
    "    dictObj['state']= tupl[3]\n",
    "    dictObj['city']= tupl[2]\n",
    "    \n",
    "    #tupl[1] -- address from DB\n",
    "    address = ''.join(c for c in tupl[1] if c.isalnum() or c==' ')\n",
    "    #print(tupl[1],\" | \",address)\n",
    "    address_as_list = address.split(' ')\n",
    "    address_as_list.sort(reverse=True)\n",
    "    prep_address =' '.join(address_as_list)\n",
    "    dictObj['prep_address'] = prep_address\n",
    "    dictObj['name']= tupl[0]\n",
    "    prepList.append(dictObj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df = pd.DataFrame(prepList).sort_values(by=['prep_address'])[['state','city','prep_address','name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_list_sorted = prep_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "prep_list_sorted_wth_scores = []\n",
    "for i in range(0,len(prep_list_sorted)):\n",
    "    dictObj=dict(prep_list_sorted[i])\n",
    "    if(i<len(prep_list_sorted)-1):\n",
    "        currObj, follObj = prep_list_sorted[i], prep_list_sorted[i+1]\n",
    "        if((currObj['state'] == follObj['state']) and (currObj['city'] == follObj['city'])):\n",
    "            addr_score_next_rec = fuzz.token_set_ratio(currObj['prep_address'], follObj['prep_address'])\n",
    "            dictObj['addr_score_next_rec']=addr_score_next_rec\n",
    "            name_score_next_rec = fuzz.token_set_ratio(currObj['name'], follObj['name'])\n",
    "            dictObj['name_score_next_rec']=name_score_next_rec\n",
    "    prep_list_sorted_wth_scores.append(dictObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184927"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prep_list_sorted_wth_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_dict_wth_scores = pd.DataFrame(prep_list_sorted_wth_scores)[[\n",
    "    'state',\n",
    "    'city',\n",
    "    'prep_address',\n",
    "    'addr_score_next_rec',\n",
    "    'name',\n",
    "    'name_score_next_rec' , ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify suspicous patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try:\n",
    "    conn=psycopg2.connect(\"dbname='yelpDB' user='postgres' host='localhost' password='P0$tgre$QL'\")\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"SELECT state,  COUNT(business_id) AS total_Count\n",
    "               FROM Businesses\n",
    "               GROUP BY state \n",
    "               ORDER BY 2 DESC\"\"\")\n",
    "statesQuery = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_states_prov_terr = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming',\n",
    "        'AB': 'Alberta',\n",
    "        'BC': 'British Columbia',\n",
    "        'MB': 'Manitoba',\n",
    "        'NB': 'New Brunswick',\n",
    "        'NL': 'Newfoundland and Labrador',\n",
    "        'NT': 'Northwest Territories',\n",
    "        'NS': 'Nova Scotia',\n",
    "        'NU': 'Nunavut',\n",
    "        'ON': 'Ontario',\n",
    "        'PE': 'Prince Edward Island',\n",
    "        'QC': 'Quebec',\n",
    "        'SK': 'Saskatchewan',\n",
    "        'YT': 'Yukon'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statesQuery = pd.DataFrame(statesQuery, columns=['state','total_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ</td>\n",
       "      <td>56686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NV</td>\n",
       "      <td>36312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ON</td>\n",
       "      <td>33412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NC</td>\n",
       "      <td>14720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OH</td>\n",
       "      <td>14697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  total_count\n",
       "0    AZ        56686\n",
       "1    NV        36312\n",
       "2    ON        33412\n",
       "3    NC        14720\n",
       "4    OH        14697"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_statesQuery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statesQuery['state_exists'] = df_statesQuery['state'].isin(dct_states_prov_terr.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_exist = np.array([ (el[0], int(el[0] in dct_states_prov_terr.keys())) for el in df_statesQuery])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>total_count</th>\n",
       "      <th>state_exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGM</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XWY</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DUR</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DOW</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BAS</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CON</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XGL</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  total_count  state_exists\n",
       "14   XGM            4         False\n",
       "19   XWY            2         False\n",
       "25   DUR            1         False\n",
       "27   DOW            1         False\n",
       "29   BAS            1         False\n",
       "31   CON            1         False\n",
       "33   XGL            1         False"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_statesQuery[df_statesQuery['state_exists'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get corresponding records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpl_str = str(list(df_statesQuery[df_statesQuery['state_exists'] == False]['state'].values)).replace('[','').replace(']','')\n",
    "\n",
    "cur.execute(\"\"\"SELECT *\n",
    "         FROM Businesses\n",
    "         WHERE state IN ({})\"\"\".format(rpl_str))\n",
    "all_recs =cur.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suspBus= pd.DataFrame(all_recs,columns=[\"business_id\",\n",
    "                                \"name\",\n",
    "                                \"address\",\n",
    "                                \"city\",\n",
    "                                \"state\",\n",
    "                                \"postal_code\",\n",
    "                                \"latitude\",\n",
    "                                \"longitude\",\n",
    "                                \"stars\",\n",
    "                                \"review_count\",\n",
    "                                \"is_open\",\n",
    "                                \"attributes\",\n",
    "                                \"categories\",\n",
    "                                \"hours\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svMJjPd4l_Zb_MoxejYZvw</td>\n",
       "      <td>Zoom Printing</td>\n",
       "      <td>1136 Center Street, Suite 442</td>\n",
       "      <td>Thornhill</td>\n",
       "      <td>DUR</td>\n",
       "      <td>L4J 3M8</td>\n",
       "      <td>43.808563</td>\n",
       "      <td>-79.463806</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>Professional Services, Advertising, Printing S...</td>\n",
       "      <td>{'Friday': '9:0-17:0', 'Monday': '9:0-17:0', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d4qoXn1Rqt47LLTDA3bAwQ</td>\n",
       "      <td>Thayer David Ice Cream Shop</td>\n",
       "      <td>8 York St</td>\n",
       "      <td>Bath</td>\n",
       "      <td>BAS</td>\n",
       "      <td>BA1 1NG</td>\n",
       "      <td>43.640646</td>\n",
       "      <td>-79.380939</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsPriceRange2': '1'}</td>\n",
       "      <td>Food, Ice Cream &amp; Frozen Yogurt</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8_GNJU3EPar9VkPzJvoC3w</td>\n",
       "      <td>Bean &amp; Brush Family Art Caf√©</td>\n",
       "      <td>The Old Sorting Office, 12 Hayfield Street</td>\n",
       "      <td>Sale</td>\n",
       "      <td>XGM</td>\n",
       "      <td>M33 7XW</td>\n",
       "      <td>42.996059</td>\n",
       "      <td>-89.568889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WiFi': 'u'free'', 'Caters': 'True', 'BikePar...</td>\n",
       "      <td>Arts &amp; Crafts, Shopping, Coffee &amp; Tea, Food</td>\n",
       "      <td>{'Friday': '8:30-19:0', 'Monday': '8:30-19:0',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44xjnQMwAQjgZ80MW5z-Gg</td>\n",
       "      <td>No. 37 Sandwich Bar</td>\n",
       "      <td>37 Monk Bridge Road</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>XWY</td>\n",
       "      <td>LS6 4EP</td>\n",
       "      <td>45.456999</td>\n",
       "      <td>-73.595250</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WiFi': ''no'', 'Alcohol': 'u'none'', 'Outdoo...</td>\n",
       "      <td>Bakeries, Food, Desserts, Restaurants, Sandwiches</td>\n",
       "      <td>{'Friday': '7:0-15:0', 'Monday': '7:0-15:0', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eeEcf7XXAGClqdUCwnwRfg</td>\n",
       "      <td>The Old Lifeboat House</td>\n",
       "      <td>The Cove, Coverack Helston</td>\n",
       "      <td>Church Cove</td>\n",
       "      <td>CON</td>\n",
       "      <td>TR12 6SX</td>\n",
       "      <td>35.532021</td>\n",
       "      <td>-80.851682</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsTakeOut': 'True', 'RestaurantsDel...</td>\n",
       "      <td>British, Restaurants</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JNZeVq9jr9AWURmnM-Yxig</td>\n",
       "      <td>Total Gardening and Landscaping</td>\n",
       "      <td></td>\n",
       "      <td>Bury</td>\n",
       "      <td>XGM</td>\n",
       "      <td>BL8 4DR</td>\n",
       "      <td>42.996059</td>\n",
       "      <td>-89.568889</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'ByAppointmentOnly': 'False', 'BusinessAccept...</td>\n",
       "      <td>Home Services, Landscaping, Tree Services, Gar...</td>\n",
       "      <td>{'Friday': '0:0-0:0', 'Monday': '0:0-0:0', 'Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6dhkHf-CFHr7C8wj-qopCQ</td>\n",
       "      <td>Paper Cutz</td>\n",
       "      <td>Gorebrook Works, Pinkbank Lane</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>XGM</td>\n",
       "      <td>M12 5GH</td>\n",
       "      <td>42.996059</td>\n",
       "      <td>-89.568889</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessParking': '{'garage': False, 'valida...</td>\n",
       "      <td>Art Supplies, Arts &amp; Crafts, Shopping</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FByZsT1Sob5Vf1AYJFPxPg</td>\n",
       "      <td>Desi Masala</td>\n",
       "      <td>61 Queen Street</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>XWY</td>\n",
       "      <td>LS27 8EB</td>\n",
       "      <td>43.652821</td>\n",
       "      <td>-79.376345</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WiFi': ''no'', 'HasTV': 'True', 'Alcohol': '...</td>\n",
       "      <td>Indian, Pakistani, Restaurants</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xjR-PII302WyyNRfpcowDg</td>\n",
       "      <td>Moxon's Fishmongers</td>\n",
       "      <td>110 Islington High Street</td>\n",
       "      <td>London</td>\n",
       "      <td>XGL</td>\n",
       "      <td>N1 8EG</td>\n",
       "      <td>43.645355</td>\n",
       "      <td>-79.524467</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessParking': '{'garage': False, 'street...</td>\n",
       "      <td>Specialty Food, Food, Seafood Markets</td>\n",
       "      <td>{'Friday': '9:0-19:30', 'Tuesday': '9:0-19:30'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZsL7FUkaWdyQnDoYB6XpSA</td>\n",
       "      <td>Happy Gathering Resturant Oldham</td>\n",
       "      <td></td>\n",
       "      <td>Oldham</td>\n",
       "      <td>XGM</td>\n",
       "      <td>OL2 6PX</td>\n",
       "      <td>42.996059</td>\n",
       "      <td>-89.568889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>Chinese, Restaurants</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>U9uyfhpZ89VEH5_webJ5Xg</td>\n",
       "      <td>Storm Cinemas - Belfast</td>\n",
       "      <td>Odyssey Arena, 2 Queens Quay</td>\n",
       "      <td>Down</td>\n",
       "      <td>DOW</td>\n",
       "      <td>BT33 0</td>\n",
       "      <td>43.641658</td>\n",
       "      <td>-79.376030</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id                              name  \\\n",
       "0   svMJjPd4l_Zb_MoxejYZvw                     Zoom Printing   \n",
       "1   d4qoXn1Rqt47LLTDA3bAwQ       Thayer David Ice Cream Shop   \n",
       "2   8_GNJU3EPar9VkPzJvoC3w      Bean & Brush Family Art Caf√©   \n",
       "3   44xjnQMwAQjgZ80MW5z-Gg               No. 37 Sandwich Bar   \n",
       "4   eeEcf7XXAGClqdUCwnwRfg            The Old Lifeboat House   \n",
       "5   JNZeVq9jr9AWURmnM-Yxig   Total Gardening and Landscaping   \n",
       "6   6dhkHf-CFHr7C8wj-qopCQ                        Paper Cutz   \n",
       "7   FByZsT1Sob5Vf1AYJFPxPg                       Desi Masala   \n",
       "8   xjR-PII302WyyNRfpcowDg               Moxon's Fishmongers   \n",
       "9   ZsL7FUkaWdyQnDoYB6XpSA  Happy Gathering Resturant Oldham   \n",
       "10  U9uyfhpZ89VEH5_webJ5Xg           Storm Cinemas - Belfast   \n",
       "\n",
       "                                       address         city state postal_code  \\\n",
       "0                1136 Center Street, Suite 442    Thornhill   DUR     L4J 3M8   \n",
       "1                                    8 York St         Bath   BAS     BA1 1NG   \n",
       "2   The Old Sorting Office, 12 Hayfield Street         Sale   XGM     M33 7XW   \n",
       "3                          37 Monk Bridge Road        Leeds   XWY     LS6 4EP   \n",
       "4                   The Cove, Coverack Helston  Church Cove   CON    TR12 6SX   \n",
       "5                                                      Bury   XGM     BL8 4DR   \n",
       "6               Gorebrook Works, Pinkbank Lane   Manchester   XGM     M12 5GH   \n",
       "7                              61 Queen Street        Leeds   XWY    LS27 8EB   \n",
       "8                    110 Islington High Street       London   XGL      N1 8EG   \n",
       "9                                                    Oldham   XGM     OL2 6PX   \n",
       "10                Odyssey Arena, 2 Queens Quay         Down   DOW      BT33 0   \n",
       "\n",
       "     latitude  longitude  stars  review_count  is_open  \\\n",
       "0   43.808563 -79.463806    3.5             3        1   \n",
       "1   43.640646 -79.380939    4.0             4        1   \n",
       "2   42.996059 -89.568889    4.0             4        1   \n",
       "3   45.456999 -73.595250    4.5             3        1   \n",
       "4   35.532021 -80.851682    3.5             3        1   \n",
       "5   42.996059 -89.568889    5.0             3        1   \n",
       "6   42.996059 -89.568889    2.5             3        1   \n",
       "7   43.652821 -79.376345    4.5             5        1   \n",
       "8   43.645355 -79.524467    4.5             3        1   \n",
       "9   42.996059 -89.568889    4.0             3        1   \n",
       "10  43.641658 -79.376030    3.0             4        1   \n",
       "\n",
       "                                           attributes  \\\n",
       "0                                                  {}   \n",
       "1                     {'RestaurantsPriceRange2': '1'}   \n",
       "2   {'WiFi': 'u'free'', 'Caters': 'True', 'BikePar...   \n",
       "3   {'WiFi': ''no'', 'Alcohol': 'u'none'', 'Outdoo...   \n",
       "4   {'RestaurantsTakeOut': 'True', 'RestaurantsDel...   \n",
       "5   {'ByAppointmentOnly': 'False', 'BusinessAccept...   \n",
       "6   {'BusinessParking': '{'garage': False, 'valida...   \n",
       "7   {'WiFi': ''no'', 'HasTV': 'True', 'Alcohol': '...   \n",
       "8   {'BusinessParking': '{'garage': False, 'street...   \n",
       "9                                                  {}   \n",
       "10                                                 {}   \n",
       "\n",
       "                                           categories  \\\n",
       "0   Professional Services, Advertising, Printing S...   \n",
       "1                     Food, Ice Cream & Frozen Yogurt   \n",
       "2         Arts & Crafts, Shopping, Coffee & Tea, Food   \n",
       "3   Bakeries, Food, Desserts, Restaurants, Sandwiches   \n",
       "4                                British, Restaurants   \n",
       "5   Home Services, Landscaping, Tree Services, Gar...   \n",
       "6               Art Supplies, Arts & Crafts, Shopping   \n",
       "7                      Indian, Pakistani, Restaurants   \n",
       "8               Specialty Food, Food, Seafood Markets   \n",
       "9                                Chinese, Restaurants   \n",
       "10                               Arts & Entertainment   \n",
       "\n",
       "                                                hours  \n",
       "0   {'Friday': '9:0-17:0', 'Monday': '9:0-17:0', '...  \n",
       "1                                                  {}  \n",
       "2   {'Friday': '8:30-19:0', 'Monday': '8:30-19:0',...  \n",
       "3   {'Friday': '7:0-15:0', 'Monday': '7:0-15:0', '...  \n",
       "4                                                  {}  \n",
       "5   {'Friday': '0:0-0:0', 'Monday': '0:0-0:0', 'Su...  \n",
       "6                                                  {}  \n",
       "7                                                  {}  \n",
       "8   {'Friday': '9:0-19:30', 'Tuesday': '9:0-19:30'...  \n",
       "9                                                  {}  \n",
       "10                                                 {}  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_suspBus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suspBus.to_csv(path_or_buf='/Users/kemalm/Desktop/suspBus.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
