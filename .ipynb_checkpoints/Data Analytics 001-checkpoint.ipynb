{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting business.json to business.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 192609 dictionaries.\n",
      "Execution time:  3.6180918216705322  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_business = []\n",
    "counter =0\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/business.json',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        listOfDicts_business.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  192609 /Users/kemalm/Desktop/yelp_dataset/business.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/business.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business_id' 'name' 'address' 'city' 'state' 'postal_code' 'latitude'\n",
      " 'longitude' 'stars' 'review_count' 'is_open' 'attributes' 'categories'\n",
      " 'hours'] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "attr_arr = np.array(['business_id', 'name', 'address', 'city', 'state', \n",
    "                     'postal_code', 'latitude', 'longitude', 'stars', \n",
    "                     'review_count', 'is_open', 'attributes', 'categories', 'hours'])\n",
    "print(attr_arr, type(attr_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">business.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192609  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['business_id' 192609.0]\n",
      " ['name' 192609.0]\n",
      " ['address' 192609.0]\n",
      " ['city' 192609.0]\n",
      " ['state' 192609.0]\n",
      " ['postal_code' 192609.0]\n",
      " ['latitude' 192609.0]\n",
      " ['longitude' 192609.0]\n",
      " ['stars' 192609.0]\n",
      " ['review_count' 192609.0]\n",
      " ['is_open' 192609.0]\n",
      " ['attributes' 192609.0]\n",
      " ['categories' 192609.0]\n",
      " ['hours' 192609.0]]\n"
     ]
    }
   ],
   "source": [
    "df_containsfield= np.zeros((len(listOfDicts_business),len(attr_arr)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_business)):\n",
    "    df_containsfield[i,:] = np.isin(attr_arr, np.array(list(listOfDicts_business[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((attr_arr.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(attr_arr)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id\n",
      "       0\n",
      "name\n",
      "       0\n",
      "address\n",
      "       0\n",
      "city\n",
      "       0\n",
      "state\n",
      "       0\n",
      "postal_code\n",
      "       0\n",
      "latitude\n",
      "       0\n",
      "longitude\n",
      "       0\n",
      "stars\n",
      "       0\n",
      "review_count\n",
      "       0\n",
      "is_open\n",
      "       0\n",
      "attributes\n",
      "   28836\n",
      "categories\n",
      "     482\n",
      "hours\n",
      "   44830\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(attr_arr):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/business.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> business.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydict(dict):\n",
    "        def __str__(self):\n",
    "            return json.dumps(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 192609 rows\n",
      "Execution time:  6.614404201507568  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/business.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,list(attr_arr), delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_business:\n",
    "        tempDict=dict(dictObj)    \n",
    "        if tempDict.get('attributes') is not None:\n",
    "            tempDict['attributes'] = mydict(tempDict['attributes']).__str__()\n",
    "        else:\n",
    "            tempDict['attributes']=\"{}\"\n",
    "            \n",
    "        if tempDict.get('hours') is not None:\n",
    "            tempDict['hours'] = mydict(tempDict['hours']).__str__()\n",
    "        else:\n",
    "            tempDict['hours']=\"{}\"\n",
    "        writer.writerow(tempDict)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting user.json to user.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 1637138 rows\n",
      "Execution time:  42.027015209198  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_user = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/user.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_user.append(json.loads(line))\n",
    "        counter+=1\n",
    "endend  = time.time()\n",
    "print(\"Successfully appended {} rows\".format(counter))\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1637138 /Users/kemalm/Desktop/yelp_dataset/user.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/user.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637138"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listOfDicts_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_user = np.array(['user_id', 'name', 'review_count', 'yelping_since', 'useful', \n",
    "                     'funny', 'cool', 'elite', 'friends', 'fans', \n",
    "                     'average_stars', 'compliment_hot', 'compliment_more', 'compliment_profile', 'compliment_cute', \n",
    "                     'compliment_list', 'compliment_note', 'compliment_plain', 'compliment_cool', 'compliment_funny', \n",
    "                     'compliment_writer', 'compliment_photos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">user.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "1637138  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['user_id' 1637138.0]\n",
      " ['name' 1637138.0]\n",
      " ['review_count' 1637138.0]\n",
      " ['yelping_since' 1637138.0]\n",
      " ['useful' 1637138.0]\n",
      " ['funny' 1637138.0]\n",
      " ['cool' 1637138.0]\n",
      " ['elite' 1637138.0]\n",
      " ['friends' 1637138.0]\n",
      " ['fans' 1637138.0]\n",
      " ['average_stars' 1637138.0]\n",
      " ['compliment_hot' 1637138.0]\n",
      " ['compliment_more' 1637138.0]\n",
      " ['compliment_profile' 1637138.0]\n",
      " ['compliment_cute' 1637138.0]\n",
      " ['compliment_list' 1637138.0]\n",
      " ['compliment_note' 1637138.0]\n",
      " ['compliment_plain' 1637138.0]\n",
      " ['compliment_cool' 1637138.0]\n",
      " ['compliment_funny' 1637138.0]\n",
      " ['compliment_writer' 1637138.0]\n",
      " ['compliment_photos' 1637138.0]]\n",
      "Execution time:  111.81420087814331  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_user),len(arr_user)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_user)):\n",
    "    df_containsfield[i,:] = np.isin(arr_user, np.array(list(listOfDicts_user[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_user.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_user)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> \n",
    "<h5 style=\"color:red;\"> WARNING! Following method works very slow for very large datasets (user.json). </h5> \n",
    "<h5 style=\"color:red;\"> Therefore, it shouldn't be run more than once. </h5> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "       0\n",
      "name\n",
      "       0\n",
      "review_count\n",
      "       0\n",
      "yelping_since\n",
      "       0\n",
      "useful\n",
      "       0\n",
      "funny\n",
      "       0\n",
      "cool\n",
      "       0\n",
      "elite\n",
      "       0\n",
      "friends\n",
      "       0\n",
      "fans\n",
      "       0\n",
      "average_stars\n",
      "       0\n",
      "compliment_hot\n",
      "       0\n",
      "compliment_more\n",
      "       0\n",
      "compliment_profile\n",
      "       0\n",
      "compliment_cute\n",
      "       0\n",
      "compliment_list\n",
      "       0\n",
      "compliment_note\n",
      "       0\n",
      "compliment_plain\n",
      "       0\n",
      "compliment_cool\n",
      "       0\n",
      "compliment_funny\n",
      "       0\n",
      "compliment_writer\n",
      "       0\n",
      "compliment_photos\n",
      "       0\n",
      "Execution time:  963.2632689476013  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_user):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/user.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> user.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 1637138 rows\n",
      "Execution time:  75.70107102394104\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/user.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,user_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_user:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1637138 yelp_dataset/user.json\n",
      "User.csv has one more row used as a header.\n",
      " 1637139 yelp_dataset/user.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l yelp_dataset/user.json\n",
    "!echo \"User.csv has one more row used as a header.\"\n",
    "!wc -l yelp_dataset/user.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting review.json to review.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 6685900 dictionaries.\n",
      "Execution time:  71.14869093894958  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_review = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/review.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_review.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6685900 /Users/kemalm/Desktop/yelp_dataset/review.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/review.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_review= np.array(['review_id', 'user_id', 'business_id', 'stars', 'useful',\n",
    "                      'funny', 'cool', 'text', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">review.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "6685900  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['review_id' 6685900.0]\n",
      " ['user_id' 6685900.0]\n",
      " ['business_id' 6685900.0]\n",
      " ['stars' 6685900.0]\n",
      " ['useful' 6685900.0]\n",
      " ['funny' 6685900.0]\n",
      " ['cool' 6685900.0]\n",
      " ['text' 6685900.0]\n",
      " ['date' 6685900.0]]\n",
      "Execution time:  299.6732749938965  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_review),len(arr_review)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_review)):\n",
    "    df_containsfield[i,:] = np.isin(arr_review, np.array(list(listOfDicts_review[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_review.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_review)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> \n",
    "<h5 style=\"color:red;\"> WARNING! Following method works very slow for very large datasets (user.json). </h5> \n",
    "<h5 style=\"color:red;\"> Therefore, it shouldn't be run more than once. </h5> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_id\n",
      "       0\n",
      "user_id\n",
      "       0\n",
      "business_id\n",
      "       0\n",
      "stars\n",
      "       0\n",
      "useful\n",
      "       0\n",
      "funny\n",
      "       0\n",
      "cool\n",
      "       0\n",
      "text\n",
      "       0\n",
      "date\n",
      "       0\n",
      "Execution time:  913.4484198093414  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_review):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/review.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date']\n"
     ]
    }
   ],
   "source": [
    "review_cols = list(arr_review)\n",
    "print(review_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> review.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 6685900 rows\n",
      "Execution time:  232.80819010734558  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/review.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,review_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_review:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting checkin.json to checkin.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 161950 dictionaries.\n",
      "Execution time:  2.0320558547973633  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_checkin = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/checkin.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_checkin.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  161950 /Users/kemalm/Desktop/yelp_dataset/checkin.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/checkin.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_checkin = np.array(['business_id', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">checkin.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "161950  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['business_id' 161950.0]\n",
      " ['date' 161950.0]]\n",
      "Execution time:  2.568455934524536  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_checkin),len(arr_checkin)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_checkin)):\n",
    "    df_containsfield[i,:] = np.isin(arr_checkin, np.array(list(listOfDicts_checkin[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_checkin.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_checkin)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id\n",
      "       0\n",
      "date\n",
      "       0\n",
      "Execution time:  14.164305925369263  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_checkin):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/checkin.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business_id', 'date']\n"
     ]
    }
   ],
   "source": [
    "checkin_cols = list(arr_checkin)\n",
    "print(checkin_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> checkin.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 161950 rows\n",
      "Execution time:  9.046382665634155  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/checkin.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,checkin_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_checkin:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  161950 yelp_dataset/checkin.json\n",
      "  161951 yelp_dataset/checkin.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l yelp_dataset/checkin.json\n",
    "!wc -l yelp_dataset/checkin.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting tip.json to tip.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 1223094 dictionaries.\n",
      "Execution time:  6.717769145965576  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_tip = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/tip.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_tip.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1223094 /Users/kemalm/Desktop/yelp_dataset/tip.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/tip.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_tip = np.array(['user_id', 'business_id', 'text', 'date', 'compliment_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">tip.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "1223094  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['user_id' 1223094.0]\n",
      " ['business_id' 1223094.0]\n",
      " ['text' 1223094.0]\n",
      " ['date' 1223094.0]\n",
      " ['compliment_count' 1223094.0]]\n",
      "Execution time:  30.554124116897583  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_tip),len(arr_tip)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_tip)):\n",
    "    df_containsfield[i,:] = np.isin(arr_tip, np.array(list(listOfDicts_tip[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_tip.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_tip)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "       0\n",
      "business_id\n",
      "       0\n",
      "text\n",
      "       0\n",
      "date\n",
      "       0\n",
      "compliment_count\n",
      "       0\n",
      "Execution time:  25.752610683441162  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_tip):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/tip.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'business_id', 'text', 'date', 'compliment_count']\n"
     ]
    }
   ],
   "source": [
    "tip_cols = list(arr_tip)\n",
    "print(tip_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> tip.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully written 1223094 rows\n",
      "Execution time:  8.033058166503906  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/tip.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,tip_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_tip:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting photo.json to photo.csv\n",
    "### importing from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "Successfully appended 200000 dictionaries.\n",
      "Execution time:  0.9235949516296387  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "listOfDicts_photo = []\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/photo.json',encoding='utf-8') as f:\n",
    "    counter=0\n",
    "    for line in f:\n",
    "        listOfDicts_photo.append(json.loads(line))\n",
    "        counter+=1\n",
    "print(\"Successfully appended {} dictionaries.\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  200000 /Users/kemalm/Desktop/yelp_dataset/photo.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/kemalm/Desktop/yelp_dataset/photo.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naming a list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_photo = np.array(['caption', 'photo_id', 'business_id', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> checking if all json objects, we obtained from <i style=\"color:blue\">photo.json </i> file, actually contain all keys, that yelp dataset documentation claims they do </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n",
      "200000  number of records\n",
      "\n",
      "Key associated with its frequency: \n",
      " [['caption' 200000.0]\n",
      " ['photo_id' 200000.0]\n",
      " ['business_id' 200000.0]\n",
      " ['label' 200000.0]]\n",
      "Execution time:  4.147678852081299  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "df_containsfield= np.zeros((len(listOfDicts_photo),len(arr_photo)))\n",
    "\n",
    "for i in range(0,len(listOfDicts_photo)):\n",
    "    df_containsfield[i,:] = np.isin(arr_photo, np.array(list(listOfDicts_photo[i].keys()))).astype(np.int64)\n",
    "print(df_containsfield.shape[0], \" number of records\\n\")\n",
    "tkeys_counter = np.zeros((arr_photo.shape[0],2), dtype=np.object)\n",
    "tkeys_counter[:,0] = np.array(arr_photo)\n",
    "tkeys_counter[:,1] = df_containsfield.sum(axis=0)\n",
    "print(\"Key associated with its frequency: \\n\", tkeys_counter)\n",
    "\n",
    "end=time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> number of null values per column</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caption\n",
      "       0\n",
      "photo_id\n",
      "       0\n",
      "business_id\n",
      "       0\n",
      "label\n",
      "       0\n",
      "Execution time:  3.233721971511841  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for a in list(arr_photo):\n",
    "    !echo $a\n",
    "    !grep -e \"\\\"$a\\\":null\" /Users/kemalm/Desktop/yelp_dataset/photo.json | wc -l\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caption', 'photo_id', 'business_id', 'label']\n"
     ]
    }
   ],
   "source": [
    "photo_cols = list(arr_photo)\n",
    "print(photo_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creating a <i style=\"color:blue\"> photo.csv </i> file and writing data to it. </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the code ...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e0c41b054e99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Executing the code ...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/kemalm/Desktop/yelp_dataset/photo.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphoto_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcounter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Executing the code ...\\n\")\n",
    "with open('/Users/kemalm/Desktop/yelp_dataset/photo.csv','w',encoding='utf-8') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file,photo_cols, delimiter='\\t' )\n",
    "    writer.writeheader()\n",
    "    counter=0\n",
    "    for dictObj in listOfDicts_photo:\n",
    "        writer.writerow(dictObj)\n",
    "        counter+=1\n",
    "print(\"Successfully written {} rows\".format(counter))\n",
    "end = time.time()\n",
    "print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python-to-PostgreSQL client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn=psycopg2.connect(\"dbname='yelpDB' user='postgres' host='localhost' password='P0$tgre$QL'\")\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "#cur.execute(\"\"\"select city,state, count(business_id)\n",
    "#                from Businesses\n",
    "#                where is_open = 1\n",
    "#                group by city,state\n",
    "#                order by 3 desc\n",
    "#                limit 10\"\"\")\n",
    "#recordsDB = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"select business_id, name, address, city, state, latitude, longitude, categories, is_open\n",
    "                from Businesses\"\"\")\n",
    "recordsDB = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US/Canada states/provinces by number of businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"SELECT state,  COUNT(business_id) AS Total_Count\n",
    "               FROM Businesses\n",
    "               WHERE is_open = 1\n",
    "               GROUP BY state \n",
    "               ORDER BY 2 DESC\"\"\")\n",
    "freqrecords = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Total # of businesses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ</td>\n",
       "      <td>46910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NV</td>\n",
       "      <td>29562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ON</td>\n",
       "      <td>26525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>12546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NC</td>\n",
       "      <td>12419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PA</td>\n",
       "      <td>9430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QC</td>\n",
       "      <td>7623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AB</td>\n",
       "      <td>6694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WI</td>\n",
       "      <td>4210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IL</td>\n",
       "      <td>1545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Total # of businesses\n",
       "0    AZ                  46910\n",
       "1    NV                  29562\n",
       "2    ON                  26525\n",
       "3    OH                  12546\n",
       "4    NC                  12419\n",
       "5    PA                   9430\n",
       "6    QC                   7623\n",
       "7    AB                   6694\n",
       "8    WI                   4210\n",
       "9    IL                   1545"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(freqrecords, columns=['State','Total # of businesses']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cities by number of businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"select city,state, count(business_id)\n",
    "               from Businesses\n",
    "               where is_open = 1\n",
    "               group by city,state\n",
    "               order by 3 desc\"\"\")\n",
    "freqrecords = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Total # of businesses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>23784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>15471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>14329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>7945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>7081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Calgary</td>\n",
       "      <td>AB</td>\n",
       "      <td>6445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>5736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Montréal</td>\n",
       "      <td>QC</td>\n",
       "      <td>5163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mesa</td>\n",
       "      <td>AZ</td>\n",
       "      <td>5149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Henderson</td>\n",
       "      <td>NV</td>\n",
       "      <td>4026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City State  Total # of businesses\n",
       "0   Las Vegas    NV                  23784\n",
       "1     Phoenix    AZ                  15471\n",
       "2     Toronto    ON                  14329\n",
       "3   Charlotte    NC                   7945\n",
       "4  Scottsdale    AZ                   7081\n",
       "5     Calgary    AB                   6445\n",
       "6  Pittsburgh    PA                   5736\n",
       "7    Montréal    QC                   5163\n",
       "8        Mesa    AZ                   5149\n",
       "9   Henderson    NV                   4026"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(freqrecords, columns=['City','State','Total # of businesses']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Places: Sending HTTP Requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from scipy.spatial.distance import pdist\n",
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_content= !cat /Users/kemalm/Desktop/gmAPI.txt\n",
    "api_key = key_content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business_id': 0, 'name': 1, 'address': 2, 'city': 3, 'state': 4, 'latitude': 5, 'longitude': 6, 'categories': 7, 'is_open': 8, 'hours': 9}\n"
     ]
    }
   ],
   "source": [
    "fields = ['business_id','name', 'address', 'city', 'state', 'latitude', 'longitude', 'categories', 'is_open', 'hours']\n",
    "#k = np.core.defchararray.add(np.array(['obt_']),np.array(fields))\n",
    "\n",
    "#print(k)\n",
    "indices =[x for x in range(0,len(fields))]\n",
    "#print(indices)\n",
    "mapDictIndexes = dict(zip(fields,indices))\n",
    "print(mapDictIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = np.array([[0,0],\n",
    "                        [ 0, 180]])# Using the geodesic distance function.\n",
    "m_dist = pdist(coordinates, # Coordinates matrix or tuples list\n",
    "               lambda u, v: geodesic(u, v).kilometers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_lat,smpl_lng =  33.5221294, -112.0181866\n",
    "url_api_place_nearbySearch =\"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={},{}&radius=500&keyword={}&key={}\".format(\n",
    "smpl_lat,smpl_lng,'Arizona Biltmore Golf Club', api_key)\n",
    "response_api_place_nearbySearch =requests.get(url_api_place_nearbySearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json.dumps(response_api_place_nearbySearch.json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_lat,smpl_lng =  33.626171,-111.915779\n",
    "url_api_place_nearbySearch =\"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={},{}&radius=500&keyword={}&key={}\".format(\n",
    "smpl_lat,smpl_lng,'Precision Door Service', api_key)\n",
    "response_api_place_nearbySearch =requests.get(url_api_place_nearbySearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_address = '19420 N 59th Ave, Ste 13'.replace(' ','+')\n",
    "url_geocoding = \"https://maps.googleapis.com/maps/api/geocode/json?address={}&key={}\".format(smpl_address,api_key)\n",
    "response_geocoding = requests.get(url_geocoding)\n",
    "response_geocodingJSON= response_geocoding.json()\n",
    "#print(json.dumps(response_geocodingJSON))\n",
    "\n",
    "#frm_address = response_geocodingJSON['results'][0]['formatted_address']\n",
    "#frm_address.rsplit(',',4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_address = '19420 N 59th Ave, Ste 13'.replace(' ','+')\n",
    "url_geocoding = \"https://maps.googleapis.com/maps/api/geocode/json?address={}&key={}\".format(smpl_address,api_key)\n",
    "response_geocoding = requests.get(url_geocoding)\n",
    "response_geocodingJSON= response_geocoding.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from scipy.spatial.distance import pdist\n",
    "from geopy.distance import geodesic\n",
    "import random as rn\n",
    "import json\n",
    "\n",
    "try:\n",
    "    conn=psycopg2.connect(\"dbname='yelpDB' user='postgres' host='localhost' password='P0$tgre$QL'\")\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"select business_id, name, address, city, state, latitude, longitude, categories\n",
    "                from Businesses\"\"\")\n",
    "recordsDB = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192609"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recordsDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business_id': 0, 'name': 1, 'address': 2, 'city': 3, 'state': 4, 'latitude': 5, 'longitude': 6, 'categories': 7}\n"
     ]
    }
   ],
   "source": [
    "key_content= !cat /Users/kemalm/Desktop/gmAPI.txt\n",
    "api_key = key_content[0]\n",
    "fields = ['business_id','name', 'address', 'city', 'state', 'latitude', 'longitude', 'categories']\n",
    "#k = np.core.defchararray.add(np.array(['obt_']),np.array(fields))\n",
    "\n",
    "#print(k)\n",
    "indices =[x for x in range(0,len(fields))]\n",
    "#print(indices)\n",
    "mapDictIndexes = dict(zip(fields,indices))\n",
    "print(mapDictIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeocodingRequestHandling(record):\n",
    "    dictObj=dict()\n",
    "    \n",
    "    business_name = record[mapDictIndexes['name']] \n",
    "    business_address = record[mapDictIndexes['address']]\n",
    "    business_latitude = record[mapDictIndexes['latitude']]\n",
    "    business_longitude = record[mapDictIndexes['longitude']]\n",
    "    \n",
    "    dictObj['business_id'] = record[mapDictIndexes['business_id']] \n",
    "    dictObj['name']= business_name\n",
    "    dictObj['address']= business_address\n",
    "    dictObj['city']= record[mapDictIndexes['city']]\n",
    "    dictObj['state']= record[mapDictIndexes['state']]\n",
    "    dictObj['latitude']= business_latitude\n",
    "    dictObj['longitude']= business_longitude\n",
    "    dictObj['categories']= record[mapDictIndexes['categories']]\n",
    "    #dictObj['is_open']= record[mapDictIndexes['is_open']]\n",
    "     \n",
    "    if(business_address !=''):\n",
    "        url_geocoding =\"https://maps.googleapis.com/maps/api/geocode/json?address={}&sensor=true&key={}\".format(\n",
    "        business_address,api_key)\n",
    "        resp =requests.get(url_geocoding)\n",
    "        resp_dict= resp.json()\n",
    "        dictObj['geocoding_status'] = resp_dict['status']\n",
    "        if(dictObj['geocoding_status']=='OK'):\n",
    "            GeocodingFunc(dictObj,resp_dict)\n",
    "    \n",
    "    url_invgeocoding = \"https://maps.googleapis.com/maps/api/geocode/json?latlng={},{}&key={}\".format(\n",
    "        business_latitude,business_longitude,api_key)\n",
    "    resp =requests.get(url_invgeocoding)\n",
    "    resp_dict= resp.json()\n",
    "    dictObj['invgeocoding_status'] = resp_dict['status']\n",
    "    if(dictObj['invgeocoding_status']=='OK'):\n",
    "        InvGeocodingFunc(dictObj, resp_dict)\n",
    "    \n",
    "    return dictObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeocodingFunc(dictObj,resp_dict):\n",
    "    dictObj['latitude_from_address']= resp_dict['results'][0]['geometry']['location']['lat']\n",
    "    dictObj['longitude_from_address']= resp_dict['results'][0]['geometry']['location']['lng']\n",
    "    #dictObj['formatted_address_from_address'] = response_placeSearchJSON['results'][0]['formatted_address']\n",
    "    coordinates=np.array([[dictObj['latitude'], dictObj['longitude']],\n",
    "                          [dictObj['latitude_from_address'],dictObj['longitude_from_address']]])    \n",
    "    m_dist = pdist(coordinates, # Coordinates matrix or tuples list\n",
    "           lambda u, v: geodesic(u, v).kilometers)\n",
    "    dictObj['dist_diff']= float(m_dist)* 1000.0\n",
    "    dictObj['place_id_from_address']= resp_dict['results'][0]['place_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InvGeocodingFunc(dictObj,resp_dict):\n",
    "    dictObj['formatted_address_from_coord'] = resp_dict['results'][0]['formatted_address']    \n",
    "    dictObj['address_components_from_coord'] = resp_dict['results'][0]['address_components']  \n",
    "    dictObj['place_id_from_coord']= resp_dict['results'][0]['place_id']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 100 rows. In total 100\n",
      "Execution time:  15.795691967010498  seconds.\n",
      "Appended 100 rows. In total 200\n",
      "Execution time:  32.00659203529358  seconds.\n",
      "Appended 100 rows. In total 300\n",
      "Execution time:  48.9500470161438  seconds.\n",
      "Appended 100 rows. In total 400\n",
      "Execution time:  64.60181403160095  seconds.\n",
      "Appended 100 rows. In total 500\n",
      "Execution time:  80.37112879753113  seconds.\n",
      "Appended 100 rows. In total 600\n",
      "Execution time:  95.18814992904663  seconds.\n",
      "Appended 100 rows. In total 700\n",
      "Execution time:  111.17470383644104  seconds.\n",
      "Appended 100 rows. In total 800\n",
      "Execution time:  125.73102593421936  seconds.\n",
      "Appended 100 rows. In total 900\n",
      "Execution time:  141.76359391212463  seconds.\n",
      "Appended 100 rows. In total 1000\n",
      "Execution time:  156.80530095100403  seconds.\n",
      "Appended 100 rows. In total 1100\n",
      "Execution time:  171.58871293067932  seconds.\n",
      "Appended 100 rows. In total 1200\n",
      "Execution time:  187.241938829422  seconds.\n",
      "Appended 100 rows. In total 1300\n",
      "Execution time:  202.5680377483368  seconds.\n",
      "Appended 100 rows. In total 1400\n",
      "Execution time:  216.77816605567932  seconds.\n",
      "Appended 100 rows. In total 1500\n",
      "Execution time:  231.94861268997192  seconds.\n",
      "Appended 100 rows. In total 1600\n",
      "Execution time:  247.23677372932434  seconds.\n",
      "Appended 100 rows. In total 1700\n",
      "Execution time:  262.8335428237915  seconds.\n",
      "Appended 100 rows. In total 1800\n",
      "Execution time:  278.169939994812  seconds.\n",
      "Appended 100 rows. In total 1900\n",
      "Execution time:  293.51794481277466  seconds.\n",
      "Appended 100 rows. In total 2000\n",
      "Execution time:  307.56024384498596  seconds.\n",
      "Appended 100 rows. In total 2100\n",
      "Execution time:  323.906222820282  seconds.\n",
      "Appended 100 rows. In total 2200\n",
      "Execution time:  339.32849192619324  seconds.\n",
      "Appended 100 rows. In total 2300\n",
      "Execution time:  355.2178008556366  seconds.\n",
      "Appended 100 rows. In total 2400\n",
      "Execution time:  370.4978668689728  seconds.\n",
      "Appended 100 rows. In total 2500\n",
      "Execution time:  384.8549189567566  seconds.\n",
      "Appended 100 rows. In total 2600\n",
      "Execution time:  400.68819975852966  seconds.\n",
      "Appended 100 rows. In total 2700\n",
      "Execution time:  416.2079849243164  seconds.\n",
      "Appended 100 rows. In total 2800\n",
      "Execution time:  431.24926471710205  seconds.\n",
      "Appended 100 rows. In total 2900\n",
      "Execution time:  446.0875508785248  seconds.\n",
      "Appended 100 rows. In total 3000\n",
      "Execution time:  461.5965509414673  seconds.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import multiprocessing\n",
    "import time as time\n",
    "\n",
    "start = time.time()\n",
    "counter = 0\n",
    "sample = rn.sample(recordsDB,3000)\n",
    "listOfDicts=[]\n",
    "for i in range(0,len(sample),100):\n",
    "    with multiprocessing.Pool( processes=multiprocessing.cpu_count()) as pool:\n",
    "        listOfDicts+=pool.map(GeocodingRequestHandling, sample[i:i+100])\n",
    "    counter+=100   \n",
    "    print(\"Appended 100 rows. In total {}\".format(counter))\n",
    "    end = time.time()\n",
    "    print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listOfDicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 3000 dictionaries\n"
     ]
    }
   ],
   "source": [
    "frm_listOfDicts = []\n",
    "counter = 0\n",
    "for el in listOfDicts:\n",
    "    dictObj = dict(el)\n",
    "    street_name, route, city, state,country = \"\",\"\",\"\",\"\",\"\"\n",
    "    for sub_el in el['address_components_from_coord']:\n",
    "        if('street_number' in sub_el['types']):\n",
    "            street_name = sub_el['long_name']\n",
    "        if('route' in sub_el['types']):\n",
    "            route = sub_el['long_name']\n",
    "        if('locality' in sub_el['types'] ):\n",
    "            city = sub_el['long_name']\n",
    "        if('administrative_area_level_1' in sub_el['types'] ):\n",
    "            state =  sub_el['short_name']\n",
    "        if('country' in sub_el['types'] ):\n",
    "            country =  sub_el['short_name']\n",
    "    if(street_name != \"\" and route != \"\"):\n",
    "        dictObj['address_from_coord'] = street_name+' '+route\n",
    "    else:\n",
    "        dictObj['address_from_coord'] = street_name+route      \n",
    "    dictObj['city_from_coord'] = city\n",
    "    dictObj['state_from_coord'] = state\n",
    "    dictObj['country_from_coord'] = country     \n",
    "    frm_listOfDicts.append(dictObj)\n",
    "    counter+=1\n",
    "print(\"Appended {} dictionaries\".format(counter))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampleGEO = pd.DataFrame(frm_listOfDicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampleGEO.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['address', 'address_components_from_coord', 'address_from_coord',\n",
       "       'business_id', 'categories', 'city', 'city_from_coord',\n",
       "       'country_from_coord', 'dist_diff', 'formatted_address_from_coord',\n",
       "       'geocoding_status', 'invgeocoding_status', 'latitude',\n",
       "       'latitude_from_address', 'longitude', 'longitude_from_address', 'name',\n",
       "       'place_id_from_address', 'place_id_from_coord', 'state',\n",
       "       'state_from_coord'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampleGEO.columns #We are going to ignore address_components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignoring address components\n",
    "cols_GEO = [ 'business_id',\n",
    "            'name',\n",
    "            'address',\n",
    "            'city',\n",
    "            'state',\n",
    "            'address_from_coord',\n",
    "            'city_from_coord',\n",
    "            'state_from_coord',\n",
    "            'country_from_coord', \n",
    "            'formatted_address_from_coord',      \n",
    "            'latitude',\n",
    "            'latitude_from_address',\n",
    "            'longitude',\n",
    "            'longitude_from_address',\n",
    "            'dist_diff',   \n",
    "            'categories',\n",
    "            'place_id_from_address',\n",
    "            'place_id_from_coord',\n",
    "            'geocoding_status',\n",
    "            'invgeocoding_status',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols_GEO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['OK', nan, 'ZERO_RESULTS', 'REQUEST_DENIED'], dtype=object),\n",
       " array(['OK'], dtype=object))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampleGEO['geocoding_status'].unique(), df_sampleGEO['invgeocoding_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "address                          3000\n",
       "address_components_from_coord    3000\n",
       "address_from_coord               3000\n",
       "business_id                      3000\n",
       "categories                       2984\n",
       "city                             3000\n",
       "city_from_coord                  3000\n",
       "country_from_coord               3000\n",
       "dist_diff                        2853\n",
       "formatted_address_from_coord     3000\n",
       "geocoding_status                 2876\n",
       "invgeocoding_status              3000\n",
       "latitude                         3000\n",
       "latitude_from_address            2853\n",
       "longitude                        3000\n",
       "longitude_from_address           2853\n",
       "name                             3000\n",
       "place_id_from_address            2853\n",
       "place_id_from_coord              3000\n",
       "state                            3000\n",
       "state_from_coord                 3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampleGEO.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampleGEO[cols_GEO].to_csv(path_or_buf='/Users/kemalm/Desktop/FinalGM/geocodingSampleFormatted.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sampleGEO[df_sampleGEO.address_from_coord == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/Users/kemalm/Desktop/FinalGM/geocodingSampleFormatted.csv')\n",
    "df_test.loc[ df_test['address'].isnull(), 'address'] = ''\n",
    "df_test.loc[ df_test['address_from_coord'].isnull(), 'address_from_coord'] = ''\n",
    "df_test.loc[ df_test['city_from_coord'].isnull(), 'city_from_coord'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "address                         3000\n",
       "city                            3000\n",
       "state                           3000\n",
       "address_from_coord              3000\n",
       "city_from_coord                 3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "formatted_address_from_coord    3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2853\n",
       "longitude                       3000\n",
       "longitude_from_address          2853\n",
       "dist_diff                       2853\n",
       "categories                      2984\n",
       "place_id_from_address           2853\n",
       "place_id_from_coord             3000\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sampleGEO[cols_GEO].count() == df_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>address_from_coord</th>\n",
       "      <th>city_from_coord</th>\n",
       "      <th>state_from_coord</th>\n",
       "      <th>country_from_coord</th>\n",
       "      <th>formatted_address_from_coord</th>\n",
       "      <th>latitude</th>\n",
       "      <th>latitude_from_address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>longitude_from_address</th>\n",
       "      <th>dist_diff</th>\n",
       "      <th>categories</th>\n",
       "      <th>place_id_from_address</th>\n",
       "      <th>place_id_from_coord</th>\n",
       "      <th>geocoding_status</th>\n",
       "      <th>invgeocoding_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pBmhuYniNwodaxlfJq5UBQ</td>\n",
       "      <td>Red Modern Furniture</td>\n",
       "      <td>201 E Camelback Rd</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>201 East Camelback Road</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>US</td>\n",
       "      <td>201 E Camelback Rd, Phoenix, AZ 85012, USA</td>\n",
       "      <td>33.509034</td>\n",
       "      <td>33.509034</td>\n",
       "      <td>-112.070878</td>\n",
       "      <td>-112.070878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Antiques, Home Decor, Home Services, Lighting ...</td>\n",
       "      <td>ChIJfZtx8L8SK4cRQCW1UnJ8JJk</td>\n",
       "      <td>ChIJfZtx8L8SK4cRQCW1UnJ8JJk</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>wOJ3NMhumJDs9FKDADa0AQ</td>\n",
       "      <td>Modify Yoga Spa Cafe</td>\n",
       "      <td>4164 N Marshall Way</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>7040 East 3rd Avenue</td>\n",
       "      <td>Scottsdale</td>\n",
       "      <td>AZ</td>\n",
       "      <td>US</td>\n",
       "      <td>7040 E 3rd Ave, Scottsdale, AZ 85251, USA</td>\n",
       "      <td>33.496462</td>\n",
       "      <td>33.496462</td>\n",
       "      <td>-111.929118</td>\n",
       "      <td>-111.929118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yoga, Restaurants, Fitness &amp; Instruction, Day ...</td>\n",
       "      <td>ChIJC0Tf8ZULK4cRAjNI5fnty7k</td>\n",
       "      <td>ChIJOSUZ8JULK4cRPKOojYcQbiw</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>QusBsOLrcamSQvoCPy3TQQ</td>\n",
       "      <td>Westney Heights Medical Centre and Xray</td>\n",
       "      <td>15 Westney Road N, Suite 11</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>ON</td>\n",
       "      <td>15 Westney Road North</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>ON</td>\n",
       "      <td>CA</td>\n",
       "      <td>15 Westney Rd N, Ajax, ON L1T 1P5, Canada</td>\n",
       "      <td>43.859083</td>\n",
       "      <td>43.859083</td>\n",
       "      <td>-79.039129</td>\n",
       "      <td>-79.039129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dentists, Health &amp; Medical, Walk-in Clinics, M...</td>\n",
       "      <td>EiUxMSwgMTUgV2VzdG5leSBSZCBOLCBBamF4LCBPTiwgQ2...</td>\n",
       "      <td>ChIJLxmMauzf1IkReXQEPO2mkGA</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>CXFR88uNnlcVemPV27oExg</td>\n",
       "      <td>Tracy's Downtown Barbers</td>\n",
       "      <td>590 N Alma School Rd, Ste 28</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>AZ</td>\n",
       "      <td>590 North Alma School Road</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>AZ</td>\n",
       "      <td>US</td>\n",
       "      <td>590 N Alma School Rd, Chandler, AZ 85224, USA</td>\n",
       "      <td>33.311682</td>\n",
       "      <td>33.311682</td>\n",
       "      <td>-111.859979</td>\n",
       "      <td>-111.859979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Barbers, Beauty &amp; Spas</td>\n",
       "      <td>EjEyOCwgNTkwIE4gQWxtYSBTY2hvb2wgUmQsIENoYW5kbG...</td>\n",
       "      <td>ChIJDwIgJ6sAK4cR21dg0BIKCnU</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>DFZnNrIZu1_oHv-4aaxJbg</td>\n",
       "      <td>Taste Of Thai</td>\n",
       "      <td>124 E Sangamon Ave</td>\n",
       "      <td>Rantoul</td>\n",
       "      <td>IL</td>\n",
       "      <td>128 East Sangamon Avenue</td>\n",
       "      <td>Rantoul</td>\n",
       "      <td>IL</td>\n",
       "      <td>US</td>\n",
       "      <td>128 E Sangamon Ave, Rantoul, IL 61866, USA</td>\n",
       "      <td>40.310398</td>\n",
       "      <td>40.310398</td>\n",
       "      <td>-88.157689</td>\n",
       "      <td>-88.157689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thai, Vietnamese, Restaurants, Asian Fusion</td>\n",
       "      <td>ChIJq6oau-gfDYgRFczdVeHQ5Nk</td>\n",
       "      <td>ChIJcXwdu-gfDYgRAffq_z8S2wM</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id                                     name  \\\n",
       "0     pBmhuYniNwodaxlfJq5UBQ                     Red Modern Furniture   \n",
       "895   wOJ3NMhumJDs9FKDADa0AQ                     Modify Yoga Spa Cafe   \n",
       "2344  QusBsOLrcamSQvoCPy3TQQ  Westney Heights Medical Centre and Xray   \n",
       "900   CXFR88uNnlcVemPV27oExg                 Tracy's Downtown Barbers   \n",
       "2341  DFZnNrIZu1_oHv-4aaxJbg                            Taste Of Thai   \n",
       "\n",
       "                           address        city state  \\\n",
       "0               201 E Camelback Rd     Phoenix    AZ   \n",
       "895            4164 N Marshall Way  Scottsdale    AZ   \n",
       "2344   15 Westney Road N, Suite 11        Ajax    ON   \n",
       "900   590 N Alma School Rd, Ste 28    Chandler    AZ   \n",
       "2341            124 E Sangamon Ave     Rantoul    IL   \n",
       "\n",
       "              address_from_coord city_from_coord state_from_coord  \\\n",
       "0        201 East Camelback Road         Phoenix               AZ   \n",
       "895         7040 East 3rd Avenue      Scottsdale               AZ   \n",
       "2344       15 Westney Road North            Ajax               ON   \n",
       "900   590 North Alma School Road        Chandler               AZ   \n",
       "2341    128 East Sangamon Avenue         Rantoul               IL   \n",
       "\n",
       "     country_from_coord                   formatted_address_from_coord  \\\n",
       "0                    US     201 E Camelback Rd, Phoenix, AZ 85012, USA   \n",
       "895                  US      7040 E 3rd Ave, Scottsdale, AZ 85251, USA   \n",
       "2344                 CA      15 Westney Rd N, Ajax, ON L1T 1P5, Canada   \n",
       "900                  US  590 N Alma School Rd, Chandler, AZ 85224, USA   \n",
       "2341                 US     128 E Sangamon Ave, Rantoul, IL 61866, USA   \n",
       "\n",
       "       latitude  latitude_from_address   longitude  longitude_from_address  \\\n",
       "0     33.509034              33.509034 -112.070878             -112.070878   \n",
       "895   33.496462              33.496462 -111.929118             -111.929118   \n",
       "2344  43.859083              43.859083  -79.039129              -79.039129   \n",
       "900   33.311682              33.311682 -111.859979             -111.859979   \n",
       "2341  40.310398              40.310398  -88.157689              -88.157689   \n",
       "\n",
       "      dist_diff                                         categories  \\\n",
       "0           0.0  Antiques, Home Decor, Home Services, Lighting ...   \n",
       "895         0.0  Yoga, Restaurants, Fitness & Instruction, Day ...   \n",
       "2344        0.0  Dentists, Health & Medical, Walk-in Clinics, M...   \n",
       "900         0.0                             Barbers, Beauty & Spas   \n",
       "2341        0.0        Thai, Vietnamese, Restaurants, Asian Fusion   \n",
       "\n",
       "                                  place_id_from_address  \\\n",
       "0                           ChIJfZtx8L8SK4cRQCW1UnJ8JJk   \n",
       "895                         ChIJC0Tf8ZULK4cRAjNI5fnty7k   \n",
       "2344  EiUxMSwgMTUgV2VzdG5leSBSZCBOLCBBamF4LCBPTiwgQ2...   \n",
       "900   EjEyOCwgNTkwIE4gQWxtYSBTY2hvb2wgUmQsIENoYW5kbG...   \n",
       "2341                        ChIJq6oau-gfDYgRFczdVeHQ5Nk   \n",
       "\n",
       "              place_id_from_coord geocoding_status invgeocoding_status  \n",
       "0     ChIJfZtx8L8SK4cRQCW1UnJ8JJk               OK                  OK  \n",
       "895   ChIJOSUZ8JULK4cRPKOojYcQbiw               OK                  OK  \n",
       "2344  ChIJLxmMauzf1IkReXQEPO2mkGA               OK                  OK  \n",
       "900   ChIJDwIgJ6sAK4cR21dg0BIKCnU               OK                  OK  \n",
       "2341  ChIJcXwdu-gfDYgRAffq_z8S2wM               OK                  OK  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[~df_test['dist_diff'].isnull()].sort_values(by=['dist_diff']).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value for calc_distance: 0.0 meters\n",
      "Max value for calc_distance: 7496171.563305463 meters\n",
      "Mean value for calc_distance: 90272.86056974754 meters\n",
      "Median for calc_distance: 5.08889081764884 meters\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Min value for calc_distance: {} meters\n",
    "Max value for calc_distance: {} meters\n",
    "Mean value for calc_distance: {} meters\n",
    "Median for calc_distance: {} meters\"\"\".format(\n",
    "                            df_test['dist_diff'].min(), \n",
    "                            df_test['dist_diff'].max(), \n",
    "                            df_test['dist_diff'].mean(),\n",
    "                            df_test['dist_diff'].median(),\n",
    "\n",
    "\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.853000e+03\n",
       "mean     9.027286e+04\n",
       "std      4.783915e+05\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      5.088891e+00\n",
       "75%      4.448364e+01\n",
       "max      7.496172e+06\n",
       "Name: dist_diff, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.dist_diff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7496171\n",
      "[0, 15, 30, 60, 120, 240, 480, 960, 1920, 3840, 7680, 15360, 30720, 61440, 122880, 245760, 491520, 983040, 1966080, 3932160, 7864320]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "ranges = [0,15]\n",
    "temp_var = 15\n",
    "while temp_var <= int(df_test['dist_diff'].max()):\n",
    "    temp_var *=2\n",
    "    ranges.append(temp_var) \n",
    "print(int(df_test['dist_diff'].max()))\n",
    "print(ranges)\n",
    "print(len(ranges))\n",
    "k = df_test[~df_test['dist_diff'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dist_diff\n",
       "(0, 15]               994\n",
       "(15, 30]              243\n",
       "(30, 60]              238\n",
       "(60, 120]             190\n",
       "(120, 240]            110\n",
       "(240, 480]             53\n",
       "(480, 960]             24\n",
       "(960, 1920]            10\n",
       "(1920, 3840]           14\n",
       "(3840, 7680]            9\n",
       "(7680, 15360]          20\n",
       "(15360, 30720]         16\n",
       "(30720, 61440]          7\n",
       "(61440, 122880]         1\n",
       "(122880, 245760]        8\n",
       "(245760, 491520]       19\n",
       "(491520, 983040]       42\n",
       "(983040, 1966080]      48\n",
       "(1966080, 3932160]     36\n",
       "(3932160, 7864320]      7\n",
       "Name: business_id, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.groupby(pd.cut(\n",
    "                k['dist_diff'], \n",
    "                ranges)).count()['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 44.483641290534365\n"
     ]
    }
   ],
   "source": [
    "QUANTILES = df_test.dist_diff.quantile([0.25,0.5,0.75])\n",
    "Q1, Q3 = QUANTILES[0.25], QUANTILES[0.75]\n",
    "print(Q1,Q3)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.bitwise_or(df_test.dist_diff <= Q1-IQR*1.5, df_test.dist_diff  >= Q3+IQR*1.5 )).astype(np.int64).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[np.bitwise_or(df_test.dist_diff <= Q1-IQR*1.5, df_test.dist_diff  >= Q3+IQR*1.5 )].sort_values(by=['dist_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'CA'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.country_from_coord.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AZ', 'AB', 'ON', 'NC', 'NV', 'QC', 'SC', 'OH', 'WI', 'PA', 'IL',\n",
       "       'NY'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.state_from_coord.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address (null count): 0\n",
      "Address (empty count): 124\n",
      "City (null count): 0\n",
      "City (empty count): 0\n",
      "State (null count): 0\n",
      "State (empty count): 0\n",
      "--------------------------------------------\n",
      "Address from coordinates (null count): 0\n",
      "Address from coordinates (empty count): 95\n",
      "City from coordinates (null count): 0\n",
      "City from coordinates (empty count): 6\n",
      "State from coordinates (null count): 0\n",
      "State from coordinates (empty count): 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Address (null count): {}\n",
    "Address (empty count): {}\n",
    "City (null count): {}\n",
    "City (empty count): {}\n",
    "State (null count): {}\n",
    "State (empty count): {}\n",
    "--------------------------------------------\n",
    "Address from coordinates (null count): {}\n",
    "Address from coordinates (empty count): {}\n",
    "City from coordinates (null count): {}\n",
    "City from coordinates (empty count): {}\n",
    "State from coordinates (null count): {}\n",
    "State from coordinates (empty count): {}\n",
    "\"\"\".format(\n",
    "df_test [df_test.address.isnull()]['business_id'].count(),\n",
    "df_test [df_test.address == '']['business_id'].count(),      \n",
    "df_test [df_test.city.isnull()]['business_id'].count(),\n",
    "df_test [df_test.city == '']['business_id'].count(),     \n",
    "df_test [df_test.state.isnull()]['business_id'].count(),\n",
    "df_test [df_test.state == '']['business_id'].count(),     \n",
    "\n",
    "df_test [df_test.address_from_coord.isnull()]['business_id'].count(),\n",
    "df_test [df_test.address_from_coord == '']['business_id'].count(),      \n",
    "df_test [df_test.city_from_coord.isnull()]['business_id'].count(),\n",
    "df_test [df_test.city_from_coord == '']['business_id'].count(),     \n",
    "df_test [df_test.state_from_coord.isnull()]['business_id'].count(),\n",
    "df_test [df_test.state_from_coord == '']['business_id'].count()   \n",
    "     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some invgeocoding calls return empty addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching cities and states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fltStates = pd.DataFrame (df_test[np.bitwise_and(df_test.state != '', df_test.state_from_coord != '')][['business_id','state','state_from_coord']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fltStates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fltCities= pd.DataFrame (df_test[np.bitwise_and(df_test.city != '', df_test.city_from_coord != '')][['business_id','city','city_from_coord']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2994, 3)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fltCities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities match: 2800 out of 2994\n",
      "States match: 2995 out of 3000\n",
      "Filtered out null and empty values.\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Cities match: {} out of {}\n",
    "States match: {} out of {}\n",
    "Filtered out null and empty values.\"\"\" .format(\n",
    "df_fltCities[df_fltCities.city == df_fltCities.city_from_coord ].business_id.count(), df_fltCities.shape[0],\n",
    "df_fltStates[df_fltStates.state == df_fltStates.state_from_coord ].business_id.count(), df_fltStates.shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fltAddresses= pd.DataFrame(df_test[np.bitwise_and(df_test.address != '', df_test.address_from_coord != '')][['business_id','address','address_from_coord']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "scores = np.zeros((df_fltAddresses.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2794, 1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(df_fltAddresses.itertuples(index=False)):\n",
    "    addr=row.__getattribute__('address')\n",
    "    addr_c = row.__getattribute__('address_from_coord')\n",
    "    score = fuzz.token_set_ratio(addr,addr_c)\n",
    "    scores[idx,0] = score\n",
    "df_fltAddresses['addr_score']= scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>address</th>\n",
       "      <th>address_from_coord</th>\n",
       "      <th>addr_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>1hceMTsoDKL40bgIqp1xkg</td>\n",
       "      <td>6432 Rea Road</td>\n",
       "      <td>6432 Rea Road</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>LQ9WorDtNJXeEfA7GWIXTA</td>\n",
       "      <td>6355 Yonge Street</td>\n",
       "      <td>6355 Yonge Street</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>wphF5TNh31RQ0a-nbrpqyw</td>\n",
       "      <td>B104-20 Broadleaf Avenue</td>\n",
       "      <td>20 Broadleaf Avenue</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>zXO__HLv4CqHJ7LJNUOc2A</td>\n",
       "      <td>884 Danforth Avenue</td>\n",
       "      <td>884 Danforth Avenue</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>r6bvqwhWy73SgyK_w8Y5Lg</td>\n",
       "      <td>2555 Victoria Park Avenue</td>\n",
       "      <td>2555 Victoria Park Avenue</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>yxTkyYEWzfsPbD58_Zblig</td>\n",
       "      <td>505 Highway 7  E</td>\n",
       "      <td>505 Highway 7</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>2DIQm_EDH7d422g6HxoTDA</td>\n",
       "      <td>621 Dixon</td>\n",
       "      <td>621 Dixon Road</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>LHqBSGDa3Iw7q_44RP9dVg</td>\n",
       "      <td>7001 Boulevard de la Vérendrye</td>\n",
       "      <td>7001 Boulevard de la Vérendrye</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Dht5tuQpI9m1DCuNG323xg</td>\n",
       "      <td>421 Bentley Street</td>\n",
       "      <td>421 Bentley Street</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>YjyQlqHoB3Q9ysJGXiJuLA</td>\n",
       "      <td>33 Villiers Street</td>\n",
       "      <td>33 Villiers Street</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id                         address  \\\n",
       "2672  1hceMTsoDKL40bgIqp1xkg                   6432 Rea Road   \n",
       "1325  LQ9WorDtNJXeEfA7GWIXTA               6355 Yonge Street   \n",
       "2745  wphF5TNh31RQ0a-nbrpqyw        B104-20 Broadleaf Avenue   \n",
       "2856  zXO__HLv4CqHJ7LJNUOc2A             884 Danforth Avenue   \n",
       "2857  r6bvqwhWy73SgyK_w8Y5Lg       2555 Victoria Park Avenue   \n",
       "410   yxTkyYEWzfsPbD58_Zblig                505 Highway 7  E   \n",
       "411   2DIQm_EDH7d422g6HxoTDA                       621 Dixon   \n",
       "934   LHqBSGDa3Iw7q_44RP9dVg  7001 Boulevard de la Vérendrye   \n",
       "2744  Dht5tuQpI9m1DCuNG323xg              421 Bentley Street   \n",
       "2261  YjyQlqHoB3Q9ysJGXiJuLA              33 Villiers Street   \n",
       "\n",
       "                  address_from_coord  addr_score  \n",
       "2672                   6432 Rea Road       100.0  \n",
       "1325               6355 Yonge Street       100.0  \n",
       "2745             20 Broadleaf Avenue       100.0  \n",
       "2856             884 Danforth Avenue       100.0  \n",
       "2857       2555 Victoria Park Avenue       100.0  \n",
       "410                    505 Highway 7       100.0  \n",
       "411                   621 Dixon Road       100.0  \n",
       "934   7001 Boulevard de la Vérendrye       100.0  \n",
       "2744              421 Bentley Street       100.0  \n",
       "2261              33 Villiers Street       100.0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fltAddresses.sort_values(by=['addr_score'],ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_scores= pd.DataFrame(pd.merge(df_test, df_fltAddresses[['business_id','addr_score']], on='business_id' ,how='left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 21)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_scores.sort_values(by=['addr_score'], ascending=False)[ [ 'business_id',\n",
    "            'name',\n",
    "            'address',\n",
    "            'city',\n",
    "            'state',\n",
    "            'address_from_coord',\n",
    "            'addr_score',\n",
    "            'city_from_coord',\n",
    "            'state_from_coord',\n",
    "            'country_from_coord', \n",
    "            'formatted_address_from_coord',      \n",
    "            'latitude',\n",
    "            'latitude_from_address',\n",
    "            'longitude',\n",
    "            'longitude_from_address',\n",
    "            'dist_diff',   \n",
    "            'categories',\n",
    "            'place_id_from_address',\n",
    "            'place_id_from_coord',\n",
    "            'geocoding_status',\n",
    "            'invgeocoding_status'\n",
    "            ]].to_csv(path_or_buf='/Users/kemalm/Desktop/FinalGM/scoresSample.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "address                         3000\n",
       "city                            3000\n",
       "state                           3000\n",
       "address_from_coord              3000\n",
       "city_from_coord                 3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "formatted_address_from_coord    3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2853\n",
       "longitude                       3000\n",
       "longitude_from_address          2853\n",
       "dist_diff                       2853\n",
       "categories                      2984\n",
       "place_id_from_address           2853\n",
       "place_id_from_coord             3000\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "addr_score                      2794\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_scores[~df_with_scores.isnull()].count() # for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = pd.read_csv('/Users/kemalm/Desktop/FinalGM/scoresSample.csv')\n",
    "testing_df.loc[ testing_df['address'].isnull(), 'address'] = ''\n",
    "testing_df.loc[ testing_df['address_from_coord'].isnull(), 'address_from_coord'] = ''\n",
    "testing_df.loc[ testing_df['city_from_coord'].isnull(), 'city_from_coord'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "address                         3000\n",
       "city                            3000\n",
       "state                           3000\n",
       "address_from_coord              3000\n",
       "addr_score                      2794\n",
       "city_from_coord                 3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "formatted_address_from_coord    3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2853\n",
       "longitude                       3000\n",
       "longitude_from_address          2853\n",
       "dist_diff                       2853\n",
       "categories                      2984\n",
       "place_id_from_address           2853\n",
       "place_id_from_coord             3000\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df[~testing_df.isnull()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Place Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_placeSearch =\"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={}&inputtype=textquery&locationbias=circle:100@{},{}&key={}&fields=place_id,name,type,permanently_closed\".format(\n",
    "    'Meatball House'.replace(' ','%'),45.4884,-73.5682, api_key)\n",
    "       \n",
    "response_placeSearch =requests.get(url_placeSearch)\n",
    "response_placeSearchJSON= response_placeSearch.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidates': [{'name': 'Meatball House',\n",
       "   'place_id': 'ChIJLd5qjmQayUwRPy5fx6lhk2c',\n",
       "   'types': ['restaurant', 'point_of_interest', 'food', 'establishment']}],\n",
       " 'status': 'OK'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_placeSearchJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'html_attributions': [], 'result': {'name': '1752 Rue Notre-Dame Ouest', 'types': ['street_address']}, 'status': 'OK'}\n"
     ]
    }
   ],
   "source": [
    "url_placeDetails = 'https://maps.googleapis.com/maps/api/place/details/json?placeid={}&fields=name,types&key={}'.format(\n",
    "'ChIJI2drjmQayUwRzU5g3kukboY',api_key)\n",
    "resp = requests.get(url_placeDetails)\n",
    "resp_dict = resp.json()\n",
    "print(resp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining info from Find Place (Places API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_df_with_scores = pd.DataFrame(testing_df[np.bitwise_and(~testing_df.dist_diff.isnull(),~testing_df.addr_score.isnull())][testing_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2771, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flt_df_with_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2173, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flt_df_with_scores[(flt_df_with_scores.dist_diff <= 100) & (flt_df_with_scores.addr_score>=70) ][flt_df_with_scores.columns].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_list_of_dicts = flt_df_with_scores[(flt_df_with_scores.dist_diff <= 100) & (flt_df_with_scores.addr_score>=70) ][flt_df_with_scores.columns].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2173, list)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flt_list_of_dicts), type(flt_list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flt_list_of_dicts)/41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlaceSearchHandlingRequest(record):\n",
    "    dictObj=dict(record)\n",
    "    \n",
    "    b_name = record['name']\n",
    "    b_lat = record['latitude']\n",
    "    b_long = record['longitude']\n",
    "\n",
    "    url_placeSearch =\"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={}&inputtype=textquery&locationbias=circle:100@{},{}&key={}&fields=place_id,name,type\".format(\n",
    "    b_name,b_lat,b_long ,api_key)\n",
    "       \n",
    "    resp_ps =requests.get(url_placeSearch)\n",
    "    resp_psDict= resp_ps.json()\n",
    "       \n",
    "    dictObj['placeSearch_status'] = resp_psDict['status']  # 1\n",
    "    if(dictObj['placeSearch_status']=='OK'):\n",
    "        ObtainData(dictObj,resp_psDict)            \n",
    "    return dictObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ObtainData(dictObj, resp_psDict):\n",
    "    dictObj['business_place_id'] = resp_psDict['candidates'][0]['place_id'] #2\n",
    "    dictObj['name_from_location']= resp_psDict['candidates'][0]['name']  #3\n",
    "    listTypes = resp_psDict['candidates'][0]['types']\n",
    "    strTypes =\", \".join(listTypes)\n",
    "    dictObj['categories_from_location']= strTypes   #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended 41 rows. In total 41\n",
      "Execution time:  1.3877439498901367  seconds.\n",
      "Appended 41 rows. In total 82\n",
      "Execution time:  2.771635055541992  seconds.\n",
      "Appended 41 rows. In total 123\n",
      "Execution time:  4.159236907958984  seconds.\n",
      "Appended 41 rows. In total 164\n",
      "Execution time:  5.54879093170166  seconds.\n",
      "Appended 41 rows. In total 205\n",
      "Execution time:  6.930213928222656  seconds.\n",
      "Appended 41 rows. In total 246\n",
      "Execution time:  8.308640718460083  seconds.\n",
      "Appended 41 rows. In total 287\n",
      "Execution time:  9.692788124084473  seconds.\n",
      "Appended 41 rows. In total 328\n",
      "Execution time:  11.080191135406494  seconds.\n",
      "Appended 41 rows. In total 369\n",
      "Execution time:  12.462975025177002  seconds.\n",
      "Appended 41 rows. In total 410\n",
      "Execution time:  13.860663890838623  seconds.\n",
      "Appended 41 rows. In total 451\n",
      "Execution time:  15.233250856399536  seconds.\n",
      "Appended 41 rows. In total 492\n",
      "Execution time:  16.620210886001587  seconds.\n",
      "Appended 41 rows. In total 533\n",
      "Execution time:  18.013474941253662  seconds.\n",
      "Appended 41 rows. In total 574\n",
      "Execution time:  19.410805702209473  seconds.\n",
      "Appended 41 rows. In total 615\n",
      "Execution time:  20.78187894821167  seconds.\n",
      "Appended 41 rows. In total 656\n",
      "Execution time:  22.169805765151978  seconds.\n",
      "Appended 41 rows. In total 697\n",
      "Execution time:  26.139781951904297  seconds.\n",
      "Appended 41 rows. In total 738\n",
      "Execution time:  31.089346885681152  seconds.\n",
      "Appended 41 rows. In total 779\n",
      "Execution time:  35.13517189025879  seconds.\n",
      "Appended 41 rows. In total 820\n",
      "Execution time:  39.90575289726257  seconds.\n",
      "Appended 41 rows. In total 861\n",
      "Execution time:  44.059682846069336  seconds.\n",
      "Appended 41 rows. In total 902\n",
      "Execution time:  48.21386694908142  seconds.\n",
      "Appended 41 rows. In total 943\n",
      "Execution time:  52.78075695037842  seconds.\n",
      "Appended 41 rows. In total 984\n",
      "Execution time:  57.2644259929657  seconds.\n",
      "Appended 41 rows. In total 1025\n",
      "Execution time:  61.62956094741821  seconds.\n",
      "Appended 41 rows. In total 1066\n",
      "Execution time:  66.1126298904419  seconds.\n",
      "Appended 41 rows. In total 1107\n",
      "Execution time:  70.57208776473999  seconds.\n",
      "Appended 41 rows. In total 1148\n",
      "Execution time:  74.76075196266174  seconds.\n",
      "Appended 41 rows. In total 1189\n",
      "Execution time:  78.81330275535583  seconds.\n",
      "Appended 41 rows. In total 1230\n",
      "Execution time:  83.57717990875244  seconds.\n",
      "Appended 41 rows. In total 1271\n",
      "Execution time:  88.33957195281982  seconds.\n",
      "Appended 41 rows. In total 1312\n",
      "Execution time:  94.03223896026611  seconds.\n",
      "Appended 41 rows. In total 1353\n",
      "Execution time:  98.70358800888062  seconds.\n",
      "Appended 41 rows. In total 1394\n",
      "Execution time:  103.28057789802551  seconds.\n",
      "Appended 41 rows. In total 1435\n",
      "Execution time:  107.86665987968445  seconds.\n",
      "Appended 41 rows. In total 1476\n",
      "Execution time:  112.34134101867676  seconds.\n",
      "Appended 41 rows. In total 1517\n",
      "Execution time:  116.38991904258728  seconds.\n",
      "Appended 41 rows. In total 1558\n",
      "Execution time:  121.16521978378296  seconds.\n",
      "Appended 41 rows. In total 1599\n",
      "Execution time:  125.51002597808838  seconds.\n",
      "Appended 41 rows. In total 1640\n",
      "Execution time:  129.75257992744446  seconds.\n",
      "Appended 41 rows. In total 1681\n",
      "Execution time:  134.10957288742065  seconds.\n",
      "Appended 41 rows. In total 1722\n",
      "Execution time:  138.56562495231628  seconds.\n",
      "Appended 41 rows. In total 1763\n",
      "Execution time:  142.82872796058655  seconds.\n",
      "Appended 41 rows. In total 1804\n",
      "Execution time:  147.2925148010254  seconds.\n",
      "Appended 41 rows. In total 1845\n",
      "Execution time:  151.56368017196655  seconds.\n",
      "Appended 41 rows. In total 1886\n",
      "Execution time:  155.81609392166138  seconds.\n",
      "Appended 41 rows. In total 1927\n",
      "Execution time:  159.96066999435425  seconds.\n",
      "Appended 41 rows. In total 1968\n",
      "Execution time:  164.94490790367126  seconds.\n",
      "Appended 41 rows. In total 2009\n",
      "Execution time:  169.22658276557922  seconds.\n",
      "Appended 41 rows. In total 2050\n",
      "Execution time:  173.47633600234985  seconds.\n",
      "Appended 41 rows. In total 2091\n",
      "Execution time:  177.6421799659729  seconds.\n",
      "Appended 41 rows. In total 2132\n",
      "Execution time:  181.91329908370972  seconds.\n",
      "Appended 41 rows. In total 2173\n",
      "Execution time:  186.91731691360474  seconds.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import multiprocessing\n",
    "import time as time\n",
    "\n",
    "start = time.time()\n",
    "counter = 0\n",
    "\n",
    "dicts_with_even_name_types=[]\n",
    "for i in range(0,len(flt_list_of_dicts),41):\n",
    "    with multiprocessing.Pool( processes=multiprocessing.cpu_count()) as pool:\n",
    "        dicts_with_even_name_types+=pool.map(PlaceSearchHandlingRequest, flt_list_of_dicts[i:i+41])\n",
    "    counter+=41   \n",
    "    print(\"Appended 41 rows. In total {}\".format(counter))\n",
    "    end = time.time()\n",
    "    print(\"Execution time: \", end - start, \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2173"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dicts_with_even_name_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePlaceSearchForEveryCase = pd.DataFrame(dicts_with_even_name_types)[['business_id',\n",
    "            'name',\n",
    "            'name_from_location',\n",
    "            'address',\n",
    "            'city',\n",
    "            'state',\n",
    "            'address_from_coord',\n",
    "            'addr_score',\n",
    "            'city_from_coord',\n",
    "            'state_from_coord',\n",
    "            'country_from_coord', \n",
    "            'formatted_address_from_coord',      \n",
    "            'latitude',\n",
    "            'latitude_from_address',\n",
    "            'longitude',\n",
    "            'longitude_from_address',\n",
    "            'dist_diff',   \n",
    "            'categories',\n",
    "            'categories_from_location',\n",
    "            'place_id_from_address',\n",
    "            'place_id_from_coord',\n",
    "            'business_place_id',\n",
    "            'geocoding_status',\n",
    "            'invgeocoding_status',                                                                        \n",
    "            'placeSearch_status'                                                    \n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     2173\n",
       "name                            2173\n",
       "name_from_location              2109\n",
       "address                         2173\n",
       "city                            2173\n",
       "state                           2173\n",
       "address_from_coord              2173\n",
       "addr_score                      2173\n",
       "city_from_coord                 2173\n",
       "state_from_coord                2173\n",
       "country_from_coord              2173\n",
       "formatted_address_from_coord    2173\n",
       "latitude                        2173\n",
       "latitude_from_address           2173\n",
       "longitude                       2173\n",
       "longitude_from_address          2173\n",
       "dist_diff                       2173\n",
       "categories                      2162\n",
       "categories_from_location        2109\n",
       "place_id_from_address           2173\n",
       "place_id_from_coord             2173\n",
       "business_place_id               2109\n",
       "geocoding_status                2173\n",
       "invgeocoding_status             2173\n",
       "placeSearch_status              2173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savePlaceSearchForEveryCase[~savePlaceSearchForEveryCase.isnull()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2173, 25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savePlaceSearchForEveryCase.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePlaceSearchForEveryCase.to_csv(path_or_buf='/Users/kemalm/Desktop/FinalGM/spasi_da_se_ne_gubi.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.DataFrame(        pd.merge(testing_df, \n",
    "         savePlaceSearchForEveryCase[['business_id','business_place_id','name_from_location','categories_from_location','placeSearch_status']],\n",
    "         on='business_id',\n",
    "         how='left'))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 25)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1971, 25)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df.placeSearch_status =='OK'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OK' nan 'ZERO_RESULTS' 'REQUEST_DENIED'] ['OK' 'ZERO_RESULTS' 'REQUEST_DENIED' nan] ['OK']\n"
     ]
    }
   ],
   "source": [
    "print(merged_df['placeSearch_status'].unique(),\n",
    "merged_df['geocoding_status'].unique(),\n",
    "merged_df['invgeocoding_status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[['business_id',\n",
    "            'name',\n",
    "            'name_from_location',\n",
    "            'address',\n",
    "            'city',\n",
    "            'state',\n",
    "            'address_from_coord',\n",
    "            'addr_score',\n",
    "            'city_from_coord',\n",
    "            'state_from_coord',\n",
    "            'country_from_coord', \n",
    "            'formatted_address_from_coord',      \n",
    "            'latitude',\n",
    "            'latitude_from_address',\n",
    "            'longitude',\n",
    "            'longitude_from_address',\n",
    "            'dist_diff',   \n",
    "            'categories',\n",
    "            'categories_from_location',\n",
    "            'place_id_from_address',\n",
    "            'place_id_from_coord',\n",
    "            'business_place_id',\n",
    "            'geocoding_status',\n",
    "            'invgeocoding_status',                                                                        \n",
    "            'placeSearch_status'                                                    \n",
    "]].to_csv(path_or_buf='/Users/kemalm/Desktop/FinalGM/mrgSample.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "address                         3000\n",
       "city                            3000\n",
       "state                           3000\n",
       "address_from_coord              3000\n",
       "addr_score                      2794\n",
       "city_from_coord                 3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "formatted_address_from_coord    3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2853\n",
       "longitude                       3000\n",
       "longitude_from_address          2853\n",
       "dist_diff                       2853\n",
       "categories                      2984\n",
       "place_id_from_address           2853\n",
       "place_id_from_coord             3000\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "business_place_id               2109\n",
       "name_from_location              2109\n",
       "categories_from_location        2109\n",
       "placeSearch_status              2173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[~merged_df.isnull()].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Dataset (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from scipy.spatial.distance import pdist\n",
    "from geopy.distance import geodesic\n",
    "import random as rn\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_mrgDataset = pd.read_csv('/Users/kemalm/Desktop/FinalGM//mrgSample.csv')\n",
    "testing_mrgDataset.loc[ testing_mrgDataset['address'].isnull(), 'address'] = ''\n",
    "testing_mrgDataset.loc[ testing_mrgDataset['address_from_coord'].isnull(), 'address_from_coord'] = ''\n",
    "testing_mrgDataset.loc[ testing_mrgDataset['city_from_coord'].isnull(), 'city_from_coord'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_mrgDataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "name_from_location              2109\n",
       "address                         3000\n",
       "city                            3000\n",
       "state                           3000\n",
       "address_from_coord              3000\n",
       "addr_score                      2794\n",
       "city_from_coord                 3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "formatted_address_from_coord    3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2853\n",
       "longitude                       3000\n",
       "longitude_from_address          2853\n",
       "dist_diff                       2853\n",
       "categories                      2984\n",
       "categories_from_location        2109\n",
       "place_id_from_address           2853\n",
       "place_id_from_coord             3000\n",
       "business_place_id               2109\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "placeSearch_status              2173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_mrgDataset[~testing_mrgDataset.isnull()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>name_from_location</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>address_from_coord</th>\n",
       "      <th>addr_score</th>\n",
       "      <th>city_from_coord</th>\n",
       "      <th>state_from_coord</th>\n",
       "      <th>...</th>\n",
       "      <th>longitude_from_address</th>\n",
       "      <th>dist_diff</th>\n",
       "      <th>categories</th>\n",
       "      <th>categories_from_location</th>\n",
       "      <th>place_id_from_address</th>\n",
       "      <th>place_id_from_coord</th>\n",
       "      <th>business_place_id</th>\n",
       "      <th>geocoding_status</th>\n",
       "      <th>invgeocoding_status</th>\n",
       "      <th>placeSearch_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1hceMTsoDKL40bgIqp1xkg</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>6432 Rea Road</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>6432 Rea Road</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>NC</td>\n",
       "      <td>...</td>\n",
       "      <td>-80.816995</td>\n",
       "      <td>9.529686</td>\n",
       "      <td>Coffee &amp; Tea, Food</td>\n",
       "      <td>cafe, store, point_of_interest, food, establis...</td>\n",
       "      <td>ChIJo18GonudVogR9ekBTl4V-CE</td>\n",
       "      <td>ChIJo18GonudVogR9ekBTl4V-CE</td>\n",
       "      <td>ChIJR_RWn3udVogRx4cfeLSF874</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LQ9WorDtNJXeEfA7GWIXTA</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>6355 Yonge Street</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>6355 Yonge Street</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>...</td>\n",
       "      <td>-79.419442</td>\n",
       "      <td>3.180084</td>\n",
       "      <td>Food, Coffee &amp; Tea</td>\n",
       "      <td>cafe, store, point_of_interest, food, establis...</td>\n",
       "      <td>ChIJRfwx1_0sK4gRxV1F-gxATs4</td>\n",
       "      <td>ChIJRfwx1_0sK4gRxV1F-gxATs4</td>\n",
       "      <td>ChIJNQXt2P0sK4gRyF8gjfCEw6g</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wphF5TNh31RQ0a-nbrpqyw</td>\n",
       "      <td>Olive That Tasting Bar</td>\n",
       "      <td>Olive That! Tasting Bar</td>\n",
       "      <td>B104-20 Broadleaf Avenue</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>ON</td>\n",
       "      <td>20 Broadleaf Avenue</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>ON</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.958035</td>\n",
       "      <td>1.181710</td>\n",
       "      <td>Food, Specialty Food</td>\n",
       "      <td>grocery_or_supermarket, store, point_of_intere...</td>\n",
       "      <td>EjJCMTA0LCAyMCBCcm9hZGxlYWYgQXZlLCBXaGl0YnksIE...</td>\n",
       "      <td>ChIJtX5ikeke1YkRNQO_9fjR3q4</td>\n",
       "      <td>ChIJS-bFhuke1YkRKIf75rl2py8</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zXO__HLv4CqHJ7LJNUOc2A</td>\n",
       "      <td>Red Dice</td>\n",
       "      <td>Red Hat Canada Ltd</td>\n",
       "      <td>884 Danforth Avenue</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>884 Danforth Avenue</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>...</td>\n",
       "      <td>-79.339836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Pizza, Restaurants, Chicken Wings</td>\n",
       "      <td>point_of_interest, establishment</td>\n",
       "      <td>ChIJO_sukobM1IkRDFPsqclHv1o</td>\n",
       "      <td>ChIJO_sukobM1IkRDFPsqclHv1o</td>\n",
       "      <td>ChIJwbmDRiMzK4gRztvVvgl_ZFo</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r6bvqwhWy73SgyK_w8Y5Lg</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2555 Victoria Park Avenue</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>2555 Victoria Park Avenue</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>...</td>\n",
       "      <td>-79.321620</td>\n",
       "      <td>121.108905</td>\n",
       "      <td>Sandwiches, Food, Restaurants, Coffee &amp; Tea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJ15ZCjUTS1IkRXKGy0wP-z_U</td>\n",
       "      <td>ChIJdTLliUTS1IkRbIpYhzH4nd0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                    name       name_from_location  \\\n",
       "0  1hceMTsoDKL40bgIqp1xkg               Starbucks                Starbucks   \n",
       "1  LQ9WorDtNJXeEfA7GWIXTA               Starbucks                Starbucks   \n",
       "2  wphF5TNh31RQ0a-nbrpqyw  Olive That Tasting Bar  Olive That! Tasting Bar   \n",
       "3  zXO__HLv4CqHJ7LJNUOc2A                Red Dice       Red Hat Canada Ltd   \n",
       "4  r6bvqwhWy73SgyK_w8Y5Lg               Starbucks                      NaN   \n",
       "\n",
       "                     address       city state         address_from_coord  \\\n",
       "0              6432 Rea Road  Charlotte    NC              6432 Rea Road   \n",
       "1          6355 Yonge Street    Toronto    ON          6355 Yonge Street   \n",
       "2   B104-20 Broadleaf Avenue     Whitby    ON        20 Broadleaf Avenue   \n",
       "3        884 Danforth Avenue    Toronto    ON        884 Danforth Avenue   \n",
       "4  2555 Victoria Park Avenue    Toronto    ON  2555 Victoria Park Avenue   \n",
       "\n",
       "   addr_score city_from_coord state_from_coord        ...          \\\n",
       "0       100.0       Charlotte               NC        ...           \n",
       "1       100.0         Toronto               ON        ...           \n",
       "2       100.0          Whitby               ON        ...           \n",
       "3       100.0         Toronto               ON        ...           \n",
       "4       100.0         Toronto               ON        ...           \n",
       "\n",
       "  longitude_from_address   dist_diff  \\\n",
       "0             -80.816995    9.529686   \n",
       "1             -79.419442    3.180084   \n",
       "2             -78.958035    1.181710   \n",
       "3             -79.339836    0.000000   \n",
       "4             -79.321620  121.108905   \n",
       "\n",
       "                                    categories  \\\n",
       "0                           Coffee & Tea, Food   \n",
       "1                           Food, Coffee & Tea   \n",
       "2                         Food, Specialty Food   \n",
       "3            Pizza, Restaurants, Chicken Wings   \n",
       "4  Sandwiches, Food, Restaurants, Coffee & Tea   \n",
       "\n",
       "                            categories_from_location  \\\n",
       "0  cafe, store, point_of_interest, food, establis...   \n",
       "1  cafe, store, point_of_interest, food, establis...   \n",
       "2  grocery_or_supermarket, store, point_of_intere...   \n",
       "3                   point_of_interest, establishment   \n",
       "4                                                NaN   \n",
       "\n",
       "                               place_id_from_address  \\\n",
       "0                        ChIJo18GonudVogR9ekBTl4V-CE   \n",
       "1                        ChIJRfwx1_0sK4gRxV1F-gxATs4   \n",
       "2  EjJCMTA0LCAyMCBCcm9hZGxlYWYgQXZlLCBXaGl0YnksIE...   \n",
       "3                        ChIJO_sukobM1IkRDFPsqclHv1o   \n",
       "4                        ChIJ15ZCjUTS1IkRXKGy0wP-z_U   \n",
       "\n",
       "           place_id_from_coord            business_place_id geocoding_status  \\\n",
       "0  ChIJo18GonudVogR9ekBTl4V-CE  ChIJR_RWn3udVogRx4cfeLSF874               OK   \n",
       "1  ChIJRfwx1_0sK4gRxV1F-gxATs4  ChIJNQXt2P0sK4gRyF8gjfCEw6g               OK   \n",
       "2  ChIJtX5ikeke1YkRNQO_9fjR3q4  ChIJS-bFhuke1YkRKIf75rl2py8               OK   \n",
       "3  ChIJO_sukobM1IkRDFPsqclHv1o  ChIJwbmDRiMzK4gRztvVvgl_ZFo               OK   \n",
       "4  ChIJdTLliUTS1IkRbIpYhzH4nd0                          NaN               OK   \n",
       "\n",
       "  invgeocoding_status placeSearch_status  \n",
       "0                  OK                 OK  \n",
       "1                  OK                 OK  \n",
       "2                  OK                 OK  \n",
       "3                  OK                 OK  \n",
       "4                  OK                NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_mrgDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import math as mt\n",
    "\n",
    "list_of_buss =list() \n",
    "for idx, row in enumerate(testing_mrgDataset.itertuples(index=False)):\n",
    "    dictObj=dict()\n",
    "    \n",
    "    business_id=row.__getattribute__('business_id')\n",
    "    dictObj['business_id'] = business_id\n",
    "    \n",
    "    name=row.__getattribute__('name')\n",
    "    dictObj['name'] = name\n",
    "\n",
    "    name_frm_loc=row.__getattribute__('name_from_location')\n",
    "    dictObj['name_from_location'] = name_frm_loc\n",
    "       \n",
    "    if(type(name_frm_loc)==str and name_frm_loc!=''):\n",
    "        name_score = fuzz.token_set_ratio(name,name_frm_loc)\n",
    "        dictObj['name_score'] = name_score\n",
    " \n",
    "    cat=row.__getattribute__('categories')\n",
    "    dictObj['categories'] = cat\n",
    "    \n",
    "    cat_frn_loc=row.__getattribute__('categories_from_location')\n",
    "    dictObj['categories_from_location']= cat_frn_loc\n",
    "    if(type(name_frm_loc)==str and cat_frn_loc!=''):     \n",
    "        cat_frm_loc_filtered = cat_frn_loc.replace(\"point_of_interest\",\"\").replace(\"establishment\",\"\")\n",
    "        categories_score = fuzz.token_set_ratio(cat,cat_frm_loc_filtered)\n",
    "        dictObj['categories_score']= categories_score\n",
    "    list_of_buss.append(dictObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_buss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_set_ratio('coffee tea food', 'cafe store food,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_buss = pd.DataFrame(list_of_buss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accul=pd.DataFrame(pd.merge(testing_mrgDataset, \n",
    "         dict_buss[['business_id', 'name_score', 'categories_score']],\n",
    "         on='business_id',\n",
    "         how='left')[['business_id',\n",
    "            'name',\n",
    "            'name_from_location',\n",
    "            'name_score',\n",
    "            'address',\n",
    "            'city',\n",
    "            'state',\n",
    "            'address_from_coord',\n",
    "            'addr_score',\n",
    "            'city_from_coord',\n",
    "            'state_from_coord',\n",
    "            'country_from_coord', \n",
    "            'formatted_address_from_coord',      \n",
    "            'latitude',\n",
    "            'latitude_from_address',\n",
    "            'longitude',\n",
    "            'longitude_from_address',\n",
    "            'dist_diff',   \n",
    "            'categories',\n",
    "            'categories_from_location',\n",
    "            'categories_score',\n",
    "            'place_id_from_address',\n",
    "            'place_id_from_coord',\n",
    "            'business_place_id',\n",
    "            'geocoding_status',\n",
    "            'invgeocoding_status',                                                                        \n",
    "            'placeSearch_status'     \n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accul.to_csv(path_or_buf='/Users/kemalm/Desktop/FinalGM/allScoresSample.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "name_from_location              2109\n",
       "name_score                      2109\n",
       "address                         3000\n",
       "city                            3000\n",
       "state                           3000\n",
       "address_from_coord              3000\n",
       "addr_score                      2794\n",
       "city_from_coord                 3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "formatted_address_from_coord    3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2853\n",
       "longitude                       3000\n",
       "longitude_from_address          2853\n",
       "dist_diff                       2853\n",
       "categories                      2984\n",
       "categories_from_location        2109\n",
       "categories_score                2109\n",
       "place_id_from_address           2853\n",
       "place_id_from_coord             3000\n",
       "business_place_id               2109\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "placeSearch_status              2173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accul[~df_accul.isnull()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allscores = pd.read_csv('/Users/kemalm/Desktop/FinalGM/allScoresSample.csv')\n",
    "df_allscores.loc[ df_allscores['address'].isnull(), 'address'] = ''\n",
    "df_allscores.loc[ df_allscores['address_from_coord'].isnull(), 'address_from_coord'] = ''\n",
    "df_allscores.loc[ df_allscores['city_from_coord'].isnull(), 'city_from_coord'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 27)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_allscores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id                     3000\n",
       "name                            3000\n",
       "name_from_location              2109\n",
       "name_score                      2109\n",
       "address                         3000\n",
       "city                            3000\n",
       "state                           3000\n",
       "address_from_coord              3000\n",
       "addr_score                      2794\n",
       "city_from_coord                 3000\n",
       "state_from_coord                3000\n",
       "country_from_coord              3000\n",
       "formatted_address_from_coord    3000\n",
       "latitude                        3000\n",
       "latitude_from_address           2853\n",
       "longitude                       3000\n",
       "longitude_from_address          2853\n",
       "dist_diff                       2853\n",
       "categories                      2984\n",
       "categories_from_location        2109\n",
       "categories_score                2109\n",
       "place_id_from_address           2853\n",
       "place_id_from_coord             3000\n",
       "business_place_id               2109\n",
       "geocoding_status                2876\n",
       "invgeocoding_status             3000\n",
       "placeSearch_status              2173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_allscores[~df_allscores.isnull()].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify suspicous patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try:\n",
    "    conn=psycopg2.connect(\"dbname='yelpDB' user='postgres' host='localhost' password='P0$tgre$QL'\")\n",
    "except:\n",
    "    print(\"I am unable to connect to the database\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"SELECT state,  COUNT(business_id) AS total_Count\n",
    "               FROM Businesses\n",
    "               GROUP BY state \n",
    "               ORDER BY 2 DESC\"\"\")\n",
    "statesQuery = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_states_prov_terr = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming',\n",
    "        'AB': 'Alberta',\n",
    "        'BC': 'British Columbia',\n",
    "        'MB': 'Manitoba',\n",
    "        'NB': 'New Brunswick',\n",
    "        'NL': 'Newfoundland and Labrador',\n",
    "        'NT': 'Northwest Territories',\n",
    "        'NS': 'Nova Scotia',\n",
    "        'NU': 'Nunavut',\n",
    "        'ON': 'Ontario',\n",
    "        'PE': 'Prince Edward Island',\n",
    "        'QC': 'Quebec',\n",
    "        'SK': 'Saskatchewan',\n",
    "        'YT': 'Yukon'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statesQuery = pd.DataFrame(statesQuery, columns=['state','total_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>total_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ</td>\n",
       "      <td>56686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NV</td>\n",
       "      <td>36312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ON</td>\n",
       "      <td>33412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NC</td>\n",
       "      <td>14720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OH</td>\n",
       "      <td>14697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  total_count\n",
       "0    AZ        56686\n",
       "1    NV        36312\n",
       "2    ON        33412\n",
       "3    NC        14720\n",
       "4    OH        14697"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_statesQuery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statesQuery['state_exists'] = df_statesQuery['state'].isin(dct_states_prov_terr.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_exist = np.array([ (el[0], int(el[0] in dct_states_prov_terr.keys())) for el in df_statesQuery])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>total_count</th>\n",
       "      <th>state_exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGM</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XWY</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DUR</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DOW</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BAS</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CON</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XGL</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  total_count  state_exists\n",
       "14   XGM            4         False\n",
       "19   XWY            2         False\n",
       "25   DUR            1         False\n",
       "27   DOW            1         False\n",
       "29   BAS            1         False\n",
       "31   CON            1         False\n",
       "33   XGL            1         False"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_statesQuery[df_statesQuery['state_exists'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get corresponding records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpl_str = str(list(df_statesQuery[df_statesQuery['state_exists'] == False]['state'].values)).replace('[','').replace(']','')\n",
    "\n",
    "cur.execute(\"\"\"SELECT *\n",
    "         FROM Businesses\n",
    "         WHERE state IN ({})\"\"\".format(rpl_str))\n",
    "all_recs =cur.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('svMJjPd4l_Zb_MoxejYZvw',\n",
       "  'Zoom Printing',\n",
       "  '1136 Center Street, Suite 442',\n",
       "  'Thornhill',\n",
       "  'DUR',\n",
       "  'L4J 3M8',\n",
       "  43.8085625817,\n",
       "  -79.4638055695,\n",
       "  3.5,\n",
       "  3,\n",
       "  1,\n",
       "  {},\n",
       "  'Professional Services, Advertising, Printing Services, Print Media, Mass Media, Local Services',\n",
       "  {'Friday': '9:0-17:0',\n",
       "   'Monday': '9:0-17:0',\n",
       "   'Tuesday': '9:0-17:0',\n",
       "   'Thursday': '9:0-17:0',\n",
       "   'Wednesday': '9:0-17:0'}),\n",
       " ('d4qoXn1Rqt47LLTDA3bAwQ',\n",
       "  'Thayer David Ice Cream Shop',\n",
       "  '8 York St',\n",
       "  'Bath',\n",
       "  'BAS',\n",
       "  'BA1 1NG',\n",
       "  43.6406456,\n",
       "  -79.380939,\n",
       "  4.0,\n",
       "  4,\n",
       "  1,\n",
       "  {'RestaurantsPriceRange2': '1'},\n",
       "  'Food, Ice Cream & Frozen Yogurt',\n",
       "  {}),\n",
       " ('8_GNJU3EPar9VkPzJvoC3w',\n",
       "  'Bean & Brush Family Art Café',\n",
       "  'The Old Sorting Office, 12 Hayfield Street',\n",
       "  'Sale',\n",
       "  'XGM',\n",
       "  'M33 7XW',\n",
       "  42.9960594,\n",
       "  -89.568889,\n",
       "  4.0,\n",
       "  4,\n",
       "  1,\n",
       "  {'WiFi': \"u'free'\",\n",
       "   'Caters': 'True',\n",
       "   'BikeParking': 'True',\n",
       "   'OutdoorSeating': 'True',\n",
       "   'BusinessParking': \"{'garage': False, 'street': False, 'validated': False, 'lot': False, 'valet': False}\",\n",
       "   'RestaurantsAttire': \"'casual'\",\n",
       "   'RestaurantsTakeOut': 'True',\n",
       "   'RestaurantsPriceRange2': '2',\n",
       "   'RestaurantsReservations': 'False',\n",
       "   'RestaurantsGoodForGroups': 'True'},\n",
       "  'Arts & Crafts, Shopping, Coffee & Tea, Food',\n",
       "  {'Friday': '8:30-19:0',\n",
       "   'Monday': '8:30-19:0',\n",
       "   'Sunday': '9:0-18:0',\n",
       "   'Tuesday': '8:30-19:0',\n",
       "   'Saturday': '8:30-19:0',\n",
       "   'Thursday': '8:30-19:0',\n",
       "   'Wednesday': '8:30-19:0'}),\n",
       " ('44xjnQMwAQjgZ80MW5z-Gg',\n",
       "  'No. 37 Sandwich Bar',\n",
       "  '37 Monk Bridge Road',\n",
       "  'Leeds',\n",
       "  'XWY',\n",
       "  'LS6 4EP',\n",
       "  45.456999,\n",
       "  -73.59525,\n",
       "  4.5,\n",
       "  3,\n",
       "  1,\n",
       "  {'WiFi': \"'no'\",\n",
       "   'Alcohol': \"u'none'\",\n",
       "   'OutdoorSeating': 'True',\n",
       "   'BusinessParking': \"{'garage': False, 'validated': False, 'street': False, 'lot': False, 'valet': False}\",\n",
       "   'RestaurantsAttire': \"u'casual'\",\n",
       "   'RestaurantsTakeOut': 'True',\n",
       "   'RestaurantsDelivery': 'True',\n",
       "   'RestaurantsReservations': 'False'},\n",
       "  'Bakeries, Food, Desserts, Restaurants, Sandwiches',\n",
       "  {'Friday': '7:0-15:0',\n",
       "   'Monday': '7:0-15:0',\n",
       "   'Tuesday': '7:0-15:0',\n",
       "   'Thursday': '7:0-15:0',\n",
       "   'Wednesday': '7:0-15:0'}),\n",
       " ('eeEcf7XXAGClqdUCwnwRfg',\n",
       "  'The Old Lifeboat House',\n",
       "  'The Cove, Coverack Helston',\n",
       "  'Church Cove',\n",
       "  'CON',\n",
       "  'TR12 6SX',\n",
       "  35.532021,\n",
       "  -80.8516825,\n",
       "  3.5,\n",
       "  3,\n",
       "  1,\n",
       "  {'RestaurantsTakeOut': 'True',\n",
       "   'RestaurantsDelivery': 'False',\n",
       "   'RestaurantsGoodForGroups': 'True'},\n",
       "  'British, Restaurants',\n",
       "  {}),\n",
       " ('JNZeVq9jr9AWURmnM-Yxig',\n",
       "  'Total Gardening and Landscaping',\n",
       "  '',\n",
       "  'Bury',\n",
       "  'XGM',\n",
       "  'BL8 4DR',\n",
       "  42.9960594,\n",
       "  -89.568889,\n",
       "  5.0,\n",
       "  3,\n",
       "  1,\n",
       "  {'ByAppointmentOnly': 'False', 'BusinessAcceptsBitcoin': 'False'},\n",
       "  'Home Services, Landscaping, Tree Services, Gardeners',\n",
       "  {'Friday': '0:0-0:0',\n",
       "   'Monday': '0:0-0:0',\n",
       "   'Sunday': '0:0-0:0',\n",
       "   'Tuesday': '0:0-0:0',\n",
       "   'Saturday': '0:0-0:0',\n",
       "   'Thursday': '0:0-0:0',\n",
       "   'Wednesday': '0:0-0:0'}),\n",
       " ('6dhkHf-CFHr7C8wj-qopCQ',\n",
       "  'Paper Cutz',\n",
       "  'Gorebrook Works, Pinkbank Lane',\n",
       "  'Manchester',\n",
       "  'XGM',\n",
       "  'M12 5GH',\n",
       "  42.9960594,\n",
       "  -89.568889,\n",
       "  2.5,\n",
       "  3,\n",
       "  1,\n",
       "  {'BusinessParking': \"{'garage': False, 'validated': False, 'street': False, 'lot': False, 'valet': False}\",\n",
       "   'RestaurantsPriceRange2': '4'},\n",
       "  'Art Supplies, Arts & Crafts, Shopping',\n",
       "  {}),\n",
       " ('FByZsT1Sob5Vf1AYJFPxPg',\n",
       "  'Desi Masala',\n",
       "  '61 Queen Street',\n",
       "  'Leeds',\n",
       "  'XWY',\n",
       "  'LS27 8EB',\n",
       "  43.6528212,\n",
       "  -79.3763454,\n",
       "  4.5,\n",
       "  5,\n",
       "  1,\n",
       "  {'WiFi': \"'no'\",\n",
       "   'HasTV': 'True',\n",
       "   'Alcohol': \"'none'\",\n",
       "   'Ambience': \"{'romantic': False, 'intimate': False, 'classy': False, 'hipster': False, 'touristy': False, 'trendy': False, 'upscale': False, 'casual': False}\",\n",
       "   'NoiseLevel': \"u'average'\",\n",
       "   'OutdoorSeating': 'False',\n",
       "   'BusinessParking': \"{'garage': False, 'street': False, 'lot': False, 'valet': False}\",\n",
       "   'RestaurantsAttire': \"u'dressy'\",\n",
       "   'RestaurantsTakeOut': 'True',\n",
       "   'RestaurantsDelivery': 'True',\n",
       "   'RestaurantsPriceRange2': '2',\n",
       "   'RestaurantsReservations': 'True',\n",
       "   'RestaurantsGoodForGroups': 'True'},\n",
       "  'Indian, Pakistani, Restaurants',\n",
       "  {}),\n",
       " ('xjR-PII302WyyNRfpcowDg',\n",
       "  \"Moxon's Fishmongers\",\n",
       "  '110 Islington High Street',\n",
       "  'London',\n",
       "  'XGL',\n",
       "  'N1 8EG',\n",
       "  43.645355,\n",
       "  -79.524467,\n",
       "  4.5,\n",
       "  3,\n",
       "  1,\n",
       "  {'BusinessParking': \"{'garage': False, 'street': True, 'lot': False, 'valet': False}\",\n",
       "   'WheelchairAccessible': 'True',\n",
       "   'BusinessAcceptsBitcoin': 'False',\n",
       "   'RestaurantsPriceRange2': '2'},\n",
       "  'Specialty Food, Food, Seafood Markets',\n",
       "  {'Friday': '9:0-19:30',\n",
       "   'Tuesday': '9:0-19:30',\n",
       "   'Saturday': '9:0-17:30',\n",
       "   'Thursday': '9:0-19:30',\n",
       "   'Wednesday': '9:0-19:30'}),\n",
       " ('ZsL7FUkaWdyQnDoYB6XpSA',\n",
       "  'Happy Gathering Resturant Oldham',\n",
       "  '',\n",
       "  'Oldham',\n",
       "  'XGM',\n",
       "  'OL2 6PX',\n",
       "  42.9960594,\n",
       "  -89.568889,\n",
       "  4.0,\n",
       "  3,\n",
       "  1,\n",
       "  {},\n",
       "  'Chinese, Restaurants',\n",
       "  {}),\n",
       " ('U9uyfhpZ89VEH5_webJ5Xg',\n",
       "  'Storm Cinemas - Belfast',\n",
       "  'Odyssey Arena, 2 Queens Quay',\n",
       "  'Down',\n",
       "  'DOW',\n",
       "  'BT33 0',\n",
       "  43.6416582,\n",
       "  -79.37603,\n",
       "  3.0,\n",
       "  4,\n",
       "  1,\n",
       "  {},\n",
       "  'Arts & Entertainment',\n",
       "  {})]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suspBus= pd.DataFrame(all_recs,columns=[\"business_id\",\n",
    "                                \"name\",\n",
    "                                \"address\",\n",
    "                                \"city\",\n",
    "                                \"state\",\n",
    "                                \"postal_code\",\n",
    "                                \"latitude\",\n",
    "                                \"longitude\",\n",
    "                                \"stars\",\n",
    "                                \"review_count\",\n",
    "                                \"is_open\",\n",
    "                                \"attributes\",\n",
    "                                \"categories\",\n",
    "                                \"hours\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svMJjPd4l_Zb_MoxejYZvw</td>\n",
       "      <td>Zoom Printing</td>\n",
       "      <td>1136 Center Street, Suite 442</td>\n",
       "      <td>Thornhill</td>\n",
       "      <td>DUR</td>\n",
       "      <td>L4J 3M8</td>\n",
       "      <td>43.808563</td>\n",
       "      <td>-79.463806</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>Professional Services, Advertising, Printing S...</td>\n",
       "      <td>{'Friday': '9:0-17:0', 'Monday': '9:0-17:0', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d4qoXn1Rqt47LLTDA3bAwQ</td>\n",
       "      <td>Thayer David Ice Cream Shop</td>\n",
       "      <td>8 York St</td>\n",
       "      <td>Bath</td>\n",
       "      <td>BAS</td>\n",
       "      <td>BA1 1NG</td>\n",
       "      <td>43.640646</td>\n",
       "      <td>-79.380939</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsPriceRange2': '1'}</td>\n",
       "      <td>Food, Ice Cream &amp; Frozen Yogurt</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8_GNJU3EPar9VkPzJvoC3w</td>\n",
       "      <td>Bean &amp; Brush Family Art Café</td>\n",
       "      <td>The Old Sorting Office, 12 Hayfield Street</td>\n",
       "      <td>Sale</td>\n",
       "      <td>XGM</td>\n",
       "      <td>M33 7XW</td>\n",
       "      <td>42.996059</td>\n",
       "      <td>-89.568889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WiFi': 'u'free'', 'Caters': 'True', 'BikePar...</td>\n",
       "      <td>Arts &amp; Crafts, Shopping, Coffee &amp; Tea, Food</td>\n",
       "      <td>{'Friday': '8:30-19:0', 'Monday': '8:30-19:0',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44xjnQMwAQjgZ80MW5z-Gg</td>\n",
       "      <td>No. 37 Sandwich Bar</td>\n",
       "      <td>37 Monk Bridge Road</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>XWY</td>\n",
       "      <td>LS6 4EP</td>\n",
       "      <td>45.456999</td>\n",
       "      <td>-73.595250</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WiFi': ''no'', 'Alcohol': 'u'none'', 'Outdoo...</td>\n",
       "      <td>Bakeries, Food, Desserts, Restaurants, Sandwiches</td>\n",
       "      <td>{'Friday': '7:0-15:0', 'Monday': '7:0-15:0', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eeEcf7XXAGClqdUCwnwRfg</td>\n",
       "      <td>The Old Lifeboat House</td>\n",
       "      <td>The Cove, Coverack Helston</td>\n",
       "      <td>Church Cove</td>\n",
       "      <td>CON</td>\n",
       "      <td>TR12 6SX</td>\n",
       "      <td>35.532021</td>\n",
       "      <td>-80.851682</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsTakeOut': 'True', 'RestaurantsDel...</td>\n",
       "      <td>British, Restaurants</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JNZeVq9jr9AWURmnM-Yxig</td>\n",
       "      <td>Total Gardening and Landscaping</td>\n",
       "      <td></td>\n",
       "      <td>Bury</td>\n",
       "      <td>XGM</td>\n",
       "      <td>BL8 4DR</td>\n",
       "      <td>42.996059</td>\n",
       "      <td>-89.568889</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'ByAppointmentOnly': 'False', 'BusinessAccept...</td>\n",
       "      <td>Home Services, Landscaping, Tree Services, Gar...</td>\n",
       "      <td>{'Friday': '0:0-0:0', 'Monday': '0:0-0:0', 'Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6dhkHf-CFHr7C8wj-qopCQ</td>\n",
       "      <td>Paper Cutz</td>\n",
       "      <td>Gorebrook Works, Pinkbank Lane</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>XGM</td>\n",
       "      <td>M12 5GH</td>\n",
       "      <td>42.996059</td>\n",
       "      <td>-89.568889</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessParking': '{'garage': False, 'valida...</td>\n",
       "      <td>Art Supplies, Arts &amp; Crafts, Shopping</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FByZsT1Sob5Vf1AYJFPxPg</td>\n",
       "      <td>Desi Masala</td>\n",
       "      <td>61 Queen Street</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>XWY</td>\n",
       "      <td>LS27 8EB</td>\n",
       "      <td>43.652821</td>\n",
       "      <td>-79.376345</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'WiFi': ''no'', 'HasTV': 'True', 'Alcohol': '...</td>\n",
       "      <td>Indian, Pakistani, Restaurants</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xjR-PII302WyyNRfpcowDg</td>\n",
       "      <td>Moxon's Fishmongers</td>\n",
       "      <td>110 Islington High Street</td>\n",
       "      <td>London</td>\n",
       "      <td>XGL</td>\n",
       "      <td>N1 8EG</td>\n",
       "      <td>43.645355</td>\n",
       "      <td>-79.524467</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessParking': '{'garage': False, 'street...</td>\n",
       "      <td>Specialty Food, Food, Seafood Markets</td>\n",
       "      <td>{'Friday': '9:0-19:30', 'Tuesday': '9:0-19:30'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZsL7FUkaWdyQnDoYB6XpSA</td>\n",
       "      <td>Happy Gathering Resturant Oldham</td>\n",
       "      <td></td>\n",
       "      <td>Oldham</td>\n",
       "      <td>XGM</td>\n",
       "      <td>OL2 6PX</td>\n",
       "      <td>42.996059</td>\n",
       "      <td>-89.568889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>Chinese, Restaurants</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>U9uyfhpZ89VEH5_webJ5Xg</td>\n",
       "      <td>Storm Cinemas - Belfast</td>\n",
       "      <td>Odyssey Arena, 2 Queens Quay</td>\n",
       "      <td>Down</td>\n",
       "      <td>DOW</td>\n",
       "      <td>BT33 0</td>\n",
       "      <td>43.641658</td>\n",
       "      <td>-79.376030</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id                              name  \\\n",
       "0   svMJjPd4l_Zb_MoxejYZvw                     Zoom Printing   \n",
       "1   d4qoXn1Rqt47LLTDA3bAwQ       Thayer David Ice Cream Shop   \n",
       "2   8_GNJU3EPar9VkPzJvoC3w      Bean & Brush Family Art Café   \n",
       "3   44xjnQMwAQjgZ80MW5z-Gg               No. 37 Sandwich Bar   \n",
       "4   eeEcf7XXAGClqdUCwnwRfg            The Old Lifeboat House   \n",
       "5   JNZeVq9jr9AWURmnM-Yxig   Total Gardening and Landscaping   \n",
       "6   6dhkHf-CFHr7C8wj-qopCQ                        Paper Cutz   \n",
       "7   FByZsT1Sob5Vf1AYJFPxPg                       Desi Masala   \n",
       "8   xjR-PII302WyyNRfpcowDg               Moxon's Fishmongers   \n",
       "9   ZsL7FUkaWdyQnDoYB6XpSA  Happy Gathering Resturant Oldham   \n",
       "10  U9uyfhpZ89VEH5_webJ5Xg           Storm Cinemas - Belfast   \n",
       "\n",
       "                                       address         city state postal_code  \\\n",
       "0                1136 Center Street, Suite 442    Thornhill   DUR     L4J 3M8   \n",
       "1                                    8 York St         Bath   BAS     BA1 1NG   \n",
       "2   The Old Sorting Office, 12 Hayfield Street         Sale   XGM     M33 7XW   \n",
       "3                          37 Monk Bridge Road        Leeds   XWY     LS6 4EP   \n",
       "4                   The Cove, Coverack Helston  Church Cove   CON    TR12 6SX   \n",
       "5                                                      Bury   XGM     BL8 4DR   \n",
       "6               Gorebrook Works, Pinkbank Lane   Manchester   XGM     M12 5GH   \n",
       "7                              61 Queen Street        Leeds   XWY    LS27 8EB   \n",
       "8                    110 Islington High Street       London   XGL      N1 8EG   \n",
       "9                                                    Oldham   XGM     OL2 6PX   \n",
       "10                Odyssey Arena, 2 Queens Quay         Down   DOW      BT33 0   \n",
       "\n",
       "     latitude  longitude  stars  review_count  is_open  \\\n",
       "0   43.808563 -79.463806    3.5             3        1   \n",
       "1   43.640646 -79.380939    4.0             4        1   \n",
       "2   42.996059 -89.568889    4.0             4        1   \n",
       "3   45.456999 -73.595250    4.5             3        1   \n",
       "4   35.532021 -80.851682    3.5             3        1   \n",
       "5   42.996059 -89.568889    5.0             3        1   \n",
       "6   42.996059 -89.568889    2.5             3        1   \n",
       "7   43.652821 -79.376345    4.5             5        1   \n",
       "8   43.645355 -79.524467    4.5             3        1   \n",
       "9   42.996059 -89.568889    4.0             3        1   \n",
       "10  43.641658 -79.376030    3.0             4        1   \n",
       "\n",
       "                                           attributes  \\\n",
       "0                                                  {}   \n",
       "1                     {'RestaurantsPriceRange2': '1'}   \n",
       "2   {'WiFi': 'u'free'', 'Caters': 'True', 'BikePar...   \n",
       "3   {'WiFi': ''no'', 'Alcohol': 'u'none'', 'Outdoo...   \n",
       "4   {'RestaurantsTakeOut': 'True', 'RestaurantsDel...   \n",
       "5   {'ByAppointmentOnly': 'False', 'BusinessAccept...   \n",
       "6   {'BusinessParking': '{'garage': False, 'valida...   \n",
       "7   {'WiFi': ''no'', 'HasTV': 'True', 'Alcohol': '...   \n",
       "8   {'BusinessParking': '{'garage': False, 'street...   \n",
       "9                                                  {}   \n",
       "10                                                 {}   \n",
       "\n",
       "                                           categories  \\\n",
       "0   Professional Services, Advertising, Printing S...   \n",
       "1                     Food, Ice Cream & Frozen Yogurt   \n",
       "2         Arts & Crafts, Shopping, Coffee & Tea, Food   \n",
       "3   Bakeries, Food, Desserts, Restaurants, Sandwiches   \n",
       "4                                British, Restaurants   \n",
       "5   Home Services, Landscaping, Tree Services, Gar...   \n",
       "6               Art Supplies, Arts & Crafts, Shopping   \n",
       "7                      Indian, Pakistani, Restaurants   \n",
       "8               Specialty Food, Food, Seafood Markets   \n",
       "9                                Chinese, Restaurants   \n",
       "10                               Arts & Entertainment   \n",
       "\n",
       "                                                hours  \n",
       "0   {'Friday': '9:0-17:0', 'Monday': '9:0-17:0', '...  \n",
       "1                                                  {}  \n",
       "2   {'Friday': '8:30-19:0', 'Monday': '8:30-19:0',...  \n",
       "3   {'Friday': '7:0-15:0', 'Monday': '7:0-15:0', '...  \n",
       "4                                                  {}  \n",
       "5   {'Friday': '0:0-0:0', 'Monday': '0:0-0:0', 'Su...  \n",
       "6                                                  {}  \n",
       "7                                                  {}  \n",
       "8   {'Friday': '9:0-19:30', 'Tuesday': '9:0-19:30'...  \n",
       "9                                                  {}  \n",
       "10                                                 {}  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_suspBus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suspBus.to_csv(path_or_buf='/Users/kemalm/Desktop/suspBus.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
